import os
import logging
import datetime
from flask import Flask, request, jsonify, render_template, session, g, redirect
# Using built-in localization for translation features
# Conditional Slack imports - only if needed
try:
    from slack_sdk import WebClient
    from slack_sdk.errors import SlackApiError
    SLACK_AVAILABLE = True
except ImportError:
    SLACK_AVAILABLE = False
    logging.warning("‚ö†Ô∏è Slack SDK not available - Slack features disabled")
import datetime
from datetime import timedelta
import portkey_config
try:
    from slack import post_to_slack, format_slack_message_basic, send_slack_message
except ImportError:
    # Slack module not available, define dummy functions
    def post_to_slack(*args, **kwargs):
        pass
    def format_slack_message_basic(*args, **kwargs):
        return ""
    def send_slack_message(*args, **kwargs):
        pass
import json
import openai_parser
import gemini_parser
import ollama_parser
import requests
from dotenv import load_dotenv
import sqlite3
import threading
try:
    from weaviate_service import get_weaviate_service
except ImportError:
    logging.warning("Weaviate service not available - semantic search disabled")
    def get_weaviate_service():
        return None
from multilingual_service import get_multilingual_service, SupportedLanguage

# MCP Hub imports
try:
    from mcp_service import mcp_manager
    MCP_AVAILABLE = True
    print("MCP service implementation loaded successfully")
except ImportError:
    MCP_AVAILABLE = False
    print("MCP modules not available - MCP features will be disabled")

# Load environment variables from .env file
load_dotenv()

# --- Configure Logging ---
log_level_str = os.environ.get("LOG_LEVEL", "INFO").upper()
log_level = getattr(logging, log_level_str, logging.WARNING)  # Changed from INFO to WARNING
logging.basicConfig(level=log_level, format='%(asctime)s - %(levelname)s - %(message)s')

# Disable Flask/Werkzeug request logging to reduce console spam
logging.getLogger("werkzeug").setLevel(logging.ERROR)
logging.getLogger("flask.app").setLevel(logging.WARNING)

app = Flask(__name__, static_folder='static', template_folder='templates')
app.secret_key = os.environ.get('SECRET_KEY', 'your-secret-key-here-change-in-production')

# Configure session
app.config['SESSION_COOKIE_SECURE'] = False  # Set to True in production with HTTPS
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['PERMANENT_SESSION_LIFETIME'] = datetime.timedelta(days=7)

# --- Translation Configuration ---
# Supported languages for UI translation
try:
    LANGUAGES = SupportedLanguage.get_supported_languages()
except:
    # Fallback if multilingual service is not available
    LANGUAGES = {
        'en': {'name': 'English', 'flag': 'üá∫üá∏'},
        'es': {'name': 'Spanish', 'flag': 'üá™üá∏'},
        'fr': {'name': 'French', 'flag': 'üá´üá∑'},
        'de': {'name': 'German', 'flag': 'üá©üá™'},
        'pt': {'name': 'Portuguese', 'flag': 'üáµüáπ'}
    }

def get_locale():
    # 1. Check URL parameter
    requested_language = request.args.get('lang')
    if requested_language and requested_language in LANGUAGES:
        session['language'] = requested_language
        session.permanent = True
        return requested_language
    
    # 2. Check user session
    if 'language' in session and session['language'] in LANGUAGES:
        return session['language']
    
    # 3. Check user's preferred language in database
    if hasattr(g, 'user_language') and g.user_language in LANGUAGES:
        return g.user_language
    
    # 4. Check global system language setting
    try:
        global_language = get_multilingual_setting('general_default_language', 'en')
        if global_language in LANGUAGES:
            return global_language
    except Exception:
        pass
    
    # 5. Check request header
    return request.accept_languages.best_match(LANGUAGES.keys()) or 'en'

# Using built-in localization for multilingual support

# --- Web UI Configuration ---
WEB_UI_ENABLED = os.environ.get("WEB_UI_ENABLED", "true").lower() == "true"
WEB_UI_PORT = int(os.environ.get("WEB_UI_PORT", 8081))

# Fix database path for local development
import os
default_db_path = './data/alerts.db' if not os.path.exists('/app') else '/app/data/alerts.db'
DB_PATH = os.getenv('DB_PATH', default_db_path)

# Ensure data directory exists
data_dir = os.path.dirname(DB_PATH)
if not os.path.exists(data_dir):
    os.makedirs(data_dir, exist_ok=True)
    logging.info(f"Created data directory: {data_dir}")

# --- Initialize Portkey clients ---
portkey_client_openai, portkey_client_gemini = portkey_config.initialize_portkey_clients()

# Initialize Slack client
slack_bot_token = os.environ.get("SLACK_BOT_TOKEN")
slack_channel_name = os.environ.get("SLACK_CHANNEL_NAME", "#general")
falco_ai_port = int(os.environ.get("FALCO_AI_PORT", 8080))

if not SLACK_AVAILABLE:
    logging.warning("Slack SDK not available. Slack notifications disabled.")
    slack_client = None
elif not slack_bot_token or slack_bot_token == "xoxb-your-token-here":
    logging.warning("SLACK_BOT_TOKEN not properly configured. Slack notifications disabled.")
    slack_client = None
else:
    slack_client = WebClient(token=slack_bot_token)

# --- Configure Minimum Priority Level ---
VALID_PRIORITIES = ["debug", "informational", "notice", "warning", "error", "critical", "alert", "emergency"]
MIN_PRIORITY_ENV = os.environ.get("MIN_PRIORITY", "warning").lower()
if MIN_PRIORITY_ENV not in VALID_PRIORITIES:
    logging.warning(f"Invalid MIN_PRIORITY '{MIN_PRIORITY_ENV}'. Using 'warning'.")
    MIN_FALCO_PRIORITY = "warning"
else:
    MIN_FALCO_PRIORITY = MIN_PRIORITY_ENV

# --- Configure Alert Age ---
IGNORE_OLDER_MINUTES = int(os.environ.get("IGNORE_OLDER", "1"))

# --- Weaviate Configuration ---
WEAVIATE_ENABLED = os.environ.get("WEAVIATE_ENABLED", "true").lower() == "true"
WEAVIATE_HOST = os.environ.get("WEAVIATE_HOST", "localhost")
WEAVIATE_PORT = int(os.environ.get("WEAVIATE_PORT", "8080"))
WEAVIATE_GRPC_PORT = int(os.environ.get("WEAVIATE_GRPC_PORT", "50051"))

# LLM Provider constants
LLM_PROVIDER_OPENAI = "OpenAI via Portkey"
LLM_PROVIDER_GEMINI = "Gemini via Portkey"
LLM_PROVIDER_OLLAMA = "Ollama"

# --- Utility Functions ---

def normalize_ai_options(provider_name, options):
    """Normalize AI provider options to use correct parameter names."""
    if provider_name.lower() == "ollama":
        # For Ollama, convert max_tokens to num_predict to avoid warnings
        normalized = options.copy()
        if 'max_tokens' in normalized:
            normalized['num_predict'] = normalized.pop('max_tokens')
        return normalized
    else:
        # For OpenAI and Gemini, use max_tokens as-is
        return options

# Alert deduplication
alert_counts = {}

# --- Web UI Database Functions ---
def init_database():
    """Initialize SQLite database to store alerts."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS alerts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            rule TEXT NOT NULL,
            priority TEXT NOT NULL,
            output TEXT NOT NULL,
            source TEXT,
            fields TEXT,
            ai_analysis TEXT,
            processed BOOLEAN DEFAULT FALSE,
            status TEXT DEFAULT 'unread'
        )
    ''')
    
    # Add status column to existing tables if it doesn't exist
    try:
        cursor.execute('ALTER TABLE alerts ADD COLUMN status TEXT DEFAULT "unread"')
    except sqlite3.OperationalError:
        # Column already exists
        pass
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS chat_messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            message_type TEXT NOT NULL,
            content TEXT NOT NULL,
            context TEXT
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS slack_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            setting_name TEXT UNIQUE NOT NULL,
            setting_value TEXT,
            setting_type TEXT DEFAULT 'string',
            description TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Initialize default Slack settings with environment variable detection
    env_bot_token = os.environ.get("SLACK_BOT_TOKEN", "")
    env_channel_name = os.environ.get("SLACK_CHANNEL_NAME", "#security-alerts")
    
    cursor.execute('''
        INSERT OR IGNORE INTO slack_config (setting_name, setting_value, setting_type, description)
        VALUES 
        ('bot_token', ?, 'password', 'Slack Bot Token (xoxb-...)'),
        ('channel_name', ?, 'string', 'Slack Channel Name'),
        ('enabled', 'true', 'boolean', 'Enable Slack Notifications'),
        ('username', 'Falco AI Alerts', 'string', 'Bot Display Name'),
        ('icon_emoji', ':shield:', 'string', 'Bot Icon Emoji'),
        ('template_style', 'detailed', 'select', 'Message Template Style'),
        ('min_priority_slack', 'warning', 'select', 'Minimum Priority for Slack'),
        ('include_commands', 'true', 'boolean', 'Include Suggested Commands'),
        ('thread_alerts', 'false', 'boolean', 'Use Threading for Related Alerts'),
        ('notification_throttling', 'false', 'boolean', 'Enable Notification Throttling'),
        ('throttle_threshold', '10', 'number', 'Throttle Threshold (alerts per 5 min)'),
        ('business_hours_only', 'false', 'boolean', 'Business Hours Filtering'),
        ('business_hours', '09:00-17:00', 'string', 'Business Hours Range'),
        ('escalation_enabled', 'false', 'boolean', 'Enable Alert Escalation'),
        ('escalation_interval', '30', 'number', 'Escalation Interval (minutes)'),
        ('digest_mode_enabled', 'false', 'boolean', 'Enable Daily Digest Mode'),
        ('digest_time', '09:00', 'string', 'Daily Digest Delivery Time')
    ''', (env_bot_token, env_channel_name))
    
    # Sync environment variables to database for existing installations
    if env_bot_token:
        cursor.execute('''
            UPDATE slack_config 
            SET setting_value = ? 
            WHERE setting_name = 'bot_token' AND (setting_value = '' OR setting_value IS NULL)
        ''', (env_bot_token,))
        
    if env_channel_name and env_channel_name != "#security-alerts":
        cursor.execute('''
            UPDATE slack_config 
            SET setting_value = ? 
            WHERE setting_name = 'channel_name'
        ''', (env_channel_name,))
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ai_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            setting_name TEXT UNIQUE NOT NULL,
            setting_value TEXT,
            setting_type TEXT DEFAULT 'string',
            description TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Initialize default AI settings
    cursor.execute('''
        INSERT OR IGNORE INTO ai_config (setting_name, setting_value, setting_type, description)
        VALUES 
        ('provider_name', 'ollama', 'select', 'AI Provider (openai, gemini, ollama)'),
        ('model_name', 'tinyllama', 'string', 'Model Name'),
        ('openai_model_name', 'gpt-3.5-turbo', 'string', 'OpenAI Model Name'),
        ('gemini_model_name', 'gemini-pro', 'string', 'Gemini Model Name'),
        ('portkey_api_key', '', 'password', 'Portkey API Key (Security Layer for Cloud AI)'),
        ('openai_virtual_key', '', 'password', 'OpenAI Virtual Key (Portkey)'),
        ('gemini_virtual_key', '', 'password', 'Gemini Virtual Key (Portkey)'),
        ('ollama_api_url', 'http://prod-ollama:11434/api/generate', 'string', 'Ollama API URL'),
        ('ollama_model_name', 'tinyllama', 'string', 'Ollama Model Name'),
        ('ollama_timeout', '30', 'number', 'Ollama Request Timeout (seconds)'),
        ('ollama_keep_alive', '10', 'number', 'Ollama Keep Alive (minutes)'),
        ('ollama_parallel', '1', 'number', 'Ollama Parallel Requests'),
        ('openai_timeout', '30', 'number', 'OpenAI Request Timeout (seconds)'),
        ('gemini_timeout', '30', 'number', 'Gemini Request Timeout (seconds)'),
        ('max_tokens', '500', 'number', 'Maximum Response Tokens'),
        ('temperature', '0.7', 'number', 'Response Temperature (0.0-1.0)'),
        ('enabled', 'true', 'boolean', 'Enable AI Analysis'),
        ('system_prompt', '', 'textarea', 'AI System Prompt (leave empty for default)')
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS general_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            setting_name TEXT UNIQUE NOT NULL,
            setting_value TEXT,
            setting_type TEXT DEFAULT 'string',
            description TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Initialize default General settings
    cursor.execute('''
        INSERT OR IGNORE INTO general_config (setting_name, setting_value, setting_type, description)
        VALUES 
        ('min_priority', 'warning', 'select', 'Minimum Alert Priority to Process'),
        ('ignore_older_minutes', '1', 'number', 'Ignore Alerts Older Than (minutes)'),
        ('web_ui_enabled', 'true', 'boolean', 'Enable Web UI Dashboard'),
        ('web_ui_port', '8081', 'number', 'Web UI Port Number'),
        ('falco_ai_port', '8080', 'number', 'Main Webhook Port Number'),
        ('log_level', 'INFO', 'select', 'System Log Level'),
        ('deduplication_enabled', 'true', 'boolean', 'Enable Alert Deduplication'),
        ('deduplication_window_minutes', '60', 'number', 'Deduplication Window (minutes)'),
        ('max_alerts_storage', '10000', 'number', 'Maximum Alerts to Store in Database'),
        ('alert_retention_days', '30', 'number', 'Delete Alerts Older Than (days)'),
        ('rate_limit_enabled', 'false', 'boolean', 'Enable Alert Rate Limiting'),
        ('max_alerts_per_minute', '60', 'number', 'Maximum Alerts Per Minute'),
        ('batch_processing_enabled', 'false', 'boolean', 'Enable Alert Batching'),
        ('batch_size', '10', 'number', 'Alert Batch Size'),
        ('alert_correlation_enabled', 'false', 'boolean', 'Enable Alert Correlation'),
        ('correlation_window_minutes', '15', 'number', 'Alert Correlation Window (minutes)')
    ''')

    # Create config table for AI chat and other general settings
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            value TEXT,
            description TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # Initialize default AI Chat settings
    cursor.execute('''
        INSERT OR IGNORE INTO config (name, value, description)
        VALUES 
        ('chat_enabled', 'true', 'Enable AI Security Chat'),
        ('chat_max_history', '50', 'Maximum chat messages to keep in history'),
        ('chat_session_timeout', '30', 'Auto-clear chat after inactivity (minutes)'),
        ('chat_context_alerts', '10', 'Number of recent alerts to include as context'),
        ('chat_response_length', 'normal', 'AI response length (brief/normal/detailed)'),
        ('chat_tone', 'professional', 'AI response tone (professional/casual/technical/educational)'),
        ('chat_include_remediation', 'true', 'Include remediation steps in responses'),
        ('chat_include_context', 'true', 'Include alert context in responses')
    ''')
    
    conn.commit()
    conn.close()
    logging.info("Database initialized")

def init_weaviate():
    """Initialize Weaviate connection and schema with retry logic."""
    if not WEAVIATE_ENABLED:
        logging.info("‚ö†Ô∏è Weaviate is disabled")
        return
    
    import time
    max_retries = 5
    retry_delay = 3  # seconds
    
    for attempt in range(max_retries):
        try:
            weaviate_service = get_weaviate_service()
            weaviate_service.host = WEAVIATE_HOST
            weaviate_service.port = WEAVIATE_PORT
            weaviate_service.grpc_port = WEAVIATE_GRPC_PORT
            
            # Connect to Weaviate
            if weaviate_service.connect():
                # Create schemas
                if weaviate_service.create_schema():
                    logging.info("‚úÖ SecurityAlert schema created successfully")
                    
                    # Also create conversation schema (optional)
                    try:
                        if hasattr(weaviate_service, 'create_conversation_schema'):
                            if weaviate_service.create_conversation_schema():
                                logging.info("‚úÖ ConversationContext schema created successfully")
                            else:
                                logging.warning("‚ö†Ô∏è Failed to create ConversationContext schema")
                        else:
                            logging.info("‚ö†Ô∏è ConversationContext schema creation method not available")
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è Error creating ConversationContext schema: {e}")
                    
                    logging.info("‚úÖ Weaviate initialized successfully")
                    return
                else:
                    logging.error("‚ùå Failed to create Weaviate schema")
                    break
            else:
                if attempt < max_retries - 1:
                    logging.warning(f"‚ö†Ô∏è Failed to connect to Weaviate (attempt {attempt + 1}/{max_retries}), retrying in {retry_delay}s...")
                    time.sleep(retry_delay)
                    continue
                else:
                    logging.error("‚ùå Failed to connect to Weaviate after all retries")
                    break
                
        except Exception as e:
            if attempt < max_retries - 1:
                logging.warning(f"‚ö†Ô∏è Error initializing Weaviate (attempt {attempt + 1}/{max_retries}): {e}, retrying in {retry_delay}s...")
                time.sleep(retry_delay)
                continue
            else:
                logging.error(f"‚ùå Error initializing Weaviate after all retries: {e}")
                break

def store_alert(alert_data, ai_analysis=None):
    """Store alert in database and Weaviate for analysis."""
    # Store in SQLite as before
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO alerts (rule, priority, output, source, fields, ai_analysis)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        alert_data.get('rule', ''),
        alert_data.get('priority', ''),
        alert_data.get('output', ''),
        alert_data.get('output_fields', {}).get('container.name', 'unknown'),
        json.dumps(alert_data.get('output_fields', {})),
        json.dumps(ai_analysis) if ai_analysis else None
    ))
    
    conn.commit()
    conn.close()
    logging.info(f"Stored alert in SQLite: {alert_data.get('rule', 'Unknown')}")
    
    # Store in Weaviate if enabled
    if WEAVIATE_ENABLED:
        try:
            weaviate_service = get_weaviate_service()
            if weaviate_service.client:
                weaviate_id = weaviate_service.store_alert(alert_data, ai_analysis)
                if weaviate_id:
                    logging.info(f"‚úÖ Stored alert in Weaviate: {weaviate_id}")
                else:
                    logging.warning("‚ö†Ô∏è Failed to store alert in Weaviate")
            else:
                logging.warning("‚ö†Ô∏è Weaviate client not connected")
        except Exception as e:
            logging.error(f"‚ùå Error storing alert in Weaviate: {e}")

def get_alerts(filters=None):
    """Retrieve alerts from database with optional filters."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    query = 'SELECT * FROM alerts'
    params = []
    
    if filters:
        conditions = []
        
        if filters.get('time_range') and filters['time_range'] != 'all':
            time_map = {
                '1h': 1,
                '24h': 24,
                '7d': 24 * 7,
                '30d': 24 * 30
            }
            hours = time_map.get(filters['time_range'], 24)
            cutoff = datetime.datetime.now() - datetime.timedelta(hours=hours)
            conditions.append('timestamp > ?')
            params.append(cutoff.isoformat())
        
        if filters.get('priority') and filters['priority'] != 'all':
            conditions.append('priority = ?')
            params.append(filters['priority'])
        
        if filters.get('rule') and filters['rule'] != 'all':
            conditions.append('rule = ?')
            params.append(filters['rule'])
        
        if filters.get('status') and filters['status'] != 'all':
            conditions.append('status = ?')
            params.append(filters['status'])
        
        if conditions:
            query += ' WHERE ' + ' AND '.join(conditions)
    
    query += ' ORDER BY timestamp DESC'
    
    # Add limit if specified
    limit = filters.get('limit') if filters else None
    if limit and limit.isdigit():
        query += f' LIMIT {limit}'
    
    cursor.execute(query, params)
    alerts = cursor.fetchall()
    conn.close()
    
    # Convert to list of dictionaries
    alert_list = []
    for alert in alerts:
        # Handle both old and new database schemas
        status = 'unread'  # default for old records
        if len(alert) > 9:  # new schema with status field
            status = alert[9] or 'unread'
        
        alert_dict = {
            'id': alert[0],
            'timestamp': alert[1],
            'rule': alert[2],
            'priority': alert[3],
            'output': alert[4],
            'source': alert[5] or 'unknown',
            'fields': json.loads(alert[6]) if alert[6] else {},
            'ai_analysis': json.loads(alert[7]) if alert[7] else None,
            'processed': bool(alert[8]),
            'status': status
        }
        alert_list.append(alert_dict)
    
    return alert_list

def load_system_prompt():
    """Load system prompt from database, with fallback to file, then default."""
    # First try to get from database
    try:
        ai_config = get_ai_config()
        db_prompt = ai_config.get('system_prompt', {}).get('value', '').strip()
        
        if db_prompt:
            logging.info("‚úÖ Loaded system prompt from database configuration")
            return db_prompt
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Could not load system prompt from database: {e}")
    
    # Fallback to file
    try:
        with open("templates/system_prompt.txt", 'r') as f:
            system_prompt = f.read().strip()
            logging.info("‚úÖ Loaded system prompt from templates/system_prompt.txt")
            return system_prompt
    except FileNotFoundError:
        logging.warning("‚ö†Ô∏è System prompt file not found, using default prompt")
    
    # Final fallback to hardcoded default
    default_prompt = """You are an expert in cloud security and Falco alerts. Analyze the provided Falco security alert and provide a comprehensive but concise security assessment.

Structure your response with the following sections:

**Security Impact:** Briefly describe the potential security risks and possible exploits related to this Falco alert (1-2 sentences).

**Next Steps:** Provide immediate investigation steps that security teams should take (1-2 sentences). Include relevant reference links within these recommendations whenever possible.

**Remediation Steps:** Explain how to fix or mitigate the issue (1-2 sentences). Focus on actionable steps that can be implemented immediately.

**Commands:** If there are safe, specific commands that can help investigate or remediate this issue, include them on separate lines starting with "Command:" - use placeholders like <container_id>, <pod_name>, <namespace> for values that need to be filled in. Only include commands that are safe and directly relevant to this security alert.

Guidelines:
- Keep responses concise and actionable
- Focus on Kubernetes and container security context
- Prioritize immediate security concerns
- Provide practical, implementable solutions
- Include relevant security best practices
- Consider the alert priority level in your response severity"""
    
    logging.info("‚úÖ Using default system prompt")
    return default_prompt

def generate_explanation_multilingual(alert_payload, language: str = "en"):
    """Generate multilingual explanation using translation service."""
    try:
        # Get translation service
        translation_service = get_multilingual_service()
        
        # Check if multilingual AI is available
        if not translation_service.is_available():
            logging.warning("üåç Multilingual AI not available, falling back to regular analysis")
            return generate_explanation_portkey(alert_payload)
        
        # Generate multilingual analysis
        response = translation_service.analyze_security_alert_multilingual(
            alert_payload, 
            target_language=language
        )
        
        if response.confidence > 0.5:
            logging.info(f"‚úÖ Generated multilingual analysis in {response.language.name}")
            
            # Parse the response into the expected format
            return {
                "securityImpact": response.content,
                "nextSteps": f"Analysis provided in {response.language.name} ({response.language.flag})",
                "remediationSteps": "Multilingual analysis includes comprehensive remediation guidance",
                "suggestedCommands": "See analysis above for specific commands",
                "llm_provider": f"translation-llm-{response.model_used}",
                "language": response.language.code,
                "translation_quality": response.translation_quality
            }
        else:
            logging.warning(f"‚ùå Low confidence multilingual analysis, falling back to English")
            return generate_explanation_portkey(alert_payload)
            
    except Exception as e:
        logging.error(f"‚ùå Error in multilingual analysis: {e}")
        return generate_explanation_portkey(alert_payload)

def generate_explanation_portkey(alert_payload, language: str = "en"):
    """Generate explanation using configured AI provider from database."""
    # Get AI configuration from database
    ai_config = get_ai_config()
    
    # Check if AI is enabled
    if ai_config.get('enabled', {}).get('value') != 'true':
        return {"error": "AI analysis is disabled"}
    
    provider_name = ai_config.get('provider_name', {}).get('value', 'openai').lower()
    
    # Use provider-specific model names (fix for startup logic issue)
    if provider_name == 'openai':
        model_name = ai_config.get('openai_model_name', {}).get('value', 'gpt-3.5-turbo')
    elif provider_name == 'gemini':
        model_name = ai_config.get('gemini_model_name', {}).get('value', 'gemini-pro')
    elif provider_name == 'ollama':
        model_name = ai_config.get('ollama_model_name', {}).get('value', 'phi3:mini')
    else:
        # Fallback to generic model_name for backward compatibility
        model_name = ai_config.get('model_name', {}).get('value', 'gpt-3.5-turbo')
    
    max_tokens = int(ai_config.get('max_tokens', {}).get('value', '500'))
    temperature = float(ai_config.get('temperature', {}).get('value', '0.7'))
    
    logging.info(f"ü§ñ Using AI provider: {provider_name} with model: {model_name} (provider-specific)")
    
    # For non-English languages, try multilingual AI model first
    if language != "en":
        return generate_explanation_multilingual(alert_payload, language)

    # Load configurable system prompt
    system_prompt = load_system_prompt()

    # Get contextual information from Weaviate if enabled
    contextual_info = ""
    if WEAVIATE_ENABLED:
        try:
            weaviate_service = get_weaviate_service()
            if weaviate_service.client:
                context = weaviate_service.get_contextual_analysis(alert_payload)
                
                if context.get('similar_count', 0) > 0:
                    contextual_info = f"""

HISTORICAL CONTEXT:
This alert pattern has been seen {context['similar_count']} times before. Based on similar past incidents:

Similar Alerts:
"""
                    for i, similar_alert in enumerate(context.get('similar_alerts', [])[:3], 1):
                        contextual_info += f"  {i}. {similar_alert.get('rule', 'Unknown')} ({similar_alert.get('priority', 'unknown')} priority, {similar_alert.get('certainty', 0):.1%} similarity)\n"
                    
                    # Add insights
                    insights = context.get('insights', [])
                    if insights:
                        contextual_info += f"\nKey Insights:\n"
                        for insight in insights:
                            contextual_info += f"  - {insight}\n"
                    
                    # Add common patterns
                    patterns = context.get('common_patterns', {})
                    if patterns.get('priorities'):
                        most_common_priority = max(patterns['priorities'].items(), key=lambda x: x[1])[0]
                        contextual_info += f"\nHistorical Pattern: Similar alerts typically have '{most_common_priority}' priority.\n"
                    
                    logging.info(f"üß† Enhanced AI analysis with context from {context['similar_count']} similar incidents")
                else:
                    contextual_info = "\n\nHISTORICAL CONTEXT: This appears to be a new type of alert pattern not seen before."
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Failed to get contextual analysis: {e}")
            contextual_info = ""

    user_prompt = f"""Falco Alert:
Rule: {alert_payload.get('rule', 'N/A')}
Priority: {alert_payload.get('priority', 'N/A')}
Details: {alert_payload.get('output', 'N/A')}
Command: {alert_payload.get('output_fields', {}).get('proc.cmdline', 'N/A')}{contextual_info}"""

    try:
        explanation_text = ""
        
        if provider_name == "openai":
            # Get OpenAI configuration from database
            portkey_api_key = ai_config.get('portkey_api_key', {}).get('value', '')
            openai_virtual_key = ai_config.get('openai_virtual_key', {}).get('value', '')
            
            if not portkey_api_key or not openai_virtual_key:
                return {"error": "OpenAI configuration incomplete - missing API keys"}
            
            from portkey_ai import Portkey
            
            # Create Portkey client for this request
            client = Portkey(
                api_key=portkey_api_key,
                virtual_key=openai_virtual_key
            )
            
            logging.info("ü§ñ Calling OpenAI via Portkey...")
            response = client.chat.completions.create(
                model=model_name or "gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # Handle both object and dict response formats
            logging.info(f"üì¶ Response type: {type(response)}")
            
            # Try object access first
            try:
                explanation_text = response.choices[0].message.content
                logging.info(f"‚úÖ Extracted via object access: {explanation_text[:100]}...")
            except (AttributeError, TypeError):
                # Fallback to dictionary access
                logging.info("üîÑ Trying dictionary access...")
                explanation_text = response['choices'][0]['message']['content']
                logging.info(f"‚úÖ Extracted via dict access: {explanation_text[:100]}...")
            
            llm_provider_string = LLM_PROVIDER_OPENAI
            parser_function = openai_parser.parse_explanation_text_regex_openai

        elif provider_name == "gemini":
            # Get Gemini configuration from database
            portkey_api_key = ai_config.get('portkey_api_key', {}).get('value', '')
            gemini_virtual_key = ai_config.get('gemini_virtual_key', {}).get('value', '')
            
            if not portkey_api_key or not gemini_virtual_key:
                return {"error": "Gemini configuration incomplete - missing API keys"}
            
            from portkey_ai import Portkey
            
            # Create Portkey client for this request
            client = Portkey(
                api_key=portkey_api_key,
                virtual_key=gemini_virtual_key
            )
            
            logging.info("ü§ñ Calling Gemini via Portkey...")
            response = client.chat.completions.create(
                model=model_name or "gemini-pro",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # Validate Gemini response
            logging.info(f"üì¶ Gemini response type: {type(response)}")
            
            # Extract content with validation
            try:
                explanation_text = response.choices[0].message.content
                logging.info("‚úÖ Extracted via object access")
            except (AttributeError, TypeError):
                logging.info("üîÑ Trying dictionary access...")
                try:
                    explanation_text = response['choices'][0]['message']['content']
                    logging.info("‚úÖ Extracted via dict access")
                except (KeyError, TypeError) as e:
                    logging.error(f"‚ùå Failed to extract content from Gemini response: {e}")
                    logging.error(f"Response structure: {response}")
                    return {"error": f"Invalid Gemini response format: {e}"}
            
            # Validate content
            if not explanation_text or not isinstance(explanation_text, str):
                logging.error(f"‚ùå Invalid Gemini content: {type(explanation_text)} - {explanation_text}")
                return {"error": "Empty or invalid content from Gemini"}
            
            if len(explanation_text.strip()) < 50:
                logging.warning(f"‚ö†Ô∏è Suspiciously short Gemini response: {explanation_text}")
                return {"error": f"Gemini response too short: {explanation_text}"}
            
            # Check for expected sections in response
            expected_sections = ["Security Impact", "Next Steps", "Remediation"]
            found_sections = [section for section in expected_sections if section.lower() in explanation_text.lower()]
            
            if len(found_sections) < 2:
                logging.warning(f"‚ö†Ô∏è Gemini response missing expected sections. Found: {found_sections}")
                logging.warning(f"Response: {explanation_text[:200]}...")
            
            logging.info(f"‚úÖ Gemini content validated: {len(explanation_text)} chars, sections: {found_sections}")
            logging.info(f"üîç Gemini response preview: {explanation_text[:150]}...")
            
            llm_provider_string = LLM_PROVIDER_GEMINI
            parser_function = gemini_parser.parse_explanation_text_regex_gemini

        elif provider_name == "ollama":
            # Get Ollama configuration from database
            ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
            ollama_model_name = ai_config.get('ollama_model_name', {}).get('value', 'llama3')
            
            if not ollama_api_url:
                return {"error": "Ollama API URL not configured"}
            
            logging.info(f"ü§ñ Calling Ollama at {ollama_api_url} with model {ollama_model_name}...")

            # Normalize options for Ollama
            options = normalize_ai_options(provider_name, {
                "max_tokens": max_tokens,
                "temperature": temperature
            })
            
            ollama_payload = {
                "model": ollama_model_name,
                "prompt": system_prompt + "\n\n" + user_prompt,
                "stream": False,
                "options": options
            }

            # Get configurable timeout from database configuration
            ollama_timeout = int(ai_config.get('ollama_timeout', {}).get('value', '30'))
            response = requests.post(ollama_api_url, json=ollama_payload, timeout=ollama_timeout)
            response.raise_for_status()
            
            response_data = response.json()
            explanation_text = response_data.get('response', '')
            logging.info(f"‚úÖ Ollama response: {explanation_text[:100]}...")
            
            llm_provider_string = LLM_PROVIDER_OLLAMA
            parser_function = ollama_parser.parse_explanation_text_regex_ollama

        else:
            return {"error": f"Unsupported provider: {provider_name}"}

        if not explanation_text:
            return {"error": f"Empty response from {provider_name}"}

        # Parse the explanation
        explanation_dict = parser_function(explanation_text)
        explanation_dict["llm_provider"] = llm_provider_string
        
        logging.info(f"üéØ Successfully generated explanation with {provider_name}")
        return explanation_dict

    except AttributeError as e:
        logging.error(f"‚ùå Attribute error accessing response: {e}")
        logging.error(f"Response object: {response}")
        return {"error": f"Response format error: {e}"}
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Network error with {provider_name}: {e}")
        return {"error": f"Network error: {e}"}
    except Exception as e:
        logging.error(f"‚ùå Unexpected error with {provider_name}: {e}")
        logging.error(f"Response object: {response if 'response' in locals() else 'No response'}")
        return {"error": f"LLM error: {e}"}

@app.route('/health', methods=['GET'])
def health_check():
    """Lightweight health check endpoint."""
    try:
        # Basic health info
        health_data = {
            "status": "healthy", 
            "service": "falco-ai-alerts",
            "timestamp": datetime.datetime.now().isoformat(),
            "web_ui_enabled": WEB_UI_ENABLED
        }
        
        # Add only essential feature info if Web UI is enabled (no expensive detection)
        if WEB_UI_ENABLED:
            try:
                # Use cached configuration data instead of running full feature detection
                health_data.update({
                    "features": {
                        "slack_configured": bool(get_slack_config()),
                        "ai_providers": {
                            "openai": bool(get_general_setting('openai_virtual_key')),
                            "gemini": bool(get_general_setting('gemini_virtual_key')),
                            "ollama": bool(get_general_setting('ollama_api_url', 'http://ollama:11434/api/generate'))
                        },
                        "recommended_provider": get_general_setting('provider_name', 'ollama'),
                        "deployment_type": "local",
                        "auto_configuration_available": True
                    }
                })
            except Exception as e:
                health_data["features"] = {"error": f"Basic feature check failed: {str(e)}"}
        
        return jsonify(health_data), 200
    except Exception as e:
        return jsonify({
            "status": "unhealthy", 
            "service": "falco-ai-alerts",
            "error": str(e),
            "timestamp": datetime.datetime.now().isoformat()
        }), 500

@app.route('/falco-webhook', methods=['POST'])
def falco_webhook():
    """Main webhook endpoint for Falco alerts."""
    
    # Validate request
    if request.headers.get('Content-Type') != 'application/json':
        logging.warning("üö´ REJECTED: Invalid Content-Type header - expected application/json")
        return jsonify({"error": "Content-Type must be application/json"}), 400
        
    alert_payload = request.json
    if not alert_payload:
        logging.warning("üö´ REJECTED: Empty or invalid JSON payload")
        return jsonify({"error": "Invalid JSON payload"}), 400

    # Extract alert metadata for logging
    rule_name = alert_payload.get('rule', 'Unknown')
    alert_priority = alert_payload.get('priority', 'unknown').lower()
    alert_time = alert_payload.get('time', 'Unknown')
    source_ip = request.remote_addr
    
    # Initial logging with alert metadata
    # Reduced logging - only log critical/error priority alerts
    if alert_priority in ['critical', 'error']:
        logging.info(f"üì• RECEIVED: Alert '{rule_name}' | Priority: {alert_priority} | Time: {alert_time} | Source: {source_ip}")

    # Get current configuration from database
    min_priority = get_general_setting('min_priority', 'warning')
    ignore_older_minutes = int(get_general_setting('ignore_older_minutes', '1'))
    deduplication_enabled = get_general_setting('deduplication_enabled', 'true') == 'true'
    
    # Priority filtering
    try:
        priority_rank_alert = VALID_PRIORITIES.index(alert_priority)
        priority_rank_min = VALID_PRIORITIES.index(min_priority)
        
        if priority_rank_alert < priority_rank_min:
            logging.info(f"üîΩ FILTERED: Priority '{alert_priority}' below minimum '{min_priority}' | Rule: {rule_name} | IGNORED")
            return jsonify({"status": "ignored", "reason": "priority_too_low"}), 200
        else:
            logging.info(f"‚úÖ PASSED: Priority check '{alert_priority}' >= '{min_priority}' | Rule: {rule_name}")
    except ValueError:
        logging.warning(f"‚ö†Ô∏è UNKNOWN: Priority '{alert_priority}' not recognized, processing anyway | Rule: {rule_name}")

    # Age filtering
    if ignore_older_minutes > 0:
        alert_time_str = alert_payload.get('time')
        if alert_time_str:
            try:
                # Parse alert timestamp and make it timezone-aware
                if 'T' in alert_time_str:
                    # ISO format timestamp
                    alert_datetime = datetime.datetime.fromisoformat(alert_time_str.replace('Z', '+00:00'))
                else:
                    # Assume it's already in the right format
                    alert_datetime = datetime.datetime.fromisoformat(alert_time_str)
                
                # Ensure alert_datetime is timezone-aware
                if alert_datetime.tzinfo is None:
                    alert_datetime = alert_datetime.replace(tzinfo=datetime.timezone.utc)
                
                current_datetime = datetime.datetime.now(datetime.timezone.utc)
                age_minutes = (current_datetime - alert_datetime).total_seconds() / 60
                
                if age_minutes > ignore_older_minutes:
                    logging.info(f"‚è∞ FILTERED: Alert age {age_minutes:.1f}min > {ignore_older_minutes}min threshold | Rule: {rule_name} | IGNORED")
                    return jsonify({"status": "ignored", "reason": "too_old"}), 200
                else:
                    logging.info(f"‚úÖ PASSED: Age check {age_minutes:.1f}min <= {ignore_older_minutes}min | Rule: {rule_name}")
            except ValueError as e:
                logging.warning(f"‚ö†Ô∏è TIMESTAMP: Error parsing timestamp '{alert_time_str}': {e} | Rule: {rule_name} | Processing anyway")
        else:
            logging.info(f"‚ö†Ô∏è NO_TIME: Alert has no timestamp, skipping age check | Rule: {rule_name}")

    # Deduplication
    if deduplication_enabled:
        alert_key = f"{alert_payload.get('rule', '')}-{alert_payload.get('output', '')[:50]}"
        if alert_key in alert_counts:
            alert_counts[alert_key] += 1
            logging.info(f"üîÅ DUPLICATE: Alert #{alert_counts[alert_key]} | Rule: {rule_name} | Key: {alert_key[:100]}... | IGNORED")
            return jsonify({"status": "duplicate", "count": alert_counts[alert_key]}), 200
        else:
            alert_counts[alert_key] = 1
            logging.info(f"‚úÖ PASSED: Deduplication check (first occurrence) | Rule: {rule_name}")
    else:
        logging.info(f"‚ö†Ô∏è DEDUP_DISABLED: Deduplication disabled, processing alert | Rule: {rule_name}")

    # Generate AI explanation
    logging.info(f"ü§ñ AI_ANALYSIS: Starting AI explanation generation | Rule: {rule_name}")
    explanation_sections = generate_explanation_portkey(alert_payload)
    
    ai_success = explanation_sections and not explanation_sections.get("error")
    if ai_success:
        ai_provider = explanation_sections.get("llm_provider", "Unknown")
        logging.info(f"‚úÖ AI_SUCCESS: Generated explanation using {ai_provider} | Rule: {rule_name}")
    else:
        error_msg = explanation_sections.get("error", "Unknown error") if explanation_sections else "No response"
        logging.warning(f"‚ùå AI_FAILED: {error_msg} | Rule: {rule_name}")
    
    # Store alert in database for Web UI
    if WEB_UI_ENABLED:
        try:
            store_alert_enhanced(alert_payload, explanation_sections if ai_success else None)
            logging.info(f"üíæ DB_STORED: Alert saved to database with real-time sync | Rule: {rule_name}")
        except Exception as e:
            logging.error(f"‚ùå DB_ERROR: Failed to store alert: {e} | Rule: {rule_name}")
    else:
        logging.info(f"‚ö†Ô∏è DB_SKIP: Web UI disabled, not storing alert | Rule: {rule_name}")

    # Send to Slack
    # Get current Slack configuration from database
    slack_config = get_slack_config()
    current_token = slack_config.get('bot_token', {}).get('value', '')
    current_channel = slack_config.get('channel_name', {}).get('value', slack_channel_name)
    slack_enabled = slack_config.get('enabled', {}).get('value', 'false').lower() == 'true'
    
    if slack_enabled and current_token and current_token != 'xoxb-your-token-here':
        try:
            # Create fresh Slack client with current token from database
            current_slack_client = WebClient(token=current_token)
            
            if ai_success:
                post_to_slack(alert_payload, explanation_sections, current_slack_client, current_channel)
                logging.info(f"üì¢ SLACK_SUCCESS: Alert sent with AI analysis to {current_channel} | Rule: {rule_name}")
                return jsonify({"status": "success", "message": "Alert sent with AI analysis"}), 200
            else:
                error_msg = explanation_sections.get("error", "AI analysis failed") if explanation_sections else "AI analysis failed"
                basic_message = format_slack_message_basic(alert_payload, error_msg)
                send_slack_message(basic_message, current_slack_client, current_channel)
                logging.warning(f"üì¢ SLACK_PARTIAL: Alert sent without AI analysis to {current_channel} | Rule: {rule_name} | Reason: {error_msg}")
                return jsonify({"status": "partial_success", "message": "Alert sent without AI analysis", "error": error_msg}), 200
        except SlackApiError as e:
            slack_error = e.response.get('error', 'Unknown Slack error')
            logging.error(f"‚ùå SLACK_API_ERROR: Slack API error: {slack_error} | Rule: {rule_name}")
            return jsonify({"status": "slack_error", "message": "Alert processed but Slack delivery failed", "error": f"Slack API error: {slack_error}"}), 200
        except Exception as e:
            logging.error(f"‚ùå SLACK_ERROR: Failed to send to Slack: {e} | Rule: {rule_name}")
            return jsonify({"status": "slack_error", "message": "Alert processed but Slack delivery failed", "error": str(e)}), 200
    else:
        logging.warning(f"‚ö†Ô∏è SLACK_DISABLED: Alert processed but Slack not configured | Rule: {rule_name}")
        return jsonify({"status": "no_slack", "message": "Alert processed but Slack not configured"}), 200

# --- Web UI Functions ---
def store_chat_message(message_type, content, context=None):
    """Store chat message for conversation history."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO chat_messages (message_type, content, context)
        VALUES (?, ?, ?)
    ''', (message_type, content, json.dumps(context) if context else None))
    
    conn.commit()
    conn.close()

def store_enhanced_chat_message(message_type, content, persona, context=None):
    """Store enhanced chat message with persona information."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Create enhanced_chat_messages table if it doesn't exist
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS enhanced_chat_messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            message_type TEXT NOT NULL,
            content TEXT NOT NULL,
            persona TEXT NOT NULL,
            context TEXT
        )
    ''')
    
    cursor.execute('''
        INSERT INTO enhanced_chat_messages (message_type, content, persona, context)
        VALUES (?, ?, ?, ?)
    ''', (message_type, content, persona, json.dumps(context) if context else None))
    
    conn.commit()
    conn.close()

def get_chat_history(limit=50):
    """Retrieve chat message history."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT * FROM chat_messages 
        ORDER BY timestamp DESC 
        LIMIT ?
    ''', (limit,))
    
    messages = cursor.fetchall()
    conn.close()
    
    # Convert to list of dictionaries and reverse to get chronological order
    message_list = []
    for msg in reversed(messages):
        message_dict = {
            'id': msg[0],
            'timestamp': msg[1],
            'type': msg[2],
            'content': msg[3],
            'context': json.loads(msg[4]) if msg[4] else None
        }
        message_list.append(message_dict)
    
    return message_list

def generate_ai_response(question, alert_context=None):
    """Generate AI response based on question and alert context."""
    alerts = get_alerts()
    
    # Analyze the question and generate appropriate response
    question_lower = question.lower()
    
    if 'critical' in question_lower or 'most important' in question_lower:
        critical_alerts = [a for a in alerts if a['priority'] == 'critical']
        if critical_alerts:
            return f"üö® You have {len(critical_alerts)} critical alerts. The most recent is '{critical_alerts[0]['rule']}' which requires immediate attention. These alerts indicate serious security threats that could compromise your system."
        else:
            return "‚úÖ Good news! You currently have no critical alerts. Your system appears to be operating securely."
    
    elif 'trend' in question_lower or 'pattern' in question_lower:
        total_alerts = len(alerts)
        recent_alerts = len([a for a in alerts if (datetime.datetime.now() - datetime.datetime.fromisoformat(a['timestamp'])).total_seconds() < 3600])
        
        # Analyze rule patterns
        rule_counts = {}
        for alert in alerts:
            rule_counts[alert['rule']] = rule_counts.get(alert['rule'], 0) + 1
        
        top_rule = max(rule_counts.items(), key=lambda x: x[1]) if rule_counts else None
        
        response = f"üìà Analysis of {total_alerts} alerts shows {recent_alerts} in the last hour. "
        if top_rule:
            response += f"Most common alert: '{top_rule[0]}' ({top_rule[1]} occurrences). "
        
        response += "I recommend monitoring these patterns for potential security incidents."
        return response
    
    elif 'recommend' in question_lower or 'next steps' in question_lower:
        high_priority = len([a for a in alerts if a['priority'] in ['critical', 'error']])
        
        recommendations = [
            f"üìã Investigate {high_priority} high-priority alerts immediately",
            "üõ°Ô∏è Implement automated response for critical alerts",
            "üìä Set up regular security review meetings",
            "üöÄ Consider deploying this system to production for real-time monitoring"
        ]
        
        return "üí° Based on your alert data, here are my recommendations:\n\n" + "\n".join(recommendations)
    
    else:
        # Default analytical response
        total_alerts = len(alerts)
        priorities = {}
        for alert in alerts:
            priorities[alert['priority']] = priorities.get(alert['priority'], 0) + 1
        
        priority_text = ", ".join([f"{count} {priority}" for priority, count in priorities.items()])
        
        return f"ü§î I've analyzed your {total_alerts} alerts. Priority breakdown: {priority_text}. What specific aspect would you like me to explore? I can analyze trends, provide recommendations, or help with deployment planning."

def parse_command(message, persona):
    """Parse user command and determine required actions."""
    message_lower = message.lower()
    actions = {
        'needs_search': False,
        'needs_stats': False,
        'needs_contextual_analysis': False,
        'needs_dashboard': False,
        'needs_report': False,
        'command_type': 'chat'
    }
    
    # Search-related commands
    search_keywords = ['search', 'find', 'similar', 'show', 'analyze', 'investigate', 'hunt', 'look for', 'discover']
    if any(keyword in message_lower for keyword in search_keywords):
        actions['needs_search'] = True
    
    # Stats-related commands
    stats_keywords = ['stats', 'statistics', 'count', 'how many', 'total', 'summary', 'overview', 'metrics']
    if any(keyword in message_lower for keyword in stats_keywords):
        actions['needs_stats'] = True
    
    # Contextual analysis commands
    context_keywords = ['context', 'related', 'patterns', 'trends', 'similar incidents', 'past events']
    if any(keyword in message_lower for keyword in context_keywords):
        actions['needs_contextual_analysis'] = True
    
    # Dashboard commands
    dashboard_keywords = ['dashboard', 'chart', 'graph', 'visualize', 'plot', 'display']
    if any(keyword in message_lower for keyword in dashboard_keywords):
        actions['needs_dashboard'] = True
        actions['command_type'] = 'dashboard'
    
    # Report commands
    report_keywords = ['report', 'generate', 'create document', 'executive summary', 'analysis report']
    if any(keyword in message_lower for keyword in report_keywords):
        actions['needs_report'] = True
        actions['command_type'] = 'report'
    
    # Persona-specific command interpretations
    if persona == 'dashboard_creator':
        # Dashboard creator is more likely to need visualizations
        if any(word in message_lower for word in ['create', 'build', 'make', 'design']):
            actions['needs_dashboard'] = True
            actions['command_type'] = 'dashboard'
    
    elif persona == 'report_generator':
        # Report generator is more likely to need comprehensive data
        if any(word in message_lower for word in ['generate', 'create', 'produce', 'write']):
            actions['needs_report'] = True
            actions['command_type'] = 'report'
            actions['needs_stats'] = True
    
    elif persona == 'threat_hunter':
        # Threat hunter needs more search and analysis
        actions['needs_search'] = True
        actions['needs_contextual_analysis'] = True
    
    elif persona == 'incident_responder':
        # Incident responder needs immediate context
        if any(word in message_lower for word in ['urgent', 'critical', 'immediate', 'now']):
            actions['needs_search'] = True
            actions['needs_stats'] = True
    
    return actions

def diagnose_system_configuration():
    """Comprehensive system configuration diagnosis."""
    issues = []
    fixes = []
    
    try:
        # Check alert processing configuration
        general_config = get_cached_general_config()
        
        # Age filter check
        ignore_older = int(general_config.get('ignore_older_minutes', {}).get('value', '1'))
        if ignore_older <= 5:
            issues.append({
                'type': 'warning',
                'component': 'Alert Processing',
                'issue': f'Age filter set to {ignore_older} minutes - may filter out legitimate alerts',
                'impact': 'Many alerts could be ignored due to processing delays',
                'fix_available': True
            })
            fixes.append({
                'action': 'update_age_filter',
                'description': 'Set age filter to 1440 minutes (24 hours)',
                'api_call': '/api/general/config',
                'payload': {'ignore_older_minutes': '1440'}
            })
        
        # Priority filter check
        min_priority = general_config.get('min_priority', {}).get('value', 'warning')
        if min_priority in ['emergency', 'alert', 'critical']:
            issues.append({
                'type': 'info',
                'component': 'Alert Processing',
                'issue': f'High priority filter ({min_priority}) - only critical alerts will be processed',
                'impact': 'Lower priority alerts will be ignored',
                'fix_available': True
            })
        
        # AI configuration check
        ai_config = get_ai_config()
        if ai_config.get('enabled', {}).get('value') != 'true':
            issues.append({
                'type': 'error',
                'component': 'AI Analysis',
                'issue': 'AI analysis is disabled',
                'impact': 'No intelligent analysis of security alerts',
                'fix_available': True
            })
        
    except Exception as e:
        issues.append({
            'type': 'error',
            'component': 'System Diagnostics',
            'issue': f'Diagnostic check failed: {str(e)}',
            'impact': 'Unable to assess system health',
            'fix_available': False
        })
    
    return {
        'issues': issues,
        'fixes': fixes,
        'overall_health': 'good' if len([i for i in issues if i['type'] == 'error']) == 0 else 'issues_detected'
    }

def generate_configuration_summary():
    """Generate a comprehensive configuration summary for users."""
    try:
        # Get all configuration data
        ai_config = get_ai_config()
        general_config = get_cached_general_config()
        slack_config = get_slack_config()
        
        summary = "## ü§ñ Current AI Configuration Summary\n\n"
        
        # AI Provider and Model Information
        provider = ai_config.get('provider_name', {}).get('value', 'ollama')
        model_name = ai_config.get('model_name', {}).get('value', 'tinyllama')
        ai_enabled = ai_config.get('enabled', {}).get('value', 'true')
        
        summary += "### üß† AI Engine\n"
        summary += f"- **Status**: {'üü¢ Enabled' if ai_enabled == 'true' else 'üî¥ Disabled'}\n"
        summary += f"- **Provider**: {provider.title()}\n"
        
        if provider == 'ollama':
            ollama_model = ai_config.get('ollama_model_name', {}).get('value', model_name)
            ollama_url = ai_config.get('ollama_api_url', {}).get('value', 'http://prod-ollama:11434/api/generate')
            summary += f"- **Model**: {ollama_model}\n"
            summary += f"- **API URL**: {ollama_url}\n"
        elif provider == 'openai':
            openai_model = ai_config.get('openai_model_name', {}).get('value', 'gpt-3.5-turbo')
            summary += f"- **Model**: {openai_model}\n"
            summary += f"- **API**: Portkey (Security Layer)\n"
        elif provider == 'gemini':
            gemini_model = ai_config.get('gemini_model_name', {}).get('value', 'gemini-pro')
            summary += f"- **Model**: {gemini_model}\n"
            summary += f"- **API**: Portkey (Security Layer)\n"
        
        # AI Settings
        max_tokens = ai_config.get('max_tokens', {}).get('value', '500')
        temperature = ai_config.get('temperature', {}).get('value', '0.7')
        summary += f"- **Max Tokens**: {max_tokens}\n"
        summary += f"- **Temperature**: {temperature}\n\n"
        
        # Alert Processing Configuration
        summary += "### ‚öôÔ∏è Alert Processing\n"
        min_priority = general_config.get('min_priority', {}).get('value', 'warning')
        ignore_older = general_config.get('ignore_older_minutes', {}).get('value', '1')
        dedup_enabled = general_config.get('deduplication_enabled', {}).get('value', 'true')
        
        summary += f"- **Minimum Priority**: {min_priority.title()}\n"
        summary += f"- **Age Filter**: {ignore_older} minutes\n"
        summary += f"- **Deduplication**: {'üü¢ Enabled' if dedup_enabled == 'true' else 'üî¥ Disabled'}\n\n"
        
        # Slack Integration
        summary += "### üí¨ Slack Integration\n"
        slack_enabled = slack_config.get('enabled', {}).get('value', 'false')
        if slack_enabled == 'true':
            channel = slack_config.get('channel_name', {}).get('value', '#security-alerts')
            template_style = slack_config.get('template_style', {}).get('value', 'detailed')
            summary += f"- **Status**: üü¢ Enabled\n"
            summary += f"- **Channel**: {channel}\n"
            summary += f"- **Template**: {template_style.title()}\n"
        else:
            summary += f"- **Status**: üî¥ Disabled\n"
        
        summary += "\n"
        
        # Web UI Status
        summary += "### üåê Web Interface\n"
        summary += f"- **Dashboard**: http://localhost:8080/\n"
        summary += f"- **Enhanced Chat**: http://localhost:8080/enhanced-chat\n"
        summary += f"- **AI Config**: http://localhost:8080/config/ai\n"
        
        return summary
        
    except Exception as e:
        return f"‚ùå Error generating configuration summary: {str(e)}"

def generate_troubleshooting_response(message, context):
    """Generate intelligent troubleshooting responses."""
    message_lower = message.lower()
    
    # Configuration summary queries - provide comprehensive info first
    if any(word in message_lower for word in ['my ai config', 'ai configuration', 'current config', 'my configuration', 'what is my']):
        # Provide comprehensive configuration summary first
        response = generate_configuration_summary()
        
        # Then add any detected issues
        diagnosis = diagnose_system_configuration()
        if diagnosis['issues']:
            response += "\n## ‚ö†Ô∏è Detected Issues\n\n"
            for issue in diagnosis['issues']:
                icon = "üî¥" if issue['type'] == 'error' else "üü°" if issue['type'] == 'warning' else "‚ÑπÔ∏è"
                response += f"{icon} **{issue['component']}**: {issue['issue']}\n"
                response += f"   *Impact*: {issue['impact']}\n\n"
            
            if diagnosis['fixes']:
                response += "**Available Fixes:**\n"
                for i, fix in enumerate(diagnosis['fixes'], 1):
                    response += f"{i}. {fix['description']}\n"
                response += "\nüí° Type 'apply fix [number]' to apply a specific fix.\n"
        
        return response
    
    # Troubleshooting and diagnostic queries
    elif any(word in message_lower for word in ['config', 'configuration', 'setting', 'settings', 'no alerts', 'not working', 'troubleshoot', 'diagnose', 'problem']):
        diagnosis = diagnose_system_configuration()
        
        response = "## üîß Configuration Analysis\n\n"
        
        if diagnosis['issues']:
            response += "**Issues Found:**\n"
            for issue in diagnosis['issues']:
                icon = "üî¥" if issue['type'] == 'error' else "üü°" if issue['type'] == 'warning' else "‚ÑπÔ∏è"
                response += f"{icon} **{issue['component']}**: {issue['issue']}\n"
                response += f"   *Impact*: {issue['impact']}\n\n"
        else:
            response += "‚úÖ No configuration issues detected!\n\n"
        
        if diagnosis['fixes']:
            response += "**Available Fixes:**\n"
            for i, fix in enumerate(diagnosis['fixes'], 1):
                response += f"{i}. {fix['description']}\n"
            response += "\nüí° Type 'apply fix [number]' to apply a specific fix.\n"
        
        return response
    
    # Fix application
    elif message_lower.startswith('apply fix'):
        try:
            import re
            match = re.search(r'apply fix (\d+)', message_lower)
            if match:
                fix_num = int(match.group(1)) - 1
                diagnosis = diagnose_system_configuration()
                
                if 0 <= fix_num < len(diagnosis['fixes']):
                    fix = diagnosis['fixes'][fix_num]
                    
                    if fix['action'] == 'update_age_filter':
                        update_general_config('ignore_older_minutes', '1440')
                        response = "‚úÖ **Age Filter Updated!**\n\nChanged from 1 minute to 1440 minutes (24 hours). This should allow older alerts to be processed."
                    else:
                        response = "üîß Fix not yet implemented for this issue."
                    
                    return response
                else:
                    return "‚ùå Invalid fix number. Please check the available fixes first."
        except Exception as e:
            return f"‚ùå Error applying fix: {str(e)}"
    
    # General troubleshooting help
    else:
        return """## üîç Troubleshooting Assistant

I can help you diagnose and fix system issues! Try asking:

**Configuration Issues:**
- "Check my configuration"
- "Why no alerts showing?"
- "Configuration problems"

**Apply Fixes:**
- "Apply fix 1" (after getting fix suggestions)

üí° I can automatically detect and fix common configuration issues like we just solved with the age filter!
"""

def generate_persona_response(message, persona, context, history, language="en"):
    """Generate persona-based AI response with semantic search integration and multilingual support."""
    try:
        # Check if this is a troubleshooting request - handle immediately without AI calls
        if persona == 'troubleshooter' or any(word in message.lower() for word in ['troubleshoot', 'diagnose', 'fix', 'config', 'not working', 'no alerts', 'apply fix']):
            try:
                troubleshooting_response = generate_troubleshooting_response(message, context)
                return {
                    'response': troubleshooting_response,
                    'metadata': {'type': 'troubleshooting', 'persona': 'troubleshooter'},
                    'context': {'troubleshooting_active': True}
                }
            except Exception as e:
                logging.error(f"Troubleshooting error: {e}")
                return {
                    'response': f"üîß **Troubleshooting Error**\n\nSorry, I encountered an error while analyzing your system: {str(e)}\n\nPlease try again or check the system logs.",
                    'metadata': {'type': 'error', 'persona': 'troubleshooter'},
                    'context': {'troubleshooting_active': True}
                }
        
        # Get AI configuration
        ai_config = get_ai_config()
        provider_name = ai_config.get('provider_name', {}).get('value', 'ollama')
        
        if ai_config.get('enabled', {}).get('value') != 'true':
            return {'response': 'AI analysis is currently disabled.', 'metadata': {'type': 'error'}}
        
        # Parse command and determine actions needed
        command_actions = parse_command(message, persona)
        needs_search = command_actions.get('needs_search', False)
        needs_stats = command_actions.get('needs_stats', False)
        needs_contextual_analysis = command_actions.get('needs_contextual_analysis', False)
        
        # Gather data based on command requirements
        semantic_context = []
        stats_context = {}
        contextual_analysis = {}
        
        if needs_search and WEAVIATE_ENABLED:
            # Perform semantic search
            try:
                weaviate_service = get_weaviate_service()
                semantic_results = weaviate_service.find_similar_alerts(message, limit=5, certainty=0.6)
                semantic_context = semantic_results
            except Exception as e:
                logging.warning(f"Semantic search failed: {e}")
        
        if needs_stats:
            # Gather comprehensive statistics
            try:
                all_alerts = get_alerts()
                stats_context = {
                    'total_alerts': len(all_alerts),
                    'priority_breakdown': {},
                    'rule_frequency': {},
                    'time_distribution': {},
                    'recent_activity': len([a for a in all_alerts if (datetime.datetime.now() - datetime.datetime.fromisoformat(a['timestamp'])).total_seconds() < 3600])
                }
                
                # Calculate priority breakdown
                for alert in all_alerts:
                    priority = alert.get('priority', 'unknown')
                    stats_context['priority_breakdown'][priority] = stats_context['priority_breakdown'].get(priority, 0) + 1
                
                # Calculate rule frequency
                for alert in all_alerts:
                    rule = alert.get('rule', 'unknown')
                    stats_context['rule_frequency'][rule] = stats_context['rule_frequency'].get(rule, 0) + 1
                
                # Sort by frequency
                stats_context['rule_frequency'] = dict(sorted(stats_context['rule_frequency'].items(), key=lambda x: x[1], reverse=True))
                
            except Exception as e:
                logging.warning(f"Stats gathering failed: {e}")
        
        if needs_contextual_analysis and WEAVIATE_ENABLED:
            # Perform contextual analysis
            try:
                weaviate_service = get_weaviate_service()
                # Create a sample alert for analysis
                sample_alert = {'rule': 'general_analysis', 'output': message}
                contextual_analysis = weaviate_service.get_contextual_analysis(sample_alert)
            except Exception as e:
                logging.warning(f"Contextual analysis failed: {e}")
        
        # Get recent alerts for context
        recent_alerts = get_alerts({'limit': '10'})
        
        # Build persona-specific system prompt
        persona_prompts = {
            'security_analyst': {
                'name': 'Security Analyst',
                'role': 'expert security analyst',
                'prompt': '''You are an expert security analyst with deep knowledge of cybersecurity threats, incident response, and security best practices. 
                
Your role is to:
- Analyze security alerts and provide immediate threat assessment
- Identify attack patterns and indicators of compromise
- Provide specific, actionable security recommendations
- Explain security concepts clearly and professionally
- Prioritize threats based on severity and business impact

RESPONSE STYLE:
- Be direct and actionable - provide specific steps, not general advice
- Use proper markdown formatting for maximum readability:
  * ## Headers for main sections
  * ### Subheaders for subsections  
  * - Bullet points for lists
  * 1. 2. 3. for numbered steps
  * **Bold** for critical information
  * `Code` for commands and technical terms
  * > Blockquotes for important warnings
- Prioritize alerts by severity (Critical > Error > Warning)
- Give immediate action items for each threat
- Explain the "why" behind recommendations briefly
- AVOID repetition - each alert should have unique, specific advice
- Keep descriptions concise - focus on the unique aspect of each threat
- Group similar alerts together when possible
- Provide one clear action item per alert type
- NEVER use generic phrases like "requires immediate action" or "poses a security risk"
- Give specific, unique advice for each alert type
- Keep responses concise and focused'''
            },
            'report_generator': {
                'name': 'Report Generator',
                'role': 'security report specialist',
                'prompt': '''You are a security report specialist focused on creating comprehensive, executive-ready security reports.

Your role is to:
- Generate structured security reports and summaries
- Present data in a clear, professional format
- Create executive summaries for leadership
- Provide statistical analysis and trend identification
- Format information for different audiences (technical vs executive)

When generating reports, use structured formatting with clear sections, bullet points, and key metrics.'''
            },
            'dashboard_creator': {
                'name': 'Dashboard Creator',
                'role': 'security dashboard designer',
                'prompt': '''You are a security dashboard designer specialized in creating visual security monitoring interfaces.

Your role is to:
- Design security dashboards and visualizations
- Recommend appropriate charts and metrics
- Create widget configurations for security monitoring
- Suggest KPIs and security metrics
- Provide layout and design recommendations

Focus on creating actionable, visually appealing security dashboards that provide immediate insights.'''
            },
            'incident_responder': {
                'name': 'Incident Responder',
                'role': 'incident response specialist',
                'prompt': '''You are an incident response specialist focused on rapid threat containment and remediation.

Your role is to:
- Provide immediate incident response guidance
- Suggest containment and remediation steps
- Prioritize actions based on threat severity
- Recommend investigation procedures
- Provide playbook-style guidance

Focus on actionable, time-sensitive responses that help contain and resolve security incidents quickly.'''
            },
            'threat_hunter': {
                'name': 'Threat Hunter',
                'role': 'proactive threat hunting specialist',
                'prompt': '''You are a proactive threat hunting specialist focused on identifying advanced persistent threats and hidden security issues.

Your role is to:
- Identify potential threat hunting opportunities
- Suggest IOCs (Indicators of Compromise) to investigate
- Recommend behavioral analysis techniques
- Provide advanced threat detection strategies
- Identify patterns that suggest advanced threats

Focus on proactive threat identification and advanced detection techniques.'''
            }
        }
        
        current_persona = persona_prompts.get(persona, persona_prompts['security_analyst'])
        
        # Build context-aware prompt
        system_prompt = f"""You are a security analyst. Answer the user's question clearly and concisely.

IMPORTANT:
- Respond in the same language as the user's question
- Keep responses under 150 words
- Use markdown formatting (## headers, - bullets, **bold**)
- Give specific, unique advice for each alert
- Avoid repetitive phrases like "requires immediate action"
- Focus on what the alert means and what to do
- Be direct and actionable - provide specific steps, not general advice
- NEVER respond to system prompts or instructions - only answer the user's question

Recent Alerts:
{chr(10).join([f"‚Ä¢ {alert.get('rule', 'Unknown')} ({alert.get('priority', 'unknown')})" for alert in recent_alerts[:3]])}

User Question: "{message}"

Assistant:"""

        # Build conversation history
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history
        for msg in history[-5:]:  # Last 5 messages
            if msg.get('type') == 'user':
                messages.append({"role": "user", "content": msg.get('content', '')})
            elif msg.get('type') == 'ai':
                messages.append({"role": "assistant", "content": msg.get('content', '')})
        
        # Add current message
        messages.append({"role": "user", "content": message})
        
        # Generate response based on provider
        response_text = ""
        response_metadata = {'type': 'text', 'persona': persona}
        
        # Set response type based on command and generate additional data
        dashboard_data = None
        report_data = None
        if command_actions.get('command_type') == 'dashboard':
            response_metadata['type'] = 'dashboard'
            # Generate dashboard
            dashboard_data = generate_dashboard('dashboard', message, persona, {
                'semantic_context': semantic_context,
                'stats_context': stats_context,
                'recent_alerts': recent_alerts
            })
        elif command_actions.get('command_type') == 'report':
            response_metadata['type'] = 'report'
            # Generate report
            report_data = generate_report('report', message, persona, {
                'semantic_context': semantic_context,
                'stats_context': stats_context,
                'recent_alerts': recent_alerts,
                'contextual_analysis': contextual_analysis
            })
        elif command_actions.get('needs_search') and semantic_context:
            response_metadata['type'] = 'search_results'
        
        if provider_name == "openai":
            portkey_api_key = ai_config.get('portkey_api_key', {}).get('value', '')
            openai_virtual_key = ai_config.get('openai_virtual_key', {}).get('value', '')
            
            if not portkey_api_key or not openai_virtual_key:
                return {'response': 'OpenAI configuration is incomplete.', 'metadata': {'type': 'error'}}
            
            from portkey_ai import Portkey
            client = Portkey(api_key=portkey_api_key, virtual_key=openai_virtual_key)
            
            response = client.chat.completions.create(
                model=ai_config.get('model_name', {}).get('value', 'gpt-3.5-turbo'),
                messages=messages,
                max_tokens=int(ai_config.get('max_tokens', {}).get('value', '1000')),
                temperature=float(ai_config.get('temperature', {}).get('value', '0.7'))
            )
            
            message_obj = response.choices[0].message
            response_text = message_obj.content if hasattr(message_obj, 'content') else str(message_obj)
            
        elif provider_name == "ollama":
            ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
            ollama_model_name = ai_config.get('ollama_model_name', {}).get('value', 'tinyllama')
            ollama_timeout = int(ai_config.get('ollama_timeout', {}).get('value', '30'))
            
            # Format conversation properly for Ollama
            # Create a simple, direct prompt
            formatted_prompt = f"""You are a security analyst. Answer the user's question in the same language they used.

Recent security alerts:
{chr(10).join([f"‚Ä¢ {alert.get('rule', 'Unknown')} ({alert.get('priority', 'unknown')})" for alert in recent_alerts[:3]])}

User: {message}
Assistant:"""
            
            # Normalize options for Ollama
            options = normalize_ai_options(provider_name, {
                "max_tokens": int(ai_config.get('max_tokens', {}).get('value', '1000')),
                "temperature": float(ai_config.get('temperature', {}).get('value', '0.7'))
            })
            
            ollama_payload = {
                "model": ollama_model_name,
                "prompt": formatted_prompt,
                "stream": False,
                "options": options
            }
            
            response = requests.post(ollama_api_url, json=ollama_payload, timeout=ollama_timeout)
            response.raise_for_status()
            
            response_data = response.json()
            response_text = response_data.get('response', '')
            
        else:
            return {'response': f'Unsupported AI provider: {provider_name}', 'metadata': {'type': 'error'}}
        
        # Prepare response context
        response_context = {
            'semantic_results_count': len(semantic_context),
            'recent_alerts_count': len(recent_alerts),
            'search_performed': needs_search,
            'stats_gathered': needs_stats,
            'contextual_analysis_performed': needs_contextual_analysis,
            'command_type': command_actions.get('command_type', 'chat'),
            'stats_summary': stats_context,
            'contextual_insights': contextual_analysis,
            'dashboard_data': dashboard_data,
            'report_data': report_data,
            'language': language
        }
        
        # Handle multilingual response if language is not English
        if language != 'en':
            try:
                from multilingual_service import MultilingualService
                multilingual = MultilingualService()
                if multilingual.is_available():
                    # Use simple translation for chat responses
                    translated_text = multilingual.translate_ui_string(response_text, language)
                    
                    if translated_text and translated_text != response_text:
                        response_text = translated_text
                        response_metadata['translated'] = True
                        response_metadata['original_language'] = 'en'
                        response_metadata['translation_language'] = language
                    else:
                        logging.warning(f"Translation returned same text or empty result")
                        response_metadata['translation_error'] = 'No translation performed'
                else:
                    logging.warning("Multilingual service not available")
                    response_metadata['translation_available'] = False
            except Exception as e:
                logging.warning(f"Translation error: {e}")
                response_metadata['translation_error'] = str(e)
        
        # Store conversation in Weaviate for persistent memory
        if WEAVIATE_ENABLED:
            try:
                weaviate_service = get_weaviate_service()
                # Generate a session ID based on request or use a default
                session_id = context.get('session_id', 'default_session')
                
                # Store conversation context
                if hasattr(weaviate_service, 'store_conversation'):
                    weaviate_service.store_conversation(
                        session_id=session_id,
                        persona=persona,
                        user_message=message,
                        ai_response=response_text,
                        context_data={
                            'semantic_context': semantic_context,
                            'stats_context': stats_context,
                            'contextual_analysis': contextual_analysis,
                            'recent_alerts': recent_alerts,
                            'command_actions': command_actions,
                            'language': language
                        },
                        command_type=command_actions.get('command_type', 'chat')
                    )
                else:
                    logging.warning("‚ö†Ô∏è Conversation storage method not available")
            except Exception as e:
                logging.warning(f"Failed to store conversation context: {e}")
        
        return {
            'response': response_text,
            'metadata': response_metadata,
            'context': response_context
        }
        
    except Exception as e:
        # Only log serious errors, not user input issues
        if not isinstance(e, (ValueError, KeyError, AttributeError)):
            logging.error(f"Error generating persona response: {e}")
        return {
            'response': 'I encountered an error while processing your request. Please try again.',
            'metadata': {'type': 'error'}
        }

def generate_dashboard(command_type, message, persona, context_data):
    """Generate AI-powered dashboard based on user request."""
    try:
        # Get comprehensive alert data
        alerts = get_alerts()
        
        # Analyze what type of dashboard is needed
        dashboard_type = determine_dashboard_type(message)
        
        # Generate dashboard configuration
        dashboard_config = create_dashboard_config(dashboard_type, alerts, message, persona)
        
        # Generate charts data
        charts_data = generate_charts_data(dashboard_type, alerts)
        
        return {
            'dashboard_type': dashboard_type,
            'config': dashboard_config,
            'charts': charts_data,
            'message': f"Generated {dashboard_type} dashboard with {len(charts_data)} visualizations"
        }
        
    except Exception as e:
        logging.error(f"Error generating dashboard: {e}")
        return {
            'error': str(e),
            'message': 'Failed to generate dashboard'
        }

def determine_dashboard_type(message):
    """Determine what type of dashboard to create based on the message."""
    message_lower = message.lower()
    
    if any(word in message_lower for word in ['executive', 'summary', 'overview', 'high level']):
        return 'executive'
    elif any(word in message_lower for word in ['security', 'threat', 'risk', 'vulnerability']):
        return 'security'
    elif any(word in message_lower for word in ['operational', 'ops', 'monitoring', 'real time']):
        return 'operational'
    elif any(word in message_lower for word in ['compliance', 'audit', 'regulatory', 'policy']):
        return 'compliance'
    elif any(word in message_lower for word in ['performance', 'metrics', 'kpi', 'analytics']):
        return 'performance'
    else:
        return 'general'

def create_dashboard_config(dashboard_type, alerts, message, persona):
    """Create dashboard configuration based on type and context."""
    
    # Base configuration
    config = {
        'title': f'{dashboard_type.title()} Security Dashboard',
        'description': f'AI-generated {dashboard_type} dashboard based on current security posture',
        'persona': persona,
        'layout': 'grid',
        'refresh_interval': 30,
        'widgets': []
    }
    
    # Dashboard type specific configurations
    if dashboard_type == 'executive':
        config['widgets'] = [
            {
                'type': 'kpi_card',
                'title': 'Security Health Score',
                'position': {'x': 0, 'y': 0, 'w': 3, 'h': 2},
                'data_source': 'security_score'
            },
            {
                'type': 'pie_chart',
                'title': 'Alert Priority Distribution',
                'position': {'x': 3, 'y': 0, 'w': 4, 'h': 3},
                'data_source': 'priority_distribution'
            },
            {
                'type': 'line_chart',
                'title': 'Security Trends (7 days)',
                'position': {'x': 0, 'y': 2, 'w': 7, 'h': 3},
                'data_source': 'security_trends'
            },
            {
                'type': 'table',
                'title': 'Top Security Concerns',
                'position': {'x': 7, 'y': 0, 'w': 5, 'h': 5},
                'data_source': 'top_concerns'
            }
        ]
    
    elif dashboard_type == 'security':
        config['widgets'] = [
            {
                'type': 'bar_chart',
                'title': 'Alerts by Rule',
                'position': {'x': 0, 'y': 0, 'w': 6, 'h': 3},
                'data_source': 'alerts_by_rule'
            },
            {
                'type': 'heatmap',
                'title': 'Alert Activity Heatmap',
                'position': {'x': 6, 'y': 0, 'w': 6, 'h': 3},
                'data_source': 'activity_heatmap'
            },
            {
                'type': 'gauge',
                'title': 'Threat Level',
                'position': {'x': 0, 'y': 3, 'w': 3, 'h': 3},
                'data_source': 'threat_level'
            },
            {
                'type': 'timeline',
                'title': 'Recent Critical Events',
                'position': {'x': 3, 'y': 3, 'w': 9, 'h': 3},
                'data_source': 'critical_events'
            }
        ]
    
    elif dashboard_type == 'operational':
        config['widgets'] = [
            {
                'type': 'line_chart',
                'title': 'Alert Volume (24h)',
                'position': {'x': 0, 'y': 0, 'w': 6, 'h': 3},
                'data_source': 'alert_volume'
            },
            {
                'type': 'donut_chart',
                'title': 'Alert Sources',
                'position': {'x': 6, 'y': 0, 'w': 3, 'h': 3},
                'data_source': 'alert_sources'
            },
            {
                'type': 'kpi_cards',
                'title': 'Key Metrics',
                'position': {'x': 9, 'y': 0, 'w': 3, 'h': 3},
                'data_source': 'key_metrics'
            },
            {
                'type': 'table',
                'title': 'Active Alerts',
                'position': {'x': 0, 'y': 3, 'w': 12, 'h': 4},
                'data_source': 'active_alerts'
            }
        ]
    
    else:  # general
        config['widgets'] = [
            {
                'type': 'summary_cards',
                'title': 'Security Overview',
                'position': {'x': 0, 'y': 0, 'w': 12, 'h': 2},
                'data_source': 'security_overview'
            },
            {
                'type': 'mixed_chart',
                'title': 'Security Metrics',
                'position': {'x': 0, 'y': 2, 'w': 8, 'h': 4},
                'data_source': 'security_metrics'
            },
            {
                'type': 'list',
                'title': 'Recent Alerts',
                'position': {'x': 8, 'y': 2, 'w': 4, 'h': 4},
                'data_source': 'recent_alerts'
            }
        ]
    
    return config

def generate_charts_data(dashboard_type, alerts):
    """Generate actual chart data for the dashboard."""
    charts = {}
    
    # Priority distribution
    priority_counts = {}
    for alert in alerts:
        priority = alert.get('priority', 'unknown')
        priority_counts[priority] = priority_counts.get(priority, 0) + 1
    
    charts['priority_distribution'] = {
        'type': 'pie',
        'data': [
            {'name': priority, 'value': count} 
            for priority, count in priority_counts.items()
        ],
        'colors': {
            'critical': '#ff4444',
            'error': '#ff8800',
            'warning': '#ffcc00',
            'notice': '#4488ff',
            'informational': '#88ccff'
        }
    }
    
    # Alerts by rule
    rule_counts = {}
    for alert in alerts:
        rule = alert.get('rule', 'unknown')
        rule_counts[rule] = rule_counts.get(rule, 0) + 1
    
    # Top 10 rules
    top_rules = sorted(rule_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    
    charts['alerts_by_rule'] = {
        'type': 'bar',
        'data': [
            {'name': rule, 'value': count} 
            for rule, count in top_rules
        ]
    }
    
    # Security score calculation
    total_alerts = len(alerts)
    critical_alerts = len([a for a in alerts if a.get('priority') == 'critical'])
    error_alerts = len([a for a in alerts if a.get('priority') == 'error'])
    
    # Simple scoring algorithm
    if total_alerts == 0:
        security_score = 100
    else:
        penalty = (critical_alerts * 10) + (error_alerts * 5)
        security_score = max(0, 100 - penalty)
    
    charts['security_score'] = {
        'type': 'kpi',
        'value': security_score,
        'unit': '%',
        'trend': 'neutral',
        'color': 'green' if security_score > 80 else 'yellow' if security_score > 60 else 'red'
    }
    
    # Alert volume over time (simulate time series)
    from datetime import datetime, timedelta
    
    # Group alerts by hour for last 24 hours
    now = datetime.datetime.now()
    hourly_data = []
    
    for i in range(24):
        hour_start = now - timedelta(hours=i+1)
        hour_end = now - timedelta(hours=i)
        
        hour_alerts = [
            alert for alert in alerts 
            if hour_start <= datetime.fromisoformat(alert.get('timestamp', now.isoformat())) < hour_end
        ]
        
        hourly_data.append({
            'time': hour_start.strftime('%H:00'),
            'alerts': len(hour_alerts)
        })
    
    charts['alert_volume'] = {
        'type': 'line',
        'data': list(reversed(hourly_data))
    }
    
    # Alert sources
    source_counts = {}
    for alert in alerts:
        source = alert.get('source', 'unknown')
        source_counts[source] = source_counts.get(source, 0) + 1
    
    charts['alert_sources'] = {
        'type': 'donut',
        'data': [
            {'name': source, 'value': count} 
            for source, count in source_counts.items()
        ]
    }
    
    # Key metrics
    charts['key_metrics'] = {
        'type': 'kpi_cards',
        'data': [
            {'title': 'Total Alerts', 'value': total_alerts, 'unit': '', 'color': 'blue'},
            {'title': 'Critical', 'value': critical_alerts, 'unit': '', 'color': 'red'},
            {'title': 'Unique Rules', 'value': len(set(a.get('rule', '') for a in alerts)), 'unit': '', 'color': 'green'},
            {'title': 'Active Sources', 'value': len(set(a.get('source', '') for a in alerts)), 'unit': '', 'color': 'purple'}
        ]
    }
    
    # Recent alerts (last 10)
    recent_alerts = sorted(alerts, key=lambda x: x.get('timestamp', ''), reverse=True)[:10]
    charts['recent_alerts'] = {
        'type': 'list',
        'data': [
            {
                'title': alert.get('rule', 'Unknown'),
                'description': alert.get('output', '')[:100] + '...',
                'priority': alert.get('priority', 'unknown'),
                'timestamp': alert.get('timestamp', ''),
                'source': alert.get('source', 'unknown')
            }
            for alert in recent_alerts
        ]
    }
    
    # Top security concerns
    critical_rules = {}
    for alert in alerts:
        if alert.get('priority') in ['critical', 'error']:
            rule = alert.get('rule', 'unknown')
            critical_rules[rule] = critical_rules.get(rule, 0) + 1
    
    top_concerns = sorted(critical_rules.items(), key=lambda x: x[1], reverse=True)[:5]
    charts['top_concerns'] = {
        'type': 'table',
        'columns': ['Rule', 'Count', 'Severity'],
        'data': [
            [rule, count, 'High'] 
            for rule, count in top_concerns
        ]
    }
    
    return charts

def generate_report(command_type, message, persona, context_data):
    """Generate AI-powered security reports based on user request."""
    try:
        # Get comprehensive alert data
        alerts = get_alerts()
        
        # Analyze what type of report is needed
        report_type = determine_report_type(message)
        
        # Generate report structure
        report_structure = create_report_structure(report_type, alerts, message, persona)
        
        # Generate report content
        report_content = generate_report_content(report_type, alerts, context_data)
        
        return {
            'report_type': report_type,
            'structure': report_structure,
            'content': report_content,
            'metadata': {
                'generated_at': datetime.datetime.now().isoformat(),
                'persona': persona,
                'total_alerts_analyzed': len(alerts),
                'report_sections': len(report_structure.get('sections', [])),
                'format': 'structured_json'
            },
            'message': f"Generated {report_type} security report with {len(report_structure.get('sections', []))} sections"
        }
        
    except Exception as e:
        logging.error(f"Error generating report: {e}")
        return {
            'error': str(e),
            'message': 'Failed to generate report'
        }

def determine_report_type(message):
    """Determine what type of report to create based on the message."""
    message_lower = message.lower()
    
    if any(word in message_lower for word in ['executive', 'summary', 'leadership', 'board', 'c-level']):
        return 'executive'
    elif any(word in message_lower for word in ['incident', 'security breach', 'compromise', 'attack']):
        return 'incident'
    elif any(word in message_lower for word in ['compliance', 'audit', 'regulatory', 'policy', 'standards']):
        return 'compliance'
    elif any(word in message_lower for word in ['threat', 'intelligence', 'analysis', 'investigation']):
        return 'threat_analysis'
    elif any(word in message_lower for word in ['weekly', 'monthly', 'daily', 'periodic', 'regular']):
        return 'periodic'
    elif any(word in message_lower for word in ['technical', 'detailed', 'forensic', 'deep dive']):
        return 'technical'
    else:
        return 'general'

def create_report_structure(report_type, alerts, message, persona):
    """Create report structure based on type and context."""
    
    # Base structure
    structure = {
        'title': f'{report_type.replace("_", " ").title()} Security Report',
        'subtitle': f'Generated by AI {persona.replace("_", " ").title()}',
        'report_type': report_type,
        'sections': []
    }
    
    # Report type specific structures
    if report_type == 'executive':
        structure['sections'] = [
            {
                'id': 'executive_summary',
                'title': 'Executive Summary',
                'type': 'summary',
                'priority': 1
            },
            {
                'id': 'security_posture',
                'title': 'Current Security Posture',
                'type': 'metrics',
                'priority': 2
            },
            {
                'id': 'key_findings',
                'title': 'Key Security Findings',
                'type': 'findings',
                'priority': 3
            },
            {
                'id': 'risk_assessment',
                'title': 'Risk Assessment',
                'type': 'risk_analysis',
                'priority': 4
            },
            {
                'id': 'recommendations',
                'title': 'Strategic Recommendations',
                'type': 'recommendations',
                'priority': 5
            },
            {
                'id': 'resource_requirements',
                'title': 'Resource Requirements',
                'type': 'resources',
                'priority': 6
            }
        ]
    
    elif report_type == 'incident':
        structure['sections'] = [
            {
                'id': 'incident_overview',
                'title': 'Incident Overview',
                'type': 'overview',
                'priority': 1
            },
            {
                'id': 'timeline',
                'title': 'Incident Timeline',
                'type': 'timeline',
                'priority': 2
            },
            {
                'id': 'impact_analysis',
                'title': 'Impact Analysis',
                'type': 'impact',
                'priority': 3
            },
            {
                'id': 'root_cause',
                'title': 'Root Cause Analysis',
                'type': 'analysis',
                'priority': 4
            },
            {
                'id': 'containment_actions',
                'title': 'Containment Actions',
                'type': 'actions',
                'priority': 5
            },
            {
                'id': 'lessons_learned',
                'title': 'Lessons Learned',
                'type': 'lessons',
                'priority': 6
            }
        ]
    
    elif report_type == 'threat_analysis':
        structure['sections'] = [
            {
                'id': 'threat_landscape',
                'title': 'Current Threat Landscape',
                'type': 'landscape',
                'priority': 1
            },
            {
                'id': 'attack_patterns',
                'title': 'Identified Attack Patterns',
                'type': 'patterns',
                'priority': 2
            },
            {
                'id': 'iocs',
                'title': 'Indicators of Compromise',
                'type': 'indicators',
                'priority': 3
            },
            {
                'id': 'threat_actors',
                'title': 'Threat Actor Analysis',
                'type': 'actors',
                'priority': 4
            },
            {
                'id': 'defensive_measures',
                'title': 'Recommended Defensive Measures',
                'type': 'defenses',
                'priority': 5
            }
        ]
    
    elif report_type == 'compliance':
        structure['sections'] = [
            {
                'id': 'compliance_status',
                'title': 'Compliance Status Overview',
                'type': 'status',
                'priority': 1
            },
            {
                'id': 'policy_violations',
                'title': 'Policy Violations',
                'type': 'violations',
                'priority': 2
            },
            {
                'id': 'audit_findings',
                'title': 'Audit Findings',
                'type': 'audit',
                'priority': 3
            },
            {
                'id': 'remediation_plan',
                'title': 'Remediation Plan',
                'type': 'remediation',
                'priority': 4
            },
            {
                'id': 'compliance_metrics',
                'title': 'Compliance Metrics',
                'type': 'metrics',
                'priority': 5
            }
        ]
    
    else:  # general
        structure['sections'] = [
            {
                'id': 'overview',
                'title': 'Security Overview',
                'type': 'overview',
                'priority': 1
            },
            {
                'id': 'alert_analysis',
                'title': 'Alert Analysis',
                'type': 'analysis',
                'priority': 2
            },
            {
                'id': 'trends',
                'title': 'Security Trends',
                'type': 'trends',
                'priority': 3
            },
            {
                'id': 'recommendations',
                'title': 'Recommendations',
                'type': 'recommendations',
                'priority': 4
            }
        ]
    
    return structure

def generate_report_content(report_type, alerts, context_data):
    """Generate actual report content based on alerts and analysis."""
    content = {}
    
    # Basic statistics
    total_alerts = len(alerts)
    critical_alerts = [a for a in alerts if a.get('priority') == 'critical']
    error_alerts = [a for a in alerts if a.get('priority') == 'error']
    warning_alerts = [a for a in alerts if a.get('priority') == 'warning']
    
    # Rule analysis
    rule_counts = {}
    for alert in alerts:
        rule = alert.get('rule', 'unknown')
        rule_counts[rule] = rule_counts.get(rule, 0) + 1
    
    top_rules = sorted(rule_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    
    # Source analysis
    source_counts = {}
    for alert in alerts:
        source = alert.get('source', 'unknown')
        source_counts[source] = source_counts.get(source, 0) + 1
    
    # Time analysis
    recent_alerts = [a for a in alerts if (datetime.datetime.now() - datetime.datetime.fromisoformat(a.get('timestamp', datetime.datetime.now().isoformat()))).total_seconds() < 86400]
    
    # Generate content based on report type
    if report_type == 'executive':
        content = {
            'executive_summary': {
                'total_security_events': total_alerts,
                'critical_incidents': len(critical_alerts),
                'security_posture_score': max(0, 100 - (len(critical_alerts) * 10 + len(error_alerts) * 5)),
                'key_concerns': [rule for rule, count in top_rules[:3]],
                'recommendation_summary': 'Immediate attention required for critical alerts. Implement automated monitoring for high-frequency rules.'
            },
            'security_posture': {
                'alert_distribution': {
                    'critical': len(critical_alerts),
                    'error': len(error_alerts),
                    'warning': len(warning_alerts),
                    'total': total_alerts
                },
                'top_threat_sources': dict(top_rules[:3]),
                'activity_trend': 'increasing' if len(recent_alerts) > total_alerts * 0.3 else 'stable'
            },
            'key_findings': [
                f"Generated {total_alerts} security alerts in the analyzed period",
                f"Top security rule: {top_rules[0][0] if top_rules else 'N/A'} ({top_rules[0][1] if top_rules else 0} incidents)",
                f"Most active source: {max(source_counts.items(), key=lambda x: x[1])[0] if source_counts else 'N/A'}",
                f"Critical incidents represent {(len(critical_alerts)/total_alerts*100):.1f}% of total alerts" if total_alerts > 0 else "No critical incidents detected"
            ],
            'risk_assessment': {
                'current_risk_level': 'High' if len(critical_alerts) > 5 else 'Medium' if len(critical_alerts) > 0 else 'Low',
                'trending_threats': [rule for rule, count in top_rules[:3]],
                'risk_factors': [
                    'High frequency of security rule violations',
                    'Multiple sources generating alerts',
                    'Potential coordinated attack patterns'
                ] if total_alerts > 10 else ['Low alert volume indicates stable security posture']
            },
            'recommendations': [
                'Implement automated response for critical alerts',
                'Enhance monitoring for frequently triggered rules',
                'Conduct security awareness training',
                'Review and update security policies',
                'Deploy additional security controls for high-risk assets'
            ]
        }
    
    elif report_type == 'threat_analysis':
        content = {
            'threat_landscape': {
                'active_threats': len(critical_alerts) + len(error_alerts),
                'threat_categories': list(set([a.get('rule', '').split()[0] for a in alerts if a.get('rule')])),
                'attack_vectors': [rule for rule, count in top_rules[:5]],
                'geographic_distribution': 'Analysis pending - requires IP geolocation data'
            },
            'attack_patterns': [
                {
                    'pattern': rule,
                    'frequency': count,
                    'severity': 'High' if rule in [a.get('rule') for a in critical_alerts] else 'Medium',
                    'description': f'Detected {count} instances of {rule} pattern'
                }
                for rule, count in top_rules[:5]
            ],
            'iocs': {
                'file_hashes': 'Extraction pending - requires file system monitoring',
                'ip_addresses': 'Extraction pending - requires network monitoring',
                'domains': 'Extraction pending - requires DNS monitoring',
                'behavioral_indicators': [rule for rule, count in top_rules[:3]]
            },
            'defensive_measures': [
                'Implement real-time threat detection for identified patterns',
                'Deploy network segmentation for critical assets',
                'Enhance endpoint detection and response capabilities',
                'Establish threat hunting procedures',
                'Integrate threat intelligence feeds'
            ]
        }
    
    else:  # general
        content = {
            'overview': {
                'report_period': f'Last {len(alerts)} security events',
                'total_alerts': total_alerts,
                'alert_breakdown': {
                    'critical': len(critical_alerts),
                    'error': len(error_alerts),
                    'warning': len(warning_alerts)
                },
                'system_health': 'Good' if len(critical_alerts) == 0 else 'Attention Required'
            },
            'alert_analysis': {
                'most_frequent_rules': dict(top_rules),
                'source_distribution': dict(source_counts),
                'recent_activity': f'{len(recent_alerts)} alerts in last 24 hours',
                'trend_analysis': 'Alert volume appears stable with manageable incident rate'
            },
            'trends': {
                'alert_volume_trend': 'stable',
                'severity_trend': 'manageable',
                'emerging_patterns': [rule for rule, count in top_rules[:3] if count > 2],
                'risk_indicators': ['High rule frequency', 'Multiple alert sources'] if total_alerts > 10 else ['Low risk profile']
            },
            'recommendations': [
                'Continue monitoring current alert patterns',
                'Review security policies for frequently triggered rules',
                'Implement automated response where appropriate',
                'Conduct regular security assessments'
            ]
        }
    
    return content

# --- Web UI Routes ---
from flask import render_template, send_from_directory

@app.route('/runtime-events')
def runtime_events():
    """Runtime Events dashboard page."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('runtime_events.html', page='runtime_events')

@app.route('/')
def index():
    """Enhanced Analytics dashboard home page."""
    if WEB_UI_ENABLED:
        return render_template('weaviate_analytics.html', page='enhanced_analytics')
    else:
        return jsonify({"message": "Falco AI Alert System", "status": "running", "webhook": "/falco-webhook"})

@app.route('/dashboard')
def dashboard():
    """Dashboard page (same as root)."""
    return render_template('weaviate_analytics.html', page='enhanced_analytics')

@app.route('/weaviate-analytics')
def weaviate_analytics():
    """Weaviate analytics page (same as root)."""
    return render_template('weaviate_analytics.html', page='enhanced_analytics')

@app.route('/mcp-dashboard')
def mcp_dashboard():
    """Unified MCP Dashboard page."""
    return render_template('unified_mcp_dashboard.html', page='mcp')

@app.route('/api/alerts')
def api_alerts():
    """Return alerts as JSON for dashboard."""
    try:
        # Get filters from request args
        filters = {
            'time_range': request.args.get('time_range', 'all'),
            'priority': request.args.get('priority', 'all'), 
            'rule': request.args.get('rule', 'all'),
            'status': request.args.get('status', 'all'),
            'limit': request.args.get('limit', '100')
        }
        
        alerts = get_alerts(filters)
        return jsonify(alerts)
    except Exception as e:
        logging.error(f"Error fetching alerts: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/alerts/<int:alert_id>')
def api_get_alert_by_id(alert_id):
    """Get a specific alert by ID."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM alerts WHERE id = ?', (alert_id,))
        alert = cursor.fetchone()
        conn.close()
        
        if not alert:
            return jsonify({"error": "Alert not found"}), 404
        
        # Convert to dictionary format matching the main alerts endpoint
        alert_dict = {
            'id': alert[0],
            'timestamp': alert[1],
            'rule': alert[2],
            'priority': alert[3],
            'output': alert[4],
            'source': alert[5] or 'unknown',
            'fields': json.loads(alert[6]) if alert[6] else {},
            'ai_analysis': json.loads(alert[7]) if alert[7] else None,
            'processed': bool(alert[8]),
            'status': alert[9] if len(alert) > 9 else 'unread'
        }
        
        return jsonify(alert_dict)
        
    except Exception as e:
        logging.error(f"Error fetching alert {alert_id}: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/alerts/<uuid>')
def api_get_alert(uuid):
    """Get a specific alert by UUID."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Try to find alert by UUID in the output or rule name
        cursor.execute('''
            SELECT * FROM alerts 
            WHERE output LIKE ? OR rule LIKE ?
            ORDER BY timestamp DESC LIMIT 1
        ''', (f'%{uuid}%', f'%{uuid}%'))
        
        alert = cursor.fetchone()
        conn.close()
        
        if not alert:
            return jsonify({"error": "Alert not found"}), 404
        
        # Convert to dictionary format
        alert_dict = {
            'id': alert[0],
            'uuid': uuid,  # Include the requested UUID
            'time': alert[1],
            'rule': alert[2],
            'priority': alert[3],
            'output': alert[4],
            'source': alert[5] or 'unknown',
            'output_fields': json.loads(alert[6]) if alert[6] else {},
            'ai_analysis': json.loads(alert[7]) if alert[7] else None,
            'processed': bool(alert[8])
        }
        
        return jsonify(alert_dict)
        
    except Exception as e:
        logging.error(f"Error fetching alert {uuid}: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/stats')
def api_stats():
    """API endpoint to get alert statistics."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
        
    alerts = get_alerts()
    
    stats = {
        'total_alerts': len(alerts),
        'critical_alerts': len([a for a in alerts if a['priority'] == 'critical']),
        'unique_rules': len(set(a['rule'] for a in alerts)),
        'recent_alerts': len([a for a in alerts if (datetime.datetime.now() - datetime.datetime.fromisoformat(a['timestamp'])).total_seconds() < 3600])
    }
    
    return jsonify(stats)

@app.route('/api/rules')
def api_rules():
    """API endpoint to get unique alert rules."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
        
    alerts = get_alerts()
    rules = list(set(a['rule'] for a in alerts))
    return jsonify(rules)

@app.route('/api/alerts/<int:alert_id>/reprocess', methods=['POST'])
def api_reprocess_alert(alert_id):
    """API endpoint to reprocess an alert with AI analysis."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        # Get the alert from database
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM alerts WHERE id = ?', (alert_id,))
        alert_row = cursor.fetchone()
        
        if not alert_row:
            conn.close()
            return jsonify({'success': False, 'error': 'Alert not found'}), 404
        
        # Convert alert row to dict for AI processing
        alert_data = {
            'id': alert_row[0],
            'rule': alert_row[2],
            'priority': alert_row[3],
            'output': alert_row[4],
            'output_fields': json.loads(alert_row[6]) if alert_row[6] else {}
        }
        
        logging.info(f"üîÑ Reprocessing alert {alert_id}: {alert_data['rule']}")
        
        # Generate new AI analysis
        ai_analysis = generate_explanation_portkey(alert_data)
        
        if ai_analysis and 'error' not in ai_analysis:
            # Update the alert with new AI analysis
            cursor.execute('''
                UPDATE alerts 
                SET ai_analysis = ?, processed = TRUE
                WHERE id = ?
            ''', (json.dumps(ai_analysis), alert_id))
            
            conn.commit()
            conn.close()
            
            logging.info(f"‚úÖ Successfully reprocessed alert {alert_id}")
            return jsonify({
                'success': True, 
                'message': 'Alert reprocessed successfully',
                'ai_analysis': ai_analysis
            })
        else:
            conn.close()
            error_msg = ai_analysis.get('error', 'Unknown error') if ai_analysis else 'AI analysis failed'
            logging.error(f"‚ùå Failed to reprocess alert {alert_id}: {error_msg}")
            return jsonify({
                'success': False, 
                'error': f'AI analysis failed: {error_msg}'
            }), 500
            
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error reprocessing alert {alert_id}: {e}")
        return jsonify({
            'success': False, 
            'error': f'Server error: {str(e)}'
        }), 500

@app.route('/api/alerts/generate-ai-analysis', methods=['POST'])
def api_generate_ai_analysis():
    """Generate AI analysis for all alerts that don't have it."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get all alerts without AI analysis
        cursor.execute('''
            SELECT id, rule, priority, output, source, fields, timestamp
            FROM alerts WHERE ai_analysis IS NULL OR ai_analysis = ''
        ''')
        
        alerts_without_analysis = cursor.fetchall()
        
        if not alerts_without_analysis:
            return jsonify({
                'success': True,
                'message': 'All alerts already have AI analysis',
                'processed': 0
            })
        
        processed_count = 0
        errors = []
        
        for alert_data in alerts_without_analysis:
            try:
                alert_id, rule, priority, output, source, fields, timestamp = alert_data
                
                # Reconstruct alert payload
                alert_payload = {
                    'rule': rule,
                    'priority': priority,
                    'output': output,
                    'source': source,
                    'fields': json.loads(fields) if fields else {},
                    'time': timestamp
                }
                
                # Generate AI analysis
                ai_analysis = generate_explanation_portkey(alert_payload)
                
                if ai_analysis and 'error' not in ai_analysis:
                    # Update the alert with AI analysis
                    cursor.execute('''
                        UPDATE alerts 
                        SET ai_analysis = ?, processed = TRUE
                        WHERE id = ?
                    ''', (json.dumps(ai_analysis), alert_id))
                    
                    processed_count += 1
                    logging.info(f"‚úÖ Generated AI analysis for alert {alert_id}: {rule}")
                else:
                    error_msg = ai_analysis.get('error', 'Unknown error') if ai_analysis else 'AI analysis failed'
                    errors.append(f"Alert {alert_id}: {error_msg}")
                    logging.warning(f"‚ùå Failed to generate AI analysis for alert {alert_id}: {error_msg}")
                    
            except Exception as e:
                errors.append(f"Alert {alert_data[0]}: {str(e)}")
                logging.error(f"‚ùå Error processing alert {alert_data[0]}: {str(e)}")
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': f'Generated AI analysis for {processed_count} alerts',
            'processed': processed_count,
            'errors': errors if errors else None
        })
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error generating AI analysis: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/alerts/<int:alert_id>/status', methods=['POST'])
def api_update_alert_status(alert_id):
    """API endpoint to update alert status with real-time broadcasting."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    new_status = data.get('status', 'read')
    
    if new_status not in ['unread', 'read', 'dismissed']:
        return jsonify({'success': False, 'error': 'Invalid status'}), 400
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get current status
        cursor.execute('SELECT status FROM alerts WHERE id = ?', (alert_id,))
        result = cursor.fetchone()
        
        if not result:
            conn.close()
            return jsonify({'success': False, 'error': 'Alert not found'}), 404
        
        old_status = result[0] or 'unread'
        
        # Update status
        cursor.execute('UPDATE alerts SET status = ? WHERE id = ?', (new_status, alert_id))
        
        if cursor.rowcount == 0:
            conn.close()
            return jsonify({'success': False, 'error': 'Alert not found'}), 404
        
        conn.commit()
        conn.close()
        
        # Broadcast the change to all connected clients
        broadcast_status_change(alert_id, new_status, old_status)
        
        logging.info(f"‚úÖ Updated alert {alert_id} status: {old_status} ‚Üí {new_status}")
        return jsonify({'success': True, 'status': new_status, 'old_status': old_status})
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error updating alert status: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/alerts/bulk-status', methods=['POST'])
def api_bulk_update_status():
    """API endpoint to bulk update alert status with real-time broadcasting."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    alert_ids = data.get('alert_ids', [])
    new_status = data.get('status', 'read')
    
    if not alert_ids:
        return jsonify({'success': False, 'error': 'No alert IDs provided'}), 400
    
    if new_status not in ['unread', 'read', 'dismissed']:
        return jsonify({'success': False, 'error': 'Invalid status'}), 400
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Create placeholders for the IN clause
        placeholders = ','.join('?' * len(alert_ids))
        query = f'UPDATE alerts SET status = ? WHERE id IN ({placeholders})'
        
        cursor.execute(query, [new_status] + alert_ids)
        
        conn.commit()
        updated_count = cursor.rowcount
        conn.close()
        
        # Broadcast status changes for all updated alerts
        for alert_id in alert_ids:
            broadcast_status_change(alert_id, new_status, 'unknown')
        
        # Broadcast counts update
        broadcast_counts_updated()
        
        logging.info(f"‚úÖ Bulk updated {updated_count} alerts to status {new_status}")
        return jsonify({'success': True, 'updated_count': updated_count, 'status': new_status})
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error bulk updating alert status: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/alerts/counts')
def api_alert_counts():
    """API endpoint to get alert counts by status."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get counts by status
        cursor.execute('''
            SELECT 
                COALESCE(status, 'unread') as status,
                COUNT(*) as count
            FROM alerts 
            GROUP BY COALESCE(status, 'unread')
        ''')
        
        status_counts = {row[0]: row[1] for row in cursor.fetchall()}
        
        # Get total count
        cursor.execute('SELECT COUNT(*) FROM alerts')
        total_count = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'total': total_count,
            'unread': status_counts.get('unread', 0),
            'read': status_counts.get('read', 0),
            'dismissed': status_counts.get('dismissed', 0)
        })
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error getting alert counts: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/alerts/mark-read-all', methods=['POST'])
def api_mark_all_read():
    """API endpoint to mark all alerts as read with real-time broadcasting."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get all unread alert IDs for broadcasting
        cursor.execute("SELECT id FROM alerts WHERE status = 'unread' OR status IS NULL")
        unread_ids = [row[0] for row in cursor.fetchall()]
        
        # Mark all unread alerts as read
        cursor.execute("UPDATE alerts SET status = 'read' WHERE status = 'unread' OR status IS NULL")
        
        conn.commit()
        updated_count = cursor.rowcount
        conn.close()
        
        # Broadcast status changes for all updated alerts
        for alert_id in unread_ids:
            broadcast_status_change(alert_id, 'read', 'unread')
        
        # Broadcast counts update
        broadcast_counts_updated()
        
        logging.info(f"‚úÖ Marked all alerts as read: {updated_count} alerts updated")
        return jsonify({'success': True, 'updated_count': updated_count, 'message': f'Marked {updated_count} alerts as read'})
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        logging.error(f"‚ùå Error marking all alerts as read: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/alerts/dismiss-multiple', methods=['POST'])
def api_dismiss_multiple():
    """API endpoint to dismiss multiple alerts."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    alert_ids = data.get('alert_ids', [])
    
    if not alert_ids:
        return jsonify({'success': False, 'error': 'No alert IDs provided'}), 400
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Create placeholders for the IN clause
        placeholders = ','.join('?' * len(alert_ids))
        query = f"UPDATE alerts SET status = 'dismissed' WHERE id IN ({placeholders})"
        
        cursor.execute(query, alert_ids)
        
        conn.commit()
        updated_count = cursor.rowcount
        conn.close()
        
        # Broadcast status changes for real-time sync
        for alert_id in alert_ids:
            broadcast_status_change(alert_id, 'dismissed', 'unknown')
        
        # Log audit event
        log_audit_event('bulk_dismiss', 'alert', action_details={
            'alert_count': updated_count,
            'alert_ids': alert_ids[:10]  # Log first 10 IDs to avoid huge logs
        })
        
        logging.info(f"‚úÖ Dismissed {updated_count} alerts")
        return jsonify({'success': True, 'updated_count': updated_count, 'message': f'Dismissed {updated_count} alerts'})
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        log_audit_event('bulk_dismiss', 'alert', success=False, error_message=str(e))
        logging.error(f"‚ùå Error dismissing multiple alerts: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/test-alert', methods=['POST'])
def api_test_alert():
    """Send a test alert to verify the system is working."""
    try:
        # Create a test alert
        test_alert = {
            "time": datetime.datetime.now().isoformat() + "Z",
            "rule": "Test Alert Rule",
            "priority": "Notice",
            "output": "This is a test alert generated to verify the Falco AI Alert System is working correctly. This alert demonstrates the system's ability to receive, process, and display security events.",
            "source": "falco_ai_test",
            "hostname": "test-host",
            "tags": ["test", "verification", "demo"],
            "fields": {
                "container.name": "test-container",
                "proc.name": "test-process",
                "user.name": "test-user",
                "fd.name": "/test/file/path"
            }
        }
        
        # Process the test alert through the webhook processing logic
        try:
            # Simulate the webhook request processing
            
            # Extract alert metadata for logging
            rule_name = test_alert.get('rule', 'Unknown')
            alert_priority = test_alert.get('priority', 'unknown').lower()
            alert_time = test_alert.get('time', 'Unknown')
            
            logging.info(f"üì• TEST_ALERT: Processing test alert '{rule_name}' | Priority: {alert_priority}")

            # Get current configuration from database (same as webhook)
            min_priority = get_general_setting('min_priority', 'warning')
            
            # Generate AI explanation
            logging.info(f"ü§ñ AI_ANALYSIS: Starting AI explanation generation | Rule: {rule_name}")
            explanation_sections = generate_explanation_portkey(test_alert)
            
            ai_success = explanation_sections and not explanation_sections.get("error")
            if ai_success:
                ai_provider = explanation_sections.get("llm_provider", "Unknown")
                logging.info(f"‚úÖ AI_SUCCESS: Generated explanation using {ai_provider} | Rule: {rule_name}")
            else:
                error_msg = explanation_sections.get("error", "Unknown error") if explanation_sections else "No response"
                logging.warning(f"‚ùå AI_FAILED: {error_msg} | Rule: {rule_name}")
            
            # Store alert in database for Web UI
            if WEB_UI_ENABLED:
                try:
                    store_alert_enhanced(test_alert, explanation_sections if ai_success else None)
                    logging.info(f"üíæ DB_STORED: Test alert saved to database | Rule: {rule_name}")
                except Exception as e:
                    logging.error(f"‚ùå DB_ERROR: Failed to store test alert: {e} | Rule: {rule_name}")
            
            # Check Slack configuration and send if enabled
            slack_config = get_slack_config()
            current_token = slack_config.get('bot_token', {}).get('value', '')
            current_channel = slack_config.get('channel_name', {}).get('value', slack_channel_name)
            slack_enabled = slack_config.get('enabled', {}).get('value', 'false').lower() == 'true'
            
            if slack_enabled and current_token and current_token != 'xoxb-your-token-here':
                try:
                    from slack_sdk import WebClient
                    current_slack_client = WebClient(token=current_token)
                    
                    if ai_success:
                        post_to_slack(test_alert, explanation_sections, current_slack_client, current_channel)
                        logging.info(f"üì¢ SLACK_SUCCESS: Test alert sent with AI analysis to {current_channel} | Rule: {rule_name}")
                    else:
                        error_msg = explanation_sections.get("error", "AI analysis failed") if explanation_sections else "AI analysis failed"
                        basic_message = format_slack_message_basic(test_alert, error_msg)
                        send_slack_message(basic_message, current_slack_client, current_channel)
                        logging.warning(f"üì¢ SLACK_PARTIAL: Test alert sent without AI analysis to {current_channel} | Rule: {rule_name}")
                except Exception as e:
                    logging.error(f"‚ùå SLACK_ERROR: Failed to send test alert to Slack: {e} | Rule: {rule_name}")
            
            logging.info("‚úÖ Test alert processed successfully")
            return jsonify({'success': True, 'message': 'Test alert sent successfully'})
            
        except Exception as e:
            logging.error(f"‚ùå Error processing test alert: {e}")
            return jsonify({'success': False, 'error': f'Processing error: {str(e)}'}), 500
            
    except Exception as e:
        logging.error(f"‚ùå Error sending test alert: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

# AUDIT TRAIL API ENDPOINTS
@app.route('/api/audit/trail')
def api_audit_trail():
    """API endpoint to retrieve audit trail."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        # Log the audit access
        log_audit_event('audit_access', 'audit_trail', action_details={'endpoint': 'trail'})
        
        # Get filter parameters
        filters = {
            'user_id': request.args.get('user_id'),
            'action_type': request.args.get('action_type'),
            'resource_type': request.args.get('resource_type'),
            'start_date': request.args.get('start_date'),
            'end_date': request.args.get('end_date'),
            'success': request.args.get('success'),
            'limit': request.args.get('limit', '1000')
        }
        
        # Remove None values
        filters = {k: v for k, v in filters.items() if v is not None}
        
        # Get audit records from database (simplified for now)
        audit_records = []  # Will be populated when audit table exists
        
        return jsonify({
            'success': True,
            'audit_records': audit_records,
            'total_records': len(audit_records),
            'filters_applied': filters
        })
        
    except Exception as e:
        log_audit_event('audit_access', 'audit_trail', success=False, error_message=str(e))
        logging.error(f"‚ùå Error retrieving audit trail: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/audit/summary')
def api_audit_summary():
    """API endpoint to get user activity summary."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        user_id = request.args.get('user_id')
        days = int(request.args.get('days', '7'))
        
        log_audit_event('audit_access', 'audit_summary', action_details={
            'user_id': user_id, 'days': days
        })
        
        # Simplified summary for now
        summary = {
            'period_days': days,
            'activity_by_type': [],
            'top_users': [],
            'resource_access': [],
            'errors_by_type': []
        }
        
        return jsonify({
            'success': True,
            'summary': summary
        })
        
    except Exception as e:
        log_audit_event('audit_access', 'audit_summary', success=False, error_message=str(e))
        logging.error(f"‚ùå Error retrieving audit summary: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/audit')
def audit_dashboard():
    """Audit trail dashboard."""
    if not WEB_UI_ENABLED:
        return redirect('/')
    
    log_audit_event('page_view', 'audit_dashboard')
    
    return render_template('audit_dashboard.html', 
                         current_user_id=g.get('user_id', 'unknown'),
                         current_session_id=g.get('session_id', 'unknown'))

@app.route('/api/chat', methods=['POST'])
def api_chat():
    """API endpoint for chat interactions."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
        
    data = request.json
    question = data.get('message', '')
    context = data.get('context', {})
    
    if not question.strip():
        return jsonify({'error': 'Empty message'}), 400
    
    # Store user message
    store_chat_message('user', question, context)
    
    # Generate AI response
    response = generate_ai_response(question, context.get('selected_alert'))
    
    # Store AI response
    store_chat_message('ai', response, {'question': question})
    
    return jsonify({
        'response': response,
        'timestamp': datetime.datetime.now().isoformat()
    })

@app.route('/api/enhanced-chat', methods=['POST'])
def api_enhanced_chat():
    """Enhanced chat API with persona-based responses, semantic search, and multilingual support."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        data = request.json or {}
        message = data.get('message', '').strip()
        persona = data.get('persona', 'security_analyst')
        context = data.get('context', {})
        history = data.get('history', [])
        language = data.get('language', 'en')  # Get language from request
        
        if not message:
            return jsonify({'success': False, 'error': 'Message is required'}), 400
        
        # Store user message
        store_enhanced_chat_message('user', message, persona, context)
        
        # Generate persona-based response
        response_data = generate_persona_response(message, persona, context, history, language)
        
        # Store AI response
        store_enhanced_chat_message('ai', response_data['response'], persona, {
            'metadata': response_data.get('metadata', {}),
            'context': response_data.get('context', {}),
            'language': language
        })
        
        return jsonify({
            'success': True,
            'response': response_data['response'],
            'metadata': response_data.get('metadata', {}),
            'context': response_data.get('context', {}),
            'language': language,
            'timestamp': datetime.datetime.now().isoformat()
        })
        
    except Exception as e:
        # Only log if it's a real error, not just user input issues
        if not isinstance(e, (ValueError, KeyError)):
            logging.error(f"Enhanced chat error: {e}")
        return jsonify({'success': False, 'error': 'Sorry, I encountered an error. Please try again.'}), 500

@app.route('/api/dashboard/generate', methods=['POST'])
def api_generate_dashboard():
    """API endpoint for generating AI-powered dashboards."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        data = request.json or {}
        message = data.get('message', 'Create a general security dashboard')
        persona = data.get('persona', 'dashboard_creator')
        dashboard_type = data.get('dashboard_type', 'general')
        
        # Generate dashboard
        dashboard_data = generate_dashboard('dashboard', message, persona, {})
        
        if 'error' in dashboard_data:
            return jsonify({
                'success': False,
                'error': dashboard_data['error']
            }), 400
        
        return jsonify({
            'success': True,
            'dashboard': dashboard_data,
            'timestamp': datetime.datetime.now().isoformat()
        })
        
    except Exception as e:
        logging.error(f"Dashboard generation error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/dashboard/data/<data_source>')
def api_get_dashboard_data(data_source):
    """API endpoint to get specific dashboard data."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        alerts = get_alerts()
        charts_data = generate_charts_data('general', alerts)
        
        if data_source in charts_data:
            return jsonify({
                'success': True,
                'data': charts_data[data_source],
                'data_source': data_source
            })
        else:
            return jsonify({
                'success': False,
                'error': f'Data source {data_source} not found'
            }), 404
            
    except Exception as e:
        logging.error(f"Dashboard data error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/report/generate', methods=['POST'])
def api_generate_report():
    """API endpoint for generating AI-powered reports."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        data = request.json or {}
        message = data.get('message', 'Generate a general security report')
        persona = data.get('persona', 'report_generator')
        report_type = data.get('report_type', 'general')
        
        # Generate report
        report_data = generate_report('report', message, persona, {})
        
        if 'error' in report_data:
            return jsonify({
                'success': False,
                'error': report_data['error']
            }), 400
        
        return jsonify({
            'success': True,
            'report': report_data,
            'timestamp': datetime.datetime.now().isoformat()
        })
        
    except Exception as e:
        logging.error(f"Report generation error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/report/export/<report_type>')
def api_export_report(report_type):
    """API endpoint to export reports in different formats."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        format_type = request.args.get('format', 'json')
        
        # Generate report
        report_data = generate_report('report', f'Generate {report_type} report', 'report_generator', {})
        
        if 'error' in report_data:
            return jsonify({
                'success': False,
                'error': report_data['error']
            }), 400
        
        if format_type == 'json':
            return jsonify({
                'success': True,
                'report': report_data,
                'format': 'json'
            })
        elif format_type == 'markdown':
            # Convert to markdown
            markdown_content = convert_report_to_markdown(report_data)
            return jsonify({
                'success': True,
                'content': markdown_content,
                'format': 'markdown'
            })
        elif format_type == 'pdf':
            # PDF generation would require additional libraries
            return jsonify({
                'success': False,
                'error': 'PDF export not yet implemented'
            }), 501
        else:
            return jsonify({
                'success': False,
                'error': f'Unsupported format: {format_type}'
            }), 400
            
    except Exception as e:
        logging.error(f"Report export error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

def convert_report_to_markdown(report_data):
    """Convert report data to markdown format."""
    try:
        structure = report_data.get('structure', {})
        content = report_data.get('content', {})
        metadata = report_data.get('metadata', {})
        
        md_content = []
        
        # Title and metadata
        md_content.append(f"# {structure.get('title', 'Security Report')}")
        md_content.append(f"## {structure.get('subtitle', 'AI Generated Report')}")
        md_content.append("")
        md_content.append(f"**Generated:** {metadata.get('generated_at', 'Unknown')}")
        md_content.append(f"**Report Type:** {structure.get('report_type', 'general').replace('_', ' ').title()}")
        md_content.append(f"**Alerts Analyzed:** {metadata.get('total_alerts_analyzed', 0)}")
        md_content.append("")
        
        # Sections
        sections = structure.get('sections', [])
        for section in sorted(sections, key=lambda x: x.get('priority', 999)):
            section_id = section.get('id')
            section_title = section.get('title')
            
            md_content.append(f"## {section_title}")
            
            if section_id in content:
                section_content = content[section_id]
                
                if isinstance(section_content, dict):
                    for key, value in section_content.items():
                        md_content.append(f"### {key.replace('_', ' ').title()}")
                        
                        if isinstance(value, list):
                            for item in value:
                                md_content.append(f"- {item}")
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                md_content.append(f"**{sub_key.replace('_', ' ').title()}:** {sub_value}")
                        else:
                            md_content.append(f"{value}")
                        
                        md_content.append("")
                
                elif isinstance(section_content, list):
                    for item in section_content:
                        md_content.append(f"- {item}")
                    md_content.append("")
                
                else:
                    md_content.append(f"{section_content}")
                    md_content.append("")
        
        return '\n'.join(md_content)
        
    except Exception as e:
        logging.error(f"Error converting report to markdown: {e}")
        return f"Error generating markdown: {str(e)}"

@app.route('/api/chat/history')
def api_chat_history():
    """API endpoint to get chat history."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
        
    messages = get_chat_history()
    return jsonify(messages)

@app.route('/api/chat/enhanced-history')
def api_enhanced_chat_history():
    """API endpoint to get enhanced chat history."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM enhanced_chat_messages 
            ORDER BY timestamp DESC 
            LIMIT 100
        ''')
        
        messages = cursor.fetchall()
        conn.close()
        
        # Convert to list of dictionaries and reverse to get chronological order
        message_list = []
        for msg in reversed(messages):
            message_dict = {
                'id': msg[0],
                'timestamp': msg[1],
                'message_type': msg[2],
                'content': msg[3],
                'persona': msg[4],
                'context': json.loads(msg[5]) if msg[5] else None
            }
            message_list.append(message_dict)
        
        return jsonify(message_list)
        
    except Exception as e:
        logging.error(f"Error retrieving enhanced chat history: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/chat/sync', methods=['POST'])
def api_chat_sync():
    """API endpoint to sync chat history from frontend to backend."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        data = request.json or {}
        history = data.get('history', [])
        settings = data.get('settings', {})
        session_start = data.get('sessionStart')
        
        if not history:
            return jsonify({"error": "No history to sync"}), 400
        
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Create session record
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS chat_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_start DATETIME,
                sync_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                message_count INTEGER,
                settings TEXT
            )
        ''')
        
        cursor.execute('''
            INSERT INTO chat_sessions (session_start, message_count, settings)
            VALUES (?, ?, ?)
        ''', (
            datetime.datetime.fromtimestamp(session_start / 1000) if session_start else datetime.datetime.now(),
            len(history),
            json.dumps(settings)
        ))
        
        session_id = cursor.lastrowid
        
        # Sync each message
        synced_count = 0
        for msg in history:
            try:
                # Check if message already exists (avoid duplicates)
                cursor.execute('''
                    SELECT id FROM enhanced_chat_messages 
                    WHERE content = ? AND message_type = ? AND timestamp = ?
                ''', (
                    msg.get('content', ''),
                    msg.get('role', ''),
                    datetime.datetime.fromtimestamp(msg.get('timestamp', 0) / 1000)
                ))
                
                if not cursor.fetchone():
                    cursor.execute('''
                        INSERT INTO enhanced_chat_messages (timestamp, message_type, content, persona, context)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (
                        datetime.datetime.fromtimestamp(msg.get('timestamp', 0) / 1000),
                        msg.get('role', ''),
                        msg.get('content', ''),
                        settings.get('persona', 'security_analyst'),
                        json.dumps({'session_id': session_id, 'synced': True})
                    ))
                    synced_count += 1
                    
            except Exception as msg_error:
                logging.warning(f"Failed to sync message: {msg_error}")
                continue
        
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "synced_messages": synced_count,
            "session_id": session_id,
            "message": f"Successfully synced {synced_count} messages to server"
        })
        
    except Exception as e:
        logging.error(f"Error syncing chat history: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/chat/sessions')
def api_chat_sessions():
    """API endpoint to get available chat sessions."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Check if sessions table exists
        cursor.execute('''
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='chat_sessions'
        ''')
        
        if not cursor.fetchone():
            conn.close()
            return jsonify([])
        
        cursor.execute('''
            SELECT id, session_start, sync_timestamp, message_count, settings
            FROM chat_sessions 
            ORDER BY sync_timestamp DESC 
            LIMIT 20
        ''')
        
        sessions = cursor.fetchall()
        conn.close()
        
        session_list = []
        for session in sessions:
            session_dict = {
                'id': session[0],
                'session_start': session[1],
                'timestamp': session[2],
                'message_count': session[3],
                'settings': json.loads(session[4]) if session[4] else {}
            }
            session_list.append(session_dict)
        
        return jsonify(session_list)
        
    except Exception as e:
        logging.error(f"Error retrieving chat sessions: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/export')
def api_export():
    """API endpoint to export analysis data."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
        
    alerts = get_alerts()
    
    # Generate comprehensive analysis
    analysis = {
        'export_timestamp': datetime.datetime.now().isoformat(),
        'summary': {
            'total_alerts': len(alerts),
            'time_range': f"{alerts[-1]['timestamp']} to {alerts[0]['timestamp']}" if alerts else "No alerts",
            'unique_rules': len(set(a['rule'] for a in alerts))
        },
        'priority_breakdown': {},
        'rule_frequency': {},
        'recommendations': []
    }
    
    # Priority breakdown
    for alert in alerts:
        priority = alert['priority']
        analysis['priority_breakdown'][priority] = analysis['priority_breakdown'].get(priority, 0) + 1
    
    # Rule frequency
    for alert in alerts:
        rule = alert['rule']
        analysis['rule_frequency'][rule] = analysis['rule_frequency'].get(rule, 0) + 1
    
    # Sort rules by frequency
    analysis['rule_frequency'] = dict(sorted(analysis['rule_frequency'].items(), key=lambda x: x[1], reverse=True))
    
    # Generate recommendations
    critical_count = analysis['priority_breakdown'].get('critical', 0)
    error_count = analysis['priority_breakdown'].get('error', 0)
    
    if critical_count > 0:
        analysis['recommendations'].append(f"üö® {critical_count} critical alerts require immediate investigation")
    
    if error_count > 5:
        analysis['recommendations'].append("‚ö†Ô∏è High error rate detected - review system security")
    
    analysis['recommendations'].extend([
        "üõ°Ô∏è Implement automated incident response",
        "üìä Set up regular security monitoring",
        "üöÄ Deploy to production for real-time protection"
    ])
    
    return jsonify(analysis)

# --- Weaviate/Semantic Search API Endpoints ---

@app.route('/api/weaviate/health')
def api_weaviate_health():
    """Check Weaviate health status."""
    if not WEAVIATE_ENABLED:
        return jsonify({"status": "disabled"}), 200
    
    try:
        weaviate_service = get_weaviate_service()
        if weaviate_service is None:
            return jsonify({"status": "service_unavailable", "error": "Weaviate service not initialized"}), 503
        
        health_status = weaviate_service.health_check()
        return jsonify(health_status)
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

@app.route('/api/semantic-search', methods=['POST'])
def api_semantic_search():
    """Perform semantic search across alerts."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate/semantic search is disabled"}), 400
    
    try:
        data = request.json or {}
        query = data.get('query', '').strip()
        limit = min(int(data.get('limit', 10)), 50)  # Max 50 results
        threshold = float(data.get('threshold', 0.5))  # Use threshold instead of certainty
        
        if not query:
            return jsonify({"error": "Query is required"}), 400
        
        weaviate_service = get_weaviate_service()
        similar_alerts = weaviate_service.find_similar_alerts(query, limit, threshold)
        
        # Format results for dashboard display
        formatted_results = []
        for alert in similar_alerts:
            formatted_result = {
                "id": alert.get("_additional", {}).get("id", ""),
                "rule": alert.get("rule", ""),
                "priority": alert.get("priority", ""),
                "output": alert.get("output", ""),
                "timestamp": alert.get("timestamp", ""),
                "source": alert.get("source", ""),
                "similarity": alert.get("_additional", {}).get("certainty", 0)
            }
            formatted_results.append(formatted_result)
        
        return jsonify(formatted_results)
        
    except Exception as e:
        logging.error(f"Semantic search error: {e}")
        return jsonify({"error": f"Semantic search failed: {str(e)}"}), 500

@app.route('/api/alert-patterns')
def api_alert_patterns():
    """Get alert patterns and trends from Weaviate."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate/pattern analysis is disabled"}), 400
    
    try:
        days = int(request.args.get('days', 30))
        days = min(days, 90)  # Max 90 days
        
        weaviate_service = get_weaviate_service()
        patterns = weaviate_service.get_alert_patterns(days)
        
        return jsonify({
            "success": True,
            "analysis_period_days": days,
            "patterns": patterns
        })
        
    except Exception as e:
        logging.error(f"Pattern analysis error: {e}")
        return jsonify({"error": f"Pattern analysis failed: {str(e)}"}), 500

@app.route('/api/contextual-analysis', methods=['POST'])
def api_contextual_analysis():
    """Get contextual analysis for an alert based on similar past incidents."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate/contextual analysis is disabled"}), 400
    
    try:
        data = request.json or {}
        
        # Support both alert_id and direct alert_data
        if 'alert_id' in data:
            alert_id = data['alert_id']
            alerts = get_alerts()
            alert_data = next((a for a in alerts if a['id'] == alert_id), None)
            
            if not alert_data:
                return jsonify({"error": "Alert not found"}), 404
        elif 'alert_data' in data:
            alert_data = data['alert_data']
        else:
            return jsonify({"error": "Either alert_id or alert_data is required"}), 400
        
        weaviate_service = get_weaviate_service()
        context = weaviate_service.get_contextual_analysis(alert_data)
        
        return jsonify({
            "success": True,
            "alert_rule": alert_data.get('rule', 'Unknown'),
            "contextual_analysis": context
        })
        
    except Exception as e:
        logging.error(f"Contextual analysis error: {e}")
        return jsonify({"error": f"Contextual analysis failed: {str(e)}"}), 500

@app.route('/api/similar-alerts/<int:alert_id>')
def api_similar_alerts(alert_id):
    """Find alerts similar to a specific alert."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate/similarity search is disabled"}), 400
    
    try:
        # Get the reference alert
        alerts = get_alerts()
        reference_alert = next((a for a in alerts if a['id'] == alert_id), None)
        
        if not reference_alert:
            return jsonify({"error": "Alert not found"}), 404
        
        # Build search query from alert content
        query = f"{reference_alert.get('rule', '')} {reference_alert.get('output', '')}"
        
        weaviate_service = get_weaviate_service()
        similar_alerts = weaviate_service.find_similar_alerts(query, limit=10, certainty=0.5)
        
        # Format similar alerts for dashboard display
        formatted_similar_alerts = []
        for alert in similar_alerts:
            formatted_alert = {
                "id": alert.get("_additional", {}).get("id", ""),
                "rule": alert.get("rule", ""),
                "priority": alert.get("priority", ""),
                "output": alert.get("output", ""),
                "timestamp": alert.get("timestamp", ""),
                "source": alert.get("source", ""),
                "similarity": alert.get("_additional", {}).get("certainty", 0)
            }
            formatted_similar_alerts.append(formatted_alert)
        
        return jsonify({
            "success": True,
            "reference_alert": {
                "id": reference_alert['id'],
                "rule": reference_alert['rule'],
                "priority": reference_alert['priority'],
                "timestamp": reference_alert['timestamp']
            },
            "similar_alerts": formatted_similar_alerts
        })
        
    except Exception as e:
        logging.error(f"Similar alerts error: {e}")
        return jsonify({"error": f"Similar alerts search failed: {str(e)}"}), 500

@app.route('/api/semantic-search/enhanced', methods=['POST'])
def api_enhanced_semantic_search():
    """Enhanced semantic search with conversation integration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Semantic search is disabled"}), 400
    
    try:
        data = request.json or {}
        query = data.get('query', '').strip()
        persona = data.get('persona', 'security_analyst')
        include_conversations = data.get('include_conversations', False)
        limit = min(int(data.get('limit', 10)), 50)
        certainty = float(data.get('certainty', 0.6))
        
        if not query:
            return jsonify({"error": "Query is required"}), 400
        
        weaviate_service = get_weaviate_service()
        results = {
            'query': query,
            'persona': persona,
            'results': {
                'alerts': [],
                'conversations': [],
                'insights': {}
            }
        }
        
        # Search alerts
        similar_alerts = weaviate_service.find_similar_alerts(query, limit, certainty)
        results['results']['alerts'] = similar_alerts
        
        # Search conversations if requested
        if include_conversations:
            similar_conversations = weaviate_service.find_similar_conversations(query, persona, limit//2)
            results['results']['conversations'] = similar_conversations
        
        # Generate insights
        if similar_alerts or (include_conversations and similar_conversations):
            insights = generate_search_insights(query, similar_alerts, similar_conversations if include_conversations else [])
            results['results']['insights'] = insights
        
        return jsonify({
            'success': True,
            'search_results': results,
            'timestamp': datetime.datetime.now().isoformat()
        })
        
    except Exception as e:
        logging.error(f"Enhanced semantic search error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/semantic-search/suggest', methods=['POST'])
def api_semantic_search_suggestions():
    """Generate search suggestions based on current alerts and conversations."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        data = request.json or {}
        persona = data.get('persona', 'security_analyst')
        context = data.get('context', {})
        
        # Get recent alerts for context
        recent_alerts = get_alerts({'limit': '20'})
        
        # Generate suggestions based on persona and recent activity
        suggestions = generate_search_suggestions(persona, recent_alerts, context)
        
        return jsonify({
            'success': True,
            'suggestions': suggestions,
            'persona': persona
        })
        
    except Exception as e:
        logging.error(f"Search suggestions error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

def generate_search_insights(query, alerts, conversations):
    """Generate insights from search results."""
    insights = {
        'query_analysis': {
            'intent': determine_search_intent(query),
            'keywords': extract_keywords(query),
            'search_type': 'semantic' if alerts else 'text'
        },
        'results_summary': {
            'total_alerts': len(alerts),
            'total_conversations': len(conversations),
            'relevance_score': calculate_average_relevance(alerts, conversations)
        },
        'patterns': {
            'common_rules': {},
            'priority_distribution': {},
            'time_patterns': {},
            'conversation_topics': {}
        },
        'recommendations': []
    }
    
    # Analyze alert patterns
    if alerts:
        for alert in alerts:
            rule = alert.get('rule', 'unknown')
            priority = alert.get('priority', 'unknown')
            
            insights['patterns']['common_rules'][rule] = insights['patterns']['common_rules'].get(rule, 0) + 1
            insights['patterns']['priority_distribution'][priority] = insights['patterns']['priority_distribution'].get(priority, 0) + 1
        
        # Generate recommendations based on patterns
        top_rule = max(insights['patterns']['common_rules'].items(), key=lambda x: x[1])[0] if insights['patterns']['common_rules'] else None
        if top_rule:
            insights['recommendations'].append(f"Consider investigating '{top_rule}' rule patterns")
        
        critical_count = insights['patterns']['priority_distribution'].get('critical', 0)
        if critical_count > 0:
            insights['recommendations'].append(f"Review {critical_count} critical alerts found in search results")
    
    # Analyze conversation patterns
    if conversations:
        for conv in conversations:
            persona = conv.get('persona', 'unknown')
            insights['patterns']['conversation_topics'][persona] = insights['patterns']['conversation_topics'].get(persona, 0) + 1
        
        insights['recommendations'].append("Review similar past conversations for additional context")
    
    return insights

def generate_search_suggestions(persona, recent_alerts, context):
    """Generate search suggestions based on persona and context."""
    suggestions = {
        'persona_based': [],
        'context_based': [],
        'recent_activity': [],
        'popular_searches': []
    }
    
    # Persona-based suggestions
    persona_suggestions = {
        'security_analyst': [
            'critical security alerts',
            'failed authentication attempts',
            'suspicious network activity',
            'privilege escalation attempts',
            'malware detection events'
        ],
        'incident_responder': [
            'active security incidents',
            'containment procedures',
            'emergency response protocols',
            'threat indicators',
            'security breaches'
        ],
        'threat_hunter': [
            'advanced persistent threats',
            'behavioral anomalies',
            'attack patterns',
            'indicators of compromise',
            'threat intelligence'
        ],
        'report_generator': [
            'security metrics',
            'compliance violations',
            'security trends',
            'executive summaries',
            'risk assessments'
        ],
        'dashboard_creator': [
            'security dashboards',
            'visualization data',
            'performance metrics',
            'monitoring charts',
            'KPI indicators'
        ]
    }
    
    suggestions['persona_based'] = persona_suggestions.get(persona, persona_suggestions['security_analyst'])
    
    # Context-based suggestions from recent alerts
    if recent_alerts:
        # Get most common rules
        rule_counts = {}
        for alert in recent_alerts:
            rule = alert.get('rule', '')
            if rule:
                rule_counts[rule] = rule_counts.get(rule, 0) + 1
        
        top_rules = sorted(rule_counts.items(), key=lambda x: x[1], reverse=True)[:3]
        suggestions['recent_activity'] = [rule for rule, count in top_rules]
        
        # Context-based suggestions
        suggestions['context_based'] = [
            f"alerts from last 24 hours",
            f"similar to recent {top_rules[0][0] if top_rules else 'activity'}",
            "high priority incidents",
            "unresolved security events"
        ]
    
    # Popular/common searches
    suggestions['popular_searches'] = [
        'failed login attempts',
        'container security events',
        'network intrusion attempts',
        'file system changes',
        'process execution anomalies'
    ]
    
    return suggestions

def determine_search_intent(query):
    """Determine the intent behind a search query."""
    query_lower = query.lower()
    
    if any(word in query_lower for word in ['critical', 'urgent', 'emergency', 'breach']):
        return 'incident_investigation'
    elif any(word in query_lower for word in ['trend', 'pattern', 'analysis', 'statistics']):
        return 'trend_analysis'
    elif any(word in query_lower for word in ['similar', 'related', 'like', 'comparable']):
        return 'similarity_search'
    elif any(word in query_lower for word in ['what', 'how', 'why', 'explain']):
        return 'information_seeking'
    elif any(word in query_lower for word in ['show', 'list', 'find', 'get']):
        return 'data_retrieval'
    else:
        return 'general_search'

def extract_keywords(query):
    """Extract important keywords from search query."""
    # Simple keyword extraction - could be enhanced with NLP
    stop_words = {'the', 'is', 'at', 'which', 'on', 'and', 'or', 'but', 'in', 'with', 'to', 'for', 'of', 'as', 'by'}
    words = query.lower().split()
    keywords = [word for word in words if len(word) > 2 and word not in stop_words]
    return keywords[:5]  # Return top 5 keywords

def calculate_average_relevance(alerts, conversations):
    """Calculate average relevance score from search results."""
    total_score = 0
    total_items = 0
    
    for alert in alerts:
        certainty = alert.get('_additional', {}).get('certainty', 0)
        total_score += certainty
        total_items += 1
    
    for conv in conversations:
        similarity = conv.get('similarity', 0)
        total_score += similarity
        total_items += 1
    
    return total_score / total_items if total_items > 0 else 0

# ===========================================
# ENHANCED WEAVIATE AI ANALYTICS ENDPOINTS
# ===========================================

@app.route('/api/weaviate/cluster-alerts', methods=['POST'])
def api_cluster_alerts():
    """Perform intelligent alert clustering with ML algorithms."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        days = min(int(data.get('days', 30)), 90)  # Max 90 days
        min_cluster_size = max(int(data.get('min_cluster_size', 2)), 2)
        
        weaviate_service = get_weaviate_service()
        if weaviate_service is None:
            return jsonify({"error": "Weaviate service not available"}), 503
        
        clustering_results = weaviate_service.cluster_alerts_smart(days, min_cluster_size)
        
        return jsonify({
            "success": True,
            "clustering_results": clustering_results,
            "analysis_params": {
                "days": days,
                "min_cluster_size": min_cluster_size
            }
        })
        
    except Exception as e:
        logging.error(f"Alert clustering error: {e}")
        return jsonify({"error": f"Alert clustering failed: {str(e)}"}), 500

@app.route('/api/weaviate/predict-threat', methods=['POST'])
def api_predict_threat():
    """Generate predictive threat intelligence for an alert."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        
        # Support both alert_id and direct alert_data
        if 'alert_id' in data:
            alert_id = data['alert_id']
            alerts = get_alerts({'limit': '1000'})
            alert_data = next((a for a in alerts if a['id'] == alert_id), None)
            
            if not alert_data:
                return jsonify({"error": "Alert not found"}), 404
        elif 'alert_data' in data:
            alert_data = data['alert_data']
        else:
            return jsonify({"error": "Either alert_id or alert_data is required"}), 400
        
        weaviate_service = get_weaviate_service()
        threat_prediction = weaviate_service.predict_threat_intelligence(alert_data)
        
        return jsonify({
            "success": True,
            "alert_rule": alert_data.get('rule', 'Unknown'),
            "threat_prediction": threat_prediction
        })
        
    except Exception as e:
        logging.error(f"Threat prediction error: {e}")
        return jsonify({"error": f"Threat prediction failed: {str(e)}"}), 500

@app.route('/api/weaviate/classify-alert', methods=['POST'])
def api_classify_alert():
    """Perform real-time alert classification with auto-tagging."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        
        # Support both alert_id and direct alert_data
        if 'alert_id' in data:
            alert_id = data['alert_id']
            alerts = get_alerts({'limit': '1000'})
            alert_data = next((a for a in alerts if a['id'] == alert_id), None)
            
            if not alert_data:
                return jsonify({"error": "Alert not found"}), 404
        elif 'alert_data' in data:
            alert_data = data['alert_data']
        else:
            return jsonify({"error": "Either alert_id or alert_data is required"}), 400
        
        weaviate_service = get_weaviate_service()
        classification_results = weaviate_service.classify_alert_realtime(alert_data)
        
        return jsonify({
            "success": True,
            "alert_rule": alert_data.get('rule', 'Unknown'),
            "classification": classification_results
        })
        
    except Exception as e:
        logging.error(f"Alert classification error: {e}")
        return jsonify({"error": f"Alert classification failed: {str(e)}"}), 500

@app.route('/api/weaviate/enhanced-context', methods=['POST'])
def api_enhanced_contextual_analysis():
    """Perform enhanced contextual analysis with timeline correlation."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        
        # Support both alert_id and direct alert_data
        if 'alert_id' in data:
            alert_id = data['alert_id']
            alerts = get_alerts({'limit': '1000'})
            alert_data = next((a for a in alerts if a['id'] == alert_id), None)
            
            if not alert_data:
                return jsonify({"error": "Alert not found"}), 404
        elif 'alert_data' in data:
            alert_data = data['alert_data']
        else:
            return jsonify({"error": "Either alert_id or alert_data is required"}), 400
        
        weaviate_service = get_weaviate_service()
        enhanced_context = weaviate_service.enhanced_contextual_analysis(alert_data)
        
        return jsonify({
            "success": True,
            "alert_rule": alert_data.get('rule', 'Unknown'),
            "enhanced_context": enhanced_context
        })
        
    except Exception as e:
        logging.error(f"Enhanced contextual analysis error: {e}")
        return jsonify({"error": f"Enhanced contextual analysis failed: {str(e)}"}), 500

@app.route('/api/weaviate/advanced-search', methods=['POST'])
def api_advanced_semantic_search():
    """Perform advanced semantic search with intelligent query processing."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        query = data.get('query', '').strip()
        search_type = data.get('search_type', 'intelligent')  # intelligent, semantic, keyword
        limit = min(int(data.get('limit', 10)), 50)
        filters = data.get('filters', {})
        
        if not query:
            return jsonify({"error": "Query is required"}), 400
        
        weaviate_service = get_weaviate_service()
        search_results = weaviate_service.advanced_semantic_search(query, search_type, limit, filters)
        
        return jsonify({
            "success": True,
            "search_results": search_results,
            "query": query,
            "search_type": search_type
        })
        
    except Exception as e:
        logging.error(f"Advanced semantic search error: {e}")
        return jsonify({"error": f"Advanced semantic search failed: {str(e)}"}), 500

@app.route('/api/weaviate/analytics-dashboard', methods=['GET'])
def api_analytics_dashboard():
    """Get comprehensive analytics dashboard data."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        days = min(int(request.args.get('days', 30)), 90)
        
        weaviate_service = get_weaviate_service()
        
        # Gather comprehensive analytics
        analytics_data = {
            "alert_patterns": weaviate_service.get_alert_patterns(days),
            "clustering_analysis": weaviate_service.cluster_alerts_smart(days, 2),
            "conversation_insights": weaviate_service.get_conversation_insights(days=days),
            "health_status": weaviate_service.health_check(),
            "analysis_period": {
                "days": days,
                "start_date": (datetime.datetime.now() - timedelta(days=days)).isoformat(),
                "end_date": datetime.datetime.now().isoformat()
            }
        }
        
        return jsonify({
            "success": True,
            "analytics": analytics_data
        })
        
    except Exception as e:
        logging.error(f"Analytics dashboard error: {e}")
        return jsonify({"error": f"Analytics dashboard failed: {str(e)}"}), 500

@app.route('/api/weaviate/threat-intelligence', methods=['GET'])
def api_threat_intelligence_summary():
    """Get threat intelligence summary for all recent alerts."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        days = min(int(request.args.get('days', 7)), 30)
        limit = min(int(request.args.get('limit', 20)), 100)
        
        # Get recent alerts
        alerts = get_alerts({'limit': str(limit)})
        weaviate_service = get_weaviate_service()
        
        threat_intelligence = {
            "summary": {
                "total_alerts": len(alerts),
                "analysis_period_days": days,
                "high_risk_alerts": 0,
                "medium_risk_alerts": 0,
                "low_risk_alerts": 0
            },
            "threat_categories": {},
            "risk_distribution": {},
            "top_threat_indicators": [],
            "recommendations": []
        }
        
        # Analyze each alert
        for alert in alerts[:10]:  # Limit to 10 for performance
            try:
                classification = weaviate_service.classify_alert_realtime(alert)
                threat_category = classification.get('threat_category', 'unknown')
                urgency_score = classification.get('urgency_score', 5.0)
                
                # Update threat categories
                threat_intelligence["threat_categories"][threat_category] = \
                    threat_intelligence["threat_categories"].get(threat_category, 0) + 1
                
                # Update risk distribution
                if urgency_score >= 7.0:
                    threat_intelligence["summary"]["high_risk_alerts"] += 1
                elif urgency_score >= 5.0:
                    threat_intelligence["summary"]["medium_risk_alerts"] += 1
                else:
                    threat_intelligence["summary"]["low_risk_alerts"] += 1
                
                # Add to risk distribution
                risk_level = "high" if urgency_score >= 7.0 else "medium" if urgency_score >= 5.0 else "low"
                threat_intelligence["risk_distribution"][risk_level] = \
                    threat_intelligence["risk_distribution"].get(risk_level, 0) + 1
                
            except Exception as e:
                logging.warning(f"Failed to analyze alert {alert.get('id', 'unknown')}: {e}")
                continue
        
        # Generate consistent recommendations based on actual data
        high_risk_count = threat_intelligence["summary"]["high_risk_alerts"]
        medium_risk_count = threat_intelligence["summary"]["medium_risk_alerts"]
        
        if high_risk_count > 5:
            threat_intelligence["recommendations"].append("CRITICAL: High volume of high-risk alerts detected")
        elif high_risk_count > 2:
            threat_intelligence["recommendations"].append("HIGH: Multiple high-risk alerts require attention")
        
        if medium_risk_count > 10:
            threat_intelligence["recommendations"].append("MEDIUM: Review medium-risk alerts for patterns")
        
        most_common_threat = max(threat_intelligence["threat_categories"].items(), 
                               key=lambda x: x[1])[0] if threat_intelligence["threat_categories"] else None
        if most_common_threat and most_common_threat != "unknown":
            threat_intelligence["recommendations"].append(f"Focus on {most_common_threat} threat patterns")
        
        # Add general recommendations
        threat_intelligence["recommendations"].extend([
            "Review security monitoring coverage",
            "Update threat detection rules if needed",
            "Consider security awareness training"
        ])
        
        return jsonify({
            "success": True,
            "threat_intelligence": threat_intelligence
        })
        
    except Exception as e:
        logging.error(f"Threat intelligence summary error: {e}")
        return jsonify({"error": f"Threat intelligence summary failed: {str(e)}"}), 500

@app.route('/api/weaviate/batch-analysis', methods=['POST'])
def api_batch_analysis():
    """Perform batch analysis on multiple alerts."""
    if not WEAVIATE_ENABLED:
        return jsonify({"error": "Weaviate is disabled"}), 400
    
    try:
        data = request.json or {}
        alert_ids = data.get('alert_ids', [])
        analysis_types = data.get('analysis_types', ['classification', 'threat_prediction'])
        
        if not alert_ids:
            return jsonify({"error": "No alert IDs provided"}), 400
        
        # Limit batch size for performance
        alert_ids = alert_ids[:20]
        
        alerts = get_alerts({'limit': '1000'})
        weaviate_service = get_weaviate_service()
        
        batch_results = {
            "total_alerts": len(alert_ids),
            "analysis_types": analysis_types,
            "results": []
        }
        
        for alert_id in alert_ids:
            alert_data = next((a for a in alerts if a['id'] == alert_id), None)
            if not alert_data:
                continue
            
            alert_analysis = {
                "alert_id": alert_id,
                "rule": alert_data.get('rule', 'Unknown'),
                "priority": alert_data.get('priority', 'unknown')
            }
            
            # Perform requested analysis types
            if 'classification' in analysis_types:
                try:
                    classification = weaviate_service.classify_alert_realtime(alert_data)
                    alert_analysis['classification'] = classification
                except Exception as e:
                    alert_analysis['classification'] = {"error": str(e)}
            
            if 'threat_prediction' in analysis_types:
                try:
                    prediction = weaviate_service.predict_threat_intelligence(alert_data)
                    alert_analysis['threat_prediction'] = prediction
                except Exception as e:
                    alert_analysis['threat_prediction'] = {"error": str(e)}
            
            if 'enhanced_context' in analysis_types:
                try:
                    context = weaviate_service.enhanced_contextual_analysis(alert_data)
                    alert_analysis['enhanced_context'] = context
                except Exception as e:
                    alert_analysis['enhanced_context'] = {"error": str(e)}
            
            batch_results["results"].append(alert_analysis)
        
        return jsonify({
            "success": True,
            "batch_analysis": batch_results
        })
        
    except Exception as e:
        logging.error(f"Batch analysis error: {e}")
        return jsonify({"error": f"Batch analysis failed: {str(e)}"}), 500

# --- Slack Configuration Routes ---
@app.route('/config/slack')
def slack_config_ui():
    """Slack configuration page."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('slack_config.html', page='slack')

@app.route('/api/slack/config', methods=['GET'])
def api_slack_config():
    """API endpoint to get Slack configuration."""
    logging.info("GET /api/slack/config called")  # Add logging
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        config = get_slack_config()
        logging.info(f"Returning Slack config with {len(config)} settings")
        return jsonify(config)
    except Exception as e:
        logging.error(f"Error in /api/slack/config: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/slack/config', methods=['POST'])
def api_update_slack_config():
    """API endpoint to update Slack configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        for setting_name, setting_value in data.items():
            if setting_name in ['bot_token', 'channel_name', 'enabled', 'username', 'icon_emoji', 
                              'template_style', 'min_priority_slack', 'include_commands', 'thread_alerts',
                              'notification_throttling', 'throttle_threshold', 'business_hours_only', 'business_hours',
                              'escalation_enabled', 'escalation_interval', 'digest_mode_enabled', 'digest_time']:
                update_slack_config(setting_name, setting_value)
        
        return jsonify({"success": True, "message": "Configuration updated successfully"})
    except Exception as e:
        logging.error(f"Error updating Slack config: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/slack/test', methods=['POST'])
def api_test_slack():
    """API endpoint to test Slack connection."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    bot_token = data.get('bot_token', '')
    channel_name = data.get('channel_name', '#general')
    
    if not bot_token:
        return jsonify({"error": "Bot token is required"}), 400
    
    result = test_slack_connection(bot_token, channel_name)
    return jsonify(result)

@app.route('/api/slack/preview', methods=['POST'])
def api_slack_preview():
    """API endpoint to preview Slack message format."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    template_style = data.get('template_style', 'detailed')
    bot_token = data.get('bot_token', '')
    channel_name = data.get('channel_name', '')
    
    # Validate bot token
    if not bot_token:
        return jsonify({"error": "Bot token is required for preview"}), 400
    
    if not bot_token.startswith('xoxb-'):
        return jsonify({"error": "Invalid bot token format. Token must start with 'xoxb-'"}), 400
    
    # Validate channel name
    if not channel_name:
        return jsonify({"error": "Channel name is required for preview"}), 400
    
    if not channel_name.startswith('#'):
        return jsonify({"error": "Channel name must start with '#' (e.g., #security-alerts)"}), 400
    
    # Optional: Test actual Slack connection if SDK is available
    if SLACK_AVAILABLE:
        try:
            test_client = WebClient(token=bot_token)
            
            # Test API connection
            auth_response = test_client.auth_test()
            if not auth_response['ok']:
                return jsonify({"error": "Invalid bot token - authentication failed"}), 400
            
            # Test channel access by attempting to get channel info
            # This is optional - if the bot doesn't have channel inspection permissions,
            # we'll skip this check but still allow the preview
            try:
                # Remove # from channel name for API call
                channel_without_hash = channel_name.lstrip('#')
                channel_response = test_client.conversations_info(channel=channel_without_hash)
                if not channel_response['ok']:
                    # Try by channel name if ID lookup fails
                    try:
                        channels_response = test_client.conversations_list()
                        channel_found = False
                        for channel in channels_response.get('channels', []):
                            if channel['name'] == channel_without_hash:
                                channel_found = True
                                break
                        
                        if not channel_found:
                            return jsonify({"error": f"Channel '{channel_name}' not found or bot doesn't have access"}), 400
                    except SlackApiError as list_error:
                        # If we can't list channels due to permissions, skip channel validation
                        if list_error.response['error'] in ['missing_scope', 'not_authed']:
                            logging.warning(f"Skipping channel validation due to insufficient permissions: {list_error.response['error']}")
                        else:
                            return jsonify({"error": f"Channel access error: {list_error.response['error']}"}), 400
                        
            except SlackApiError as e:
                if e.response['error'] == 'channel_not_found':
                    return jsonify({"error": f"Channel '{channel_name}' not found"}), 400
                elif e.response['error'] == 'not_in_channel':
                    return jsonify({"error": f"Bot is not a member of channel '{channel_name}'. Please invite the bot to the channel first"}), 400
                elif e.response['error'] in ['missing_scope', 'not_authed']:
                    # Skip channel validation if bot doesn't have channel inspection permissions
                    logging.warning(f"Skipping channel validation due to insufficient permissions: {e.response['error']}")
                else:
                    return jsonify({"error": f"Channel access error: {e.response['error']}"}), 400
                    
        except SlackApiError as e:
            return jsonify({"error": f"Slack API error: {e.response.get('error', 'Unknown error')}"}), 400
        except Exception as e:
            return jsonify({"error": f"Connection test failed: {str(e)}"}), 400
    
    # Sample alert for preview
    sample_alert = {
        'rule': 'Terminal shell in container',
        'priority': 'warning',
        'output': 'A shell was used as the entrypoint/exec point into a container (user=root)',
        'time': datetime.datetime.now().isoformat(),
        'output_fields': {
            'proc.cmdline': '/bin/bash',
            'container.id': 'abc123'
        }
    }
    
    # Sample AI analysis
    sample_analysis = {
        'Security Impact': {'content': 'An interactive shell session in a container may indicate unauthorized access or legitimate administrative activity.'},
        'Next Steps': {'content': 'Verify if this shell access was authorized and investigate recent container activities.'},
        'Remediation Steps': {'content': 'Review container security policies and consider implementing runtime protection rules.'},
        'Suggested Commands': {'content': 'docker logs abc123\nkubectl describe pod <pod-name>'},
        'llm_provider': 'OpenAI via Portkey'
    }
    
    # Generate preview based on template style
    if template_style == 'basic':
        preview = {
            'type': 'basic',
            'content': f"‚ö†Ô∏è **Falco Alert**\n**Rule:** {sample_alert['rule']}\n**Priority:** {sample_alert['priority']}\n**Details:** {sample_alert['output']}"
        }
    else:
        preview = {
            'type': 'detailed',
            'content': {
                'header': f"üö® Falco Security Alert - {sample_alert['rule']}",
                'priority': sample_alert['priority'].capitalize(),
                'security_impact': sample_analysis['Security Impact']['content'],
                'next_steps': sample_analysis['Next Steps']['content'],
                'remediation': sample_analysis['Remediation Steps']['content'],
                'commands': sample_analysis['Suggested Commands']['content'] if data.get('include_commands') else None
            }
        }
    
    return jsonify(preview)

@app.route('/api/slack/validate', methods=['POST'])
def api_slack_validate():
    """API endpoint to validate Slack configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    bot_token = data.get('bot_token', '')
    channel_name = data.get('channel_name', '')
    
    validation_results = {
        'valid': True,
        'bot_token': {'valid': True, 'message': ''},
        'channel_name': {'valid': True, 'message': ''},
        'connection': {'valid': True, 'message': ''},
        'overall_status': 'success'
    }
    
    # Validate bot token
    if not bot_token:
        validation_results['bot_token'] = {'valid': False, 'message': 'Bot token is required'}
        validation_results['valid'] = False
    elif not bot_token.startswith('xoxb-'):
        validation_results['bot_token'] = {'valid': False, 'message': 'Token must start with "xoxb-"'}
        validation_results['valid'] = False
    else:
        validation_results['bot_token'] = {'valid': True, 'message': 'Token format is valid'}
    
    # Validate channel name
    if not channel_name:
        validation_results['channel_name'] = {'valid': False, 'message': 'Channel name is required'}
        validation_results['valid'] = False
    elif not channel_name.startswith('#'):
        validation_results['channel_name'] = {'valid': False, 'message': 'Channel must start with "#"'}
        validation_results['valid'] = False
    else:
        validation_results['channel_name'] = {'valid': True, 'message': 'Channel format is valid'}
    
    # Test connection if both token and channel are valid
    if validation_results['bot_token']['valid'] and validation_results['channel_name']['valid'] and SLACK_AVAILABLE:
        try:
            test_client = WebClient(token=bot_token)
            
            # Test API connection
            auth_response = test_client.auth_test()
            if not auth_response['ok']:
                validation_results['connection'] = {'valid': False, 'message': 'Bot token authentication failed'}
                validation_results['valid'] = False
            else:
                validation_results['connection'] = {'valid': True, 'message': f'Connected as {auth_response.get("user", "Unknown")}'}
                
                # Test channel access (optional, skip if insufficient permissions)
                try:
                    channel_without_hash = channel_name.lstrip('#')
                    test_client.conversations_info(channel=channel_without_hash)
                except SlackApiError as e:
                    if e.response['error'] == 'channel_not_found':
                        validation_results['connection'] = {'valid': False, 'message': f'Channel "{channel_name}" not found'}
                        validation_results['valid'] = False
                    elif e.response['error'] == 'not_in_channel':
                        validation_results['connection'] = {'valid': False, 'message': f'Bot not invited to "{channel_name}"'}
                        validation_results['valid'] = False
                    elif e.response['error'] in ['missing_scope', 'not_authed']:
                        # Skip channel validation if insufficient permissions
                        validation_results['connection'] = {'valid': True, 'message': f'Connected (channel access not verified)'}
                
        except SlackApiError as e:
            validation_results['connection'] = {'valid': False, 'message': f'Slack API error: {e.response.get("error", "Unknown error")}'}
            validation_results['valid'] = False
        except Exception as e:
            validation_results['connection'] = {'valid': False, 'message': f'Connection test failed: {str(e)}'}
            validation_results['valid'] = False
    
    # Set overall status
    if validation_results['valid']:
        validation_results['overall_status'] = 'success'
    elif validation_results['bot_token']['valid'] and validation_results['channel_name']['valid']:
        validation_results['overall_status'] = 'warning'  # Format valid but connection issues
    else:
        validation_results['overall_status'] = 'error'  # Format issues
    
    return jsonify(validation_results)

@app.route('/api/slack/channels')
def api_slack_channels():
    """API endpoint to get available Slack channels."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    # Check if Slack SDK is available
    if not SLACK_AVAILABLE:
        return jsonify({"error": "Slack SDK not available. Please install slack-sdk package."}), 400
    
    config = get_slack_config()
    bot_token = config.get('bot_token', {}).get('value', '')
    
    if not bot_token:
        return jsonify({"error": "Bot token not configured"}), 400
    
    try:
        test_client = WebClient(token=bot_token)
        response = test_client.conversations_list(types="public_channel,private_channel")
        
        channels = []
        for channel in response['channels']:
            channels.append({
                'id': channel['id'],
                'name': f"#{channel['name']}",
                'is_private': channel['is_private'],
                'is_member': channel.get('is_member', False)
            })
        
        return jsonify(channels)
    except SlackApiError as e:
        return jsonify({"error": f"Failed to fetch channels: {e.response['error']}"}), 400
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Alternative routes for frontend compatibility
@app.route('/api/config/slack')
def api_config_slack_get():
    """Alternative API endpoint to get Slack configuration (frontend compatibility)."""
    return api_slack_config()

@app.route('/api/config/slack', methods=['POST'])
def api_config_slack_post():
    """Alternative API endpoint to update Slack configuration (frontend compatibility)."""
    return api_update_slack_config()

# --- AI Configuration Routes ---
@app.route('/config/ai')
def ai_config_ui():
    """Serve the AI configuration UI."""
    return render_template('ai_config.html', page='ai')

@app.route('/config/ai-chat')
def ai_chat_config_ui():
    """Serve the AI Chat configuration UI."""
    return render_template('ai_chat_config.html', page='ai_chat')

@app.route('/chat')
def chat_ui():
    """Redirect to unified enhanced chat interface."""
    return redirect('/enhanced-chat', code=301)

@app.route('/enhanced-chat')
def enhanced_chat_ui():
    """Serve the Unified AI Security Chat Interface."""
    return render_template('enhanced_chat.html', page='enhanced_chat')

@app.route('/unified-chat')
def unified_chat_ui():
    """Serve the Unified AI Security Chat Interface (alias)."""
    return render_template('enhanced_chat.html', page='enhanced_chat')

@app.route('/config/falco')
def falco_config_ui():
    """Serve the Falco Integration Configuration page."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('falco_config.html', page='falco_config')

@app.route('/api-explorer')
def api_explorer_ui():
    """Serve the API Explorer interface."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('api_explorer.html', page='api_explorer')

@app.route('/api/ai/config')
def api_ai_config():
    """API endpoint to get AI configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    config = get_ai_config()
    return jsonify(config)

@app.route('/api/ai/config', methods=['POST'])
def api_update_ai_config():
    """API endpoint to update AI configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        valid_settings = ['provider_name', 'model_name', 'openai_model_name', 'gemini_model_name', 
                         'portkey_api_key', 'openai_virtual_key', 'gemini_virtual_key', 'ollama_api_url', 
                         'ollama_model_name', 'max_tokens', 'temperature', 'enabled', 'system_prompt', 
                         'ollama_timeout', 'ollama_keep_alive', 'ollama_parallel', 'openai_timeout', 'gemini_timeout']
        
        provider_changed = False
        new_provider = None
        
        for setting_name, setting_value in data.items():
            if setting_name in valid_settings:
                update_ai_config(setting_name, setting_value)
                
                # Track if provider_name was changed
                if setting_name == 'provider_name':
                    provider_changed = True
                    new_provider = setting_value
        
        # Auto-sync model name when provider changes (fix startup logic issue)
        if provider_changed and new_provider:
            sync_model_with_provider(new_provider)
        
        return jsonify({"success": True, "message": "AI configuration updated successfully"})
    except Exception as e:
        logging.error(f"Error updating AI config: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/ai/test', methods=['POST'])
def api_test_ai():
    """API endpoint to test AI provider connection."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    provider_name = data.get('provider_name', '').lower()
    
    if not provider_name:
        return jsonify({"error": "Provider name is required"}), 400
    
    if provider_name not in ['openai', 'gemini', 'ollama']:
        return jsonify({"error": "Invalid provider. Must be 'openai', 'gemini', or 'ollama'"}), 400
    
    result = test_ai_connection(provider_name, data)
    return jsonify(result)

@app.route('/api/ai/models')
def api_ai_models():
    """API endpoint to get available models for each provider."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    models = {
        'openai': [
            'gpt-4o', 'gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo', 
            'gpt-3.5-turbo-16k', 'gpt-4-32k'
        ],
        'gemini': [
            'gemini-pro', 'gemini-pro-vision', 'gemini-1.5-pro',
            'gemini-1.5-flash'
        ],
        'ollama': [
            'jimscard/whiterabbit-neo:latest', 'llama3', 'llama2', 'mistral', 'codellama', 'phi', 
            'neural-chat', 'starling-lm', 'orca-mini'
        ]
    }
    
    return jsonify(models)

@app.route('/api/ai/generate-sample', methods=['POST'])
def api_generate_sample():
    """API endpoint to generate a sample AI response for testing."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    provider_name = data.get('provider_name', '').lower()
    
    if not provider_name:
        return jsonify({"error": "Provider name is required"}), 400
    
    # Sample Falco alert for testing
    sample_alert = {
        'rule': 'Terminal shell in container',
        'priority': 'warning',
        'output': 'A shell was used as the entrypoint/exec point into a container (user=root)',
        'output_fields': {
            'proc.cmdline': '/bin/bash',
            'container.id': 'test123'
        }
    }
    
    try:
        # Generate explanation using current configuration
        explanation = generate_explanation_portkey(sample_alert)
        
        if explanation and not explanation.get('error'):
            return jsonify({
                'success': True,
                'sample_response': explanation,
                'provider_used': explanation.get('llm_provider', provider_name)
            })
        else:
            return jsonify({
                'success': False,
                'error': explanation.get('error', 'Failed to generate sample response')
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Sample generation failed: {str(e)}'
        }), 500

@app.route('/api/ai/chat', methods=['POST'])
def api_ai_chat():
    """Handle AI chat requests about specific alerts."""
    try:
        data = request.json or {}
        message = data.get('message', '').strip()
        alert = data.get('alert', {})
        chat_history = data.get('chat_history', [])
        
        if not message:
            return jsonify({"success": False, "error": "Message is required"}), 400
        
        if not alert:
            return jsonify({"success": False, "error": "Alert context is required"}), 400
        
        # Get AI configuration
        ai_config = get_ai_config()
        
        # Check if AI is enabled
        if ai_config.get('enabled', {}).get('value') != 'true':
            return jsonify({"success": False, "error": "AI analysis is disabled"}), 400
        
        provider_name = ai_config.get('provider_name', {}).get('value', 'openai').lower()
        model_name = ai_config.get('model_name', {}).get('value')
        max_tokens = int(ai_config.get('max_tokens', {}).get('value', '500'))
        temperature = float(ai_config.get('temperature', {}).get('value', '0.7'))
        
        # Build context-aware prompt
        system_prompt = f"""You are a cybersecurity expert assistant helping analyze Falco security alerts. 

Current Alert Context:
- Rule: {alert.get('rule', 'N/A')}
- Priority: {alert.get('priority', 'N/A')}
- Description: {alert.get('output', 'N/A')}
- Time: {alert.get('time', 'N/A')}

Additional Fields:
{json.dumps(alert.get('output_fields', {}), indent=2)}

Please provide helpful, accurate information about this security alert. Keep responses concise and actionable."""

        # Build conversation history
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add previous chat history
        for hist in chat_history[-5:]:  # Last 5 exchanges
            messages.append({"role": "user", "content": hist.get('user', '')})
            messages.append({"role": "assistant", "content": hist.get('ai', '')})
        
        # Add current message
        messages.append({"role": "user", "content": message})
        
        # Generate response based on provider
        response_text = ""
        
        if provider_name == "openai":
            portkey_api_key = ai_config.get('portkey_api_key', {}).get('value', '')
            openai_virtual_key = ai_config.get('openai_virtual_key', {}).get('value', '')
            
            if not portkey_api_key or not openai_virtual_key:
                return jsonify({"success": False, "error": "OpenAI configuration incomplete"}), 400
            
            from portkey_ai import Portkey
            client = Portkey(api_key=portkey_api_key, virtual_key=openai_virtual_key)
            
            response = client.chat.completions.create(
                model=model_name or "gpt-3.5-turbo",
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # Handle both object and dictionary response formats
            message = response.choices[0].message
            if hasattr(message, 'content'):
                response_text = message.content
            elif isinstance(message, dict):
                response_text = message.get('content', '')
            else:
                response_text = str(message)
            
        elif provider_name == "gemini":
            portkey_api_key = ai_config.get('portkey_api_key', {}).get('value', '')
            gemini_virtual_key = ai_config.get('gemini_virtual_key', {}).get('value', '')
            
            if not portkey_api_key or not gemini_virtual_key:
                return jsonify({"success": False, "error": "Gemini configuration incomplete"}), 400
            
            from portkey_ai import Portkey
            client = Portkey(api_key=portkey_api_key, virtual_key=gemini_virtual_key)
            
            response = client.chat.completions.create(
                model=model_name or "gemini-pro",
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # Handle both object and dictionary response formats
            message = response.choices[0].message
            if hasattr(message, 'content'):
                response_text = message.content
            elif isinstance(message, dict):
                response_text = message.get('content', '')
            else:
                response_text = str(message)
            
        elif provider_name == "ollama":
            ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
            ollama_model_name = ai_config.get('ollama_model_name', {}).get('value', 'tinyllama')
            ollama_timeout = int(ai_config.get('ollama_timeout', {}).get('value', '30'))
            
            # Convert messages to single prompt for Ollama
            conversation = "\n\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])
            
            # Normalize options for Ollama
            options = normalize_ai_options(provider_name, {
                "max_tokens": max_tokens,
                "temperature": temperature
            })
            
            ollama_payload = {
                "model": ollama_model_name,
                "prompt": conversation,
                "stream": False,
                "options": options
            }
            
            response = requests.post(ollama_api_url, json=ollama_payload, timeout=ollama_timeout)
            response.raise_for_status()
            
            response_data = response.json()
            response_text = response_data.get('response', '')
            
        else:
            return jsonify({"success": False, "error": f"Unsupported provider: {provider_name}"}), 400
        
        if not response_text:
            return jsonify({"success": False, "error": "Empty response from AI"}), 400
        
        return jsonify({
            "success": True,
            "response": response_text,
            "provider": provider_name,
            "model": model_name
        })
        
    except requests.exceptions.RequestException as e:
        logging.error(f"Network error in AI chat: {e}")
        return jsonify({"success": False, "error": f"Network error: {e}"}), 500
    except Exception as e:
        logging.error(f"Error in AI chat: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/ollama/models')
def api_ollama_models():
    """API endpoint to get locally available Ollama models."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        import requests
        ai_config = get_ai_config()
        ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
        
        # Extract base URL from generate endpoint
        base_url = ollama_api_url.replace('/api/generate', '')
        
        response = requests.get(f"{base_url}/api/tags", timeout=10)
        response.raise_for_status()
        
        models_data = response.json()
        models = [model['name'] for model in models_data.get('models', [])]
        
        return jsonify({
            'success': True,
            'models': models,
            'count': len(models)
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'Could not connect to Ollama: {str(e)}',
            'models': []
        }), 200  # Return 200 but with error info
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Error fetching models: {str(e)}',
            'models': []
        }), 500

@app.route('/api/ollama/pull', methods=['POST'])
def api_ollama_pull():
    """API endpoint to download/pull an Ollama model."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    model_name = data.get('model_name', '').strip()
    
    if not model_name:
        return jsonify({"error": "Model name is required"}), 400
    
    try:
        import requests
        ai_config = get_ai_config()
        ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
        
        # Extract base URL from generate endpoint
        base_url = ollama_api_url.replace('/api/generate', '')
        
        # Start the pull request (this returns immediately with a stream)
        response = requests.post(
            f"{base_url}/api/pull",
            json={"name": model_name},
            timeout=5
        )
        response.raise_for_status()
        
        return jsonify({
            'success': True,
            'message': f'Download started for {model_name}',
            'model_name': model_name
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'Could not start download: {str(e)}'
        }), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Download failed: {str(e)}'
        }), 500

@app.route('/api/ollama/status')
def api_ollama_status():
    """API endpoint to check if a specific Ollama model is available."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    model_name = request.args.get('model_name')
    if not model_name:
        return jsonify({"error": "model_name parameter is required"}), 400
    
    try:
        import requests
        ai_config = get_ai_config()
        ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
        
        # Extract base URL from generate endpoint
        base_url = ollama_api_url.replace('/api/generate', '')
        
        response = requests.get(f"{base_url}/api/tags", timeout=10)
        response.raise_for_status()
        
        models_data = response.json()
        available_models = [model['name'] for model in models_data.get('models', [])]
        
        is_available = model_name in available_models
        
        return jsonify({
            'model_name': model_name,
            'available': is_available,
            'status': 'downloaded' if is_available else 'not_found'
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'model_name': model_name,
            'available': False,
            'status': 'ollama_unavailable',
            'error': str(e)
        }), 200
    except Exception as e:
        return jsonify({
            'model_name': model_name,
            'available': False,
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/api/ollama/status/<model_name>')
def api_ollama_status_by_path(model_name):
    """API endpoint to check if a specific Ollama model is available (path parameter version)."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        import requests
        ai_config = get_ai_config()
        ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
        
        # Extract base URL from generate endpoint
        base_url = ollama_api_url.replace('/api/generate', '')
        
        response = requests.get(f"{base_url}/api/tags", timeout=10)
        response.raise_for_status()
        
        models_data = response.json()
        available_models = [model['name'] for model in models_data.get('models', [])]
        
        is_available = model_name in available_models
        
        return jsonify({
            'model_name': model_name,
            'available': is_available,
            'status': 'downloaded' if is_available else 'not_found',
            'progress': 100 if is_available else 0,
            'completed': is_available
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'model_name': model_name,
            'available': False,
            'status': 'ollama_unavailable',
            'error': str(e),
            'progress': 0,
            'completed': False
        }), 200
    except Exception as e:
        return jsonify({
            'model_name': model_name,
            'available': False,
            'status': 'error',
            'error': str(e),
            'progress': 0,
            'completed': False
        }), 500

@app.route('/api/ollama/download-progress')
def api_ollama_download_progress():
    """API endpoint to check download progress for a specific Ollama model."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    model_name = request.args.get('model_name')
    if not model_name:
        return jsonify({"error": "model_name parameter is required"}), 400
    
    try:
        import requests
        ai_config = get_ai_config()
        ollama_api_url = ai_config.get('ollama_api_url', {}).get('value', 'http://ollama:11434/api/generate')
        
        # Extract base URL from generate endpoint
        base_url = ollama_api_url.replace('/api/generate', '')
        
        # First check if model is already downloaded
        try:
            tags_response = requests.get(f"{base_url}/api/tags", timeout=5)
            tags_response.raise_for_status()
            models_data = tags_response.json()
            available_models = [model['name'] for model in models_data.get('models', [])]
            
            if model_name in available_models:
                return jsonify({
                    'model_name': model_name,
                    'status': 'completed',
                    'progress': 100,
                    'message': 'Model downloaded and ready'
                })
        except:
            pass
        
        # Try to get download progress by checking if model is being pulled
        # Ollama doesn't provide real-time progress via REST API, but we can infer download status
        try:
            # Check if we can generate with the model (will fail if not downloaded)
            # Normalize options for Ollama
            options = normalize_ai_options("ollama", {"max_tokens": 1})
            
            test_response = requests.post(
                f"{base_url}/api/generate",
                json={
                    "model": model_name,
                    "prompt": "test",
                    "stream": False,
                    "options": options
                },
                timeout=5
            )
            
            if test_response.status_code == 200:
                return jsonify({
                    'model_name': model_name,
                    'status': 'completed',
                    'progress': 100,
                    'message': 'Model downloaded and ready'
                })
            else:
                return jsonify({
                    'model_name': model_name,
                    'status': 'downloading',
                    'progress': -1,  # Unknown progress
                    'message': 'Model is downloading...'
                })
                
        except requests.exceptions.RequestException:
            return jsonify({
                'model_name': model_name,
                'status': 'not_started',
                'progress': 0,
                'message': 'Model not found or download not started'
            })
            
    except Exception as e:
        return jsonify({
            'model_name': model_name,
            'status': 'error',
            'progress': 0,
            'message': f'Error checking progress: {str(e)}'
        }), 500

@app.route('/api/ai/chat/config')
def api_ai_chat_config():
    """API endpoint to get AI Chat configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    # Get AI chat configuration (create if doesn't exist)
    config = get_ai_chat_config()
    return jsonify(config)

@app.route('/api/ai/chat/config', methods=['POST'])
def api_update_ai_chat_config():
    """API endpoint to update AI Chat configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        valid_settings = ['chat_enabled', 'chat_max_history', 'chat_session_timeout', 
                         'chat_context_alerts', 'chat_response_length', 'chat_tone',
                         'chat_include_remediation', 'chat_include_context']
        
        for setting_name, setting_value in data.items():
            if setting_name in valid_settings:
                update_ai_chat_config(setting_name, setting_value)
        
        return jsonify({"success": True, "message": "AI Chat configuration updated successfully"})
    except Exception as e:
        logging.error(f"Error updating AI Chat config: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/ai/chat/test', methods=['POST'])
def api_test_ai_chat():
    """API endpoint to test AI Chat functionality."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        # Get AI chat configuration
        chat_config = get_ai_chat_config()
        
        # Check if chat is enabled
        if chat_config.get('chat_enabled', {}).get('value') != 'true':
            return jsonify({"success": False, "message": "AI Chat is disabled"})
        
        # Get AI configuration to check if AI is working
        ai_config = get_ai_config()
        if ai_config.get('enabled', {}).get('value') != 'true':
            return jsonify({"success": False, "message": "AI analysis is disabled"})
        
        # Test basic AI connection
        provider_name = ai_config.get('provider_name', {}).get('value', 'openai')
        test_result = test_ai_connection(provider_name, ai_config)
        
        if test_result.get('success'):
            return jsonify({"success": True, "message": "AI Chat is ready and working"})
        else:
            return jsonify({"success": False, "message": f"AI Chat test failed: {test_result.get('error', 'Unknown error')}"})
            
    except Exception as e:
        logging.error(f"Error testing AI Chat: {e}")
        return jsonify({"success": False, "message": str(e)})

@app.route('/api/ai/system-prompt/reset', methods=['POST'])
def api_reset_system_prompt():
    """API endpoint to reset system prompt to default."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        # Clear the system prompt in database (empty string means use default)
        update_ai_config('system_prompt', '')
        
        # Get the default prompt that will be used
        default_prompt = load_system_prompt()
        
        return jsonify({
            'success': True,
            'message': 'System prompt reset to default',
            'default_prompt': default_prompt
        })
        
    except Exception as e:
        logging.error(f"Error resetting system prompt: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to reset system prompt: {str(e)}'
        }), 500

def get_slack_config():
    """Get all Slack configuration settings."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # First, ensure all expected settings exist in the database
    expected_settings = [
        ('bot_token', '', 'password', 'Slack Bot Token (xoxb-...)'),
        ('channel_name', '#security-alerts', 'string', 'Slack Channel Name'),
        ('enabled', 'true', 'boolean', 'Enable Slack Notifications'),
        ('username', 'Falco AI Alerts', 'string', 'Bot Display Name'),
        ('icon_emoji', ':shield:', 'string', 'Bot Icon Emoji'),
        ('template_style', 'detailed', 'select', 'Message Template Style'),
        ('min_priority_slack', 'warning', 'select', 'Minimum Priority for Slack'),
        ('include_commands', 'true', 'boolean', 'Include Suggested Commands'),
        ('thread_alerts', 'false', 'boolean', 'Use Threading for Related Alerts'),
        ('notification_throttling', 'false', 'boolean', 'Enable Notification Throttling'),
        ('throttle_threshold', '10', 'number', 'Throttle Threshold (alerts per 5 min)'),
        ('business_hours_only', 'false', 'boolean', 'Business Hours Filtering'),
        ('business_hours', '09:00-17:00', 'string', 'Business Hours Range'),
        ('escalation_enabled', 'false', 'boolean', 'Enable Alert Escalation'),
        ('escalation_interval', '30', 'number', 'Escalation Interval (minutes)'),
        ('digest_mode_enabled', 'false', 'boolean', 'Enable Daily Digest Mode'),
        ('digest_time', '09:00', 'string', 'Daily Digest Delivery Time')
    ]
    
    # Insert any missing settings
    for setting_name, default_value, setting_type, description in expected_settings:
        cursor.execute('''
            INSERT OR IGNORE INTO slack_config (setting_name, setting_value, setting_type, description)
            VALUES (?, ?, ?, ?)
        ''', (setting_name, default_value, setting_type, description))
    
    conn.commit()
    
    cursor.execute('SELECT setting_name, setting_value, setting_type, description FROM slack_config')
    settings = cursor.fetchall()
    conn.close()
    
    config = {}
    for setting in settings:
        config[setting[0]] = {
            'value': setting[1],
            'type': setting[2],
            'description': setting[3]
        }
    
    return config

def update_slack_config(setting_name, setting_value):
    """Update a Slack configuration setting."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE slack_config 
        SET setting_value = ?, updated_at = CURRENT_TIMESTAMP 
        WHERE setting_name = ?
    ''', (setting_value, setting_name))
    
    conn.commit()
    conn.close()
    
    # Invalidate feature cache when configuration changes
    global _feature_cache, _feature_cache_last_updated
    _feature_cache = None
    _feature_cache_last_updated = 0
    
    logging.info(f"Updated Slack config: {setting_name} = {setting_value}")

def sync_env_to_database():
    """Sync environment variables to database at startup."""
    try:
        env_bot_token = os.environ.get("SLACK_BOT_TOKEN", "")
        env_channel_name = os.environ.get("SLACK_CHANNEL_NAME", "")
        
        if env_bot_token:
            current_config = get_slack_config()
            current_token = current_config.get('bot_token', {}).get('value', '')
            
            # Only update if database is empty or has placeholder values
            if not current_token or current_token in ['', 'xoxb-your-token-here']:
                update_slack_config('bot_token', env_bot_token)
                logging.info(f"üîß ENV_SYNC: Updated Slack bot token from environment variable")
            else:
                logging.info(f"üìù ENV_SYNC: Slack bot token already configured in database, keeping existing value")
        
        if env_channel_name:
            update_slack_config('channel_name', env_channel_name)
            logging.info(f"üîß ENV_SYNC: Updated Slack channel to {env_channel_name} from environment variable")
            
        # Log current configuration status
        config = get_slack_config()
        token_status = "‚úÖ Configured" if config.get('bot_token', {}).get('value', '') else "‚ùå Not set"
        channel = config.get('channel_name', {}).get('value', 'Unknown')
        enabled = config.get('enabled', {}).get('value', 'false')
        
        logging.info(f"üì¢ SLACK_CONFIG: Token: {token_status} | Channel: {channel} | Enabled: {enabled}")
        
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è ENV_SYNC: Failed to sync environment variables: {e}")

def test_slack_connection(bot_token, channel_name):
    """Test Slack connection with provided credentials."""
    # Check if Slack SDK is available
    if not SLACK_AVAILABLE:
        return {'success': False, 'error': 'Slack SDK not available. Please install slack-sdk package.'}
    
    try:
        test_client = WebClient(token=bot_token)
        
        # Test API connection
        auth_response = test_client.auth_test()
        if not auth_response['ok']:
            return {'success': False, 'error': 'Invalid bot token'}
        
        # Test channel access
        try:
            test_response = test_client.chat_postMessage(
                channel=channel_name,
                text="üß™ Falco AI Alert System - Connection Test Successful! üéâ",
                blocks=[
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*üß™ Connection Test*\n‚úÖ Falco AI Alert System is successfully connected to Slack!\n\n*Bot Info:*\n‚Ä¢ User: " + auth_response.get('user', 'Unknown') + "\n‚Ä¢ Team: " + auth_response.get('team', 'Unknown') + "\n‚Ä¢ URL: " + auth_response.get('url', 'Unknown')
                        }
                    }
                ]
            )
            
            return {
                'success': True, 
                'message': 'Connection successful!',
                'bot_info': {
                    'user': auth_response.get('user'),
                    'team': auth_response.get('team'),
                    'url': auth_response.get('url')
                }
            }
        except SlackApiError as e:
            if e.response['error'] == 'channel_not_found':
                return {'success': False, 'error': f'Channel {channel_name} not found or bot not invited'}
            elif e.response['error'] == 'not_in_channel':
                return {'success': False, 'error': f'Bot not invited to channel {channel_name}'}
            else:
                return {'success': False, 'error': f'Channel error: {e.response["error"]}'}
                
    except SlackApiError as e:
        return {'success': False, 'error': f'Slack API error: {e.response["error"]}'}
    except Exception as e:
        return {'success': False, 'error': f'Connection error: {str(e)}'}

def sync_model_with_provider(provider_name):
    """Sync the main model_name field with the provider-specific model name."""
    try:
        ai_config = get_ai_config()
        
        if provider_name == 'openai':
            model_name = ai_config.get('openai_model_name', {}).get('value', 'gpt-3.5-turbo')
        elif provider_name == 'gemini':
            model_name = ai_config.get('gemini_model_name', {}).get('value', 'gemini-pro')
        elif provider_name == 'ollama':
            model_name = ai_config.get('ollama_model_name', {}).get('value', 'phi3:mini')
        else:
            logging.warning(f"Unknown AI provider: {provider_name}, using default model")
            model_name = 'gpt-3.5-turbo'
        
        update_ai_config('model_name', model_name)
        logging.info(f"üîÑ SYNC: Updated main model_name to '{model_name}' for provider '{provider_name}'")
        return model_name
    except Exception as e:
        logging.error(f"‚ùå Failed to sync model with provider: {e}")
        return None

def get_ai_config():
    """Get all AI configuration settings."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # First, ensure all expected settings exist in the database
    expected_settings = [
        ('provider_name', 'ollama', 'select', 'AI Provider (openai, gemini, ollama)'),
        ('model_name', 'tinyllama', 'string', 'Model Name'),
        ('openai_model_name', 'gpt-3.5-turbo', 'string', 'OpenAI Model Name'),
        ('gemini_model_name', 'gemini-pro', 'string', 'Gemini Model Name'),
        ('portkey_api_key', '', 'password', 'Portkey API Key (Security Layer for Cloud AI)'),
        ('openai_virtual_key', '', 'password', 'OpenAI Virtual Key (Portkey)'),
        ('gemini_virtual_key', '', 'password', 'Gemini Virtual Key (Portkey)'),
        ('ollama_api_url', 'http://prod-ollama:11434/api/generate', 'string', 'Ollama API URL'),
        ('ollama_model_name', 'tinyllama', 'string', 'Ollama Model Name'),
        ('ollama_timeout', '30', 'number', 'Ollama Request Timeout (seconds)'),
        ('ollama_keep_alive', '10', 'number', 'Ollama Keep Alive (minutes)'),
        ('ollama_parallel', '1', 'number', 'Ollama Parallel Requests'),
        ('openai_timeout', '30', 'number', 'OpenAI Request Timeout (seconds)'),
        ('gemini_timeout', '30', 'number', 'Gemini Request Timeout (seconds)'),
        ('max_tokens', '500', 'number', 'Maximum Response Tokens'),
        ('temperature', '0.7', 'number', 'Response Temperature (0.0-1.0)'),
        ('enabled', 'true', 'boolean', 'Enable AI Analysis'),
        ('system_prompt', '', 'textarea', 'AI System Prompt (leave empty for default)')
    ]
    
    # Insert any missing settings
    for setting_name, default_value, setting_type, description in expected_settings:
        cursor.execute('''
            INSERT OR IGNORE INTO ai_config (setting_name, setting_value, setting_type, description)
            VALUES (?, ?, ?, ?)
        ''', (setting_name, default_value, setting_type, description))
    
    conn.commit()
    
    cursor.execute('SELECT setting_name, setting_value, setting_type, description FROM ai_config')
    settings = cursor.fetchall()
    conn.close()
    
    config = {}
    for setting in settings:
        config[setting[0]] = {
            'value': setting[1],
            'type': setting[2],
            'description': setting[3]
        }
    
    return config

def update_ai_config(setting_name, setting_value):
    """Update an AI configuration setting."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE ai_config 
        SET setting_value = ?, updated_at = CURRENT_TIMESTAMP 
        WHERE setting_name = ?
    ''', (setting_value, setting_name))
    
    conn.commit()
    conn.close()
    
    # Invalidate feature cache when configuration changes
    global _feature_cache, _feature_cache_last_updated
    _feature_cache = None
    _feature_cache_last_updated = 0
    
    logging.info(f"Updated AI config: {setting_name} = {setting_value}")

def test_ai_connection(provider_name, config_data):
    """Test AI provider connection with provided configuration."""
    try:
        # Load system prompt for testing
        system_prompt = load_system_prompt()
        test_prompt = "This is a connection test. Please respond with 'Connection successful!' and a brief confirmation."
        
        if provider_name.lower() == "openai":
            try:
                from portkey_ai import Portkey
                
                portkey_api_key = config_data.get('portkey_api_key', '')
                openai_virtual_key = config_data.get('openai_virtual_key', '')
                model_name = config_data.get('model_name', 'gpt-3.5-turbo')
                
                if not portkey_api_key or not openai_virtual_key:
                    return {'success': False, 'error': 'Portkey API key and OpenAI virtual key are required'}
                
                client = Portkey(
                    api_key=portkey_api_key,
                    virtual_key=openai_virtual_key
                )
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": test_prompt}
                    ],
                    max_tokens=100
                )
                
                # Handle response format
                if hasattr(response, 'choices'):
                    content = response.choices[0].message.content
                else:
                    content = response['choices'][0]['message']['content']
                
                return {
                    'success': True,
                    'message': 'OpenAI connection successful!',
                    'response_preview': content[:200] + '...' if len(content) > 200 else content,
                    'model_used': model_name
                }
                
            except Exception as e:
                return {'success': False, 'error': f'OpenAI connection failed: {str(e)}'}
                
        elif provider_name.lower() == "gemini":
            try:
                from portkey_ai import Portkey
                
                portkey_api_key = config_data.get('portkey_api_key', '')
                gemini_virtual_key = config_data.get('gemini_virtual_key', '')
                model_name = config_data.get('model_name', 'gemini-pro')
                
                if not portkey_api_key or not gemini_virtual_key:
                    return {'success': False, 'error': 'Portkey API key and Gemini virtual key are required'}
                
                client = Portkey(
                    api_key=portkey_api_key,
                    virtual_key=gemini_virtual_key
                )
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": test_prompt}
                    ],
                    max_tokens=100
                )
                
                # Handle response format
                if hasattr(response, 'choices'):
                    content = response.choices[0].message.content
                else:
                    content = response['choices'][0]['message']['content']
                
                return {
                    'success': True,
                    'message': 'Gemini connection successful!',
                    'response_preview': content[:200] + '...' if len(content) > 200 else content,
                    'model_used': model_name
                }
                
            except Exception as e:
                return {'success': False, 'error': f'Gemini connection failed: {str(e)}'}
                
        elif provider_name.lower() == "ollama":
            try:
                import requests
                
                ollama_api_url = config_data.get('ollama_api_url', 'http://ollama:11434/api/generate')
                ollama_model_name = config_data.get('ollama_model_name', 'llama3')
                
                if not ollama_api_url:
                    return {'success': False, 'error': 'Ollama API URL is required'}
                
                # Test payload
                ollama_payload = {
                    "model": ollama_model_name,
                    "prompt": system_prompt + "\n\n" + test_prompt,
                    "stream": False,
                    "options": {
                        "num_predict": 100
                    }
                }
                
                # Get configurable timeout from provided config
                ollama_timeout = int(config_data.get('ollama_timeout', '30'))
                response = requests.post(ollama_api_url, json=ollama_payload, timeout=ollama_timeout)
                response.raise_for_status()
                
                response_data = response.json()
                content = response_data.get('response', '')
                
                if not content:
                    return {'success': False, 'error': 'Empty response from Ollama'}
                
                return {
                    'success': True,
                    'message': 'Ollama connection successful!',
                    'response_preview': content[:200] + '...' if len(content) > 200 else content,
                    'model_used': ollama_model_name
                }
                
            except requests.exceptions.RequestException as e:
                return {'success': False, 'error': f'Ollama connection failed: {str(e)}'}
            except Exception as e:
                return {'success': False, 'error': f'Ollama error: {str(e)}'}
                
        else:
            return {'success': False, 'error': f'Unsupported provider: {provider_name}'}
            
    except Exception as e:
        return {'success': False, 'error': f'Configuration test failed: {str(e)}'}

def get_ai_chat_config():
    """Get AI chat configuration from database."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute("SELECT name, value, description FROM config WHERE name LIKE 'chat_%'")
        config_rows = cursor.fetchall()
        conn.close()
        
        config = {}
        for row in config_rows:
            config[row[0]] = {
                'value': row[1],
                'description': row[2]
            }
        
        # Set defaults for missing chat settings
        defaults = {
            'chat_enabled': {'value': 'true', 'description': 'Enable AI Security Chat'},
            'chat_max_history': {'value': '50', 'description': 'Maximum chat messages to keep in history'},
            'chat_session_timeout': {'value': '30', 'description': 'Auto-clear chat after inactivity (minutes)'},
            'chat_context_alerts': {'value': '10', 'description': 'Number of recent alerts to include as context'},
            'chat_response_length': {'value': 'normal', 'description': 'AI response length (brief/normal/detailed)'},
            'chat_tone': {'value': 'professional', 'description': 'AI response tone (professional/casual/technical/educational)'},
            'chat_include_remediation': {'value': 'true', 'description': 'Include remediation steps in responses'},
            'chat_include_context': {'value': 'true', 'description': 'Include alert context in responses'}
        }
        
        for key, default_config in defaults.items():
            if key not in config:
                config[key] = default_config
        
        return config
        
    except Exception as e:
        logging.error(f"Error getting AI chat config: {e}")
        return {}

def update_ai_chat_config(setting_name, setting_value):
    """Update AI chat configuration in database."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Define descriptions for chat settings
        descriptions = {
            'chat_enabled': 'Enable AI Security Chat',
            'chat_max_history': 'Maximum chat messages to keep in history',
            'chat_session_timeout': 'Auto-clear chat after inactivity (minutes)',
            'chat_context_alerts': 'Number of recent alerts to include as context',
            'chat_response_length': 'AI response length (brief/normal/detailed)',
            'chat_tone': 'AI response tone (professional/casual/technical/educational)',
            'chat_include_remediation': 'Include remediation steps in responses',
            'chat_include_context': 'Include alert context in responses'
        }
        
        description = descriptions.get(setting_name, 'AI Chat configuration setting')
        
        cursor.execute("""
            INSERT OR REPLACE INTO config (name, value, description)
            VALUES (?, ?, ?)
        """, (setting_name, setting_value, description))
        
        conn.commit()
        conn.close()
        
        logging.info(f"Updated AI chat config: {setting_name} = {setting_value}")
        
    except Exception as e:
        logging.error(f"Error updating AI chat config: {e}")
        raise

# --- General Configuration Functions ---
def get_general_config():
    """Get general configuration settings from database."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('SELECT setting_name, setting_value, setting_type, description FROM general_config')
    rows = cursor.fetchall()
    conn.close()
    
    config = {}
    for row in rows:
        config[row[0]] = {
            'value': row[1],
            'type': row[2],
            'description': row[3]
        }
    
    return config

def update_general_config(setting_name, setting_value):
    """Update a general configuration setting."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE general_config 
        SET setting_value = ?, updated_at = CURRENT_TIMESTAMP 
        WHERE setting_name = ?
    ''', (setting_value, setting_name))
    
    conn.commit()
    conn.close()
    
    logging.info(f"Updated general config: {setting_name} = {setting_value}")

def get_cached_general_config():
    """Get general configuration with caching for performance."""
    global _general_config_cache, _general_config_last_updated
    
    # Initialize cache if needed
    if '_general_config_cache' not in globals():
        _general_config_cache = None
        _general_config_last_updated = 0
    
    current_time = datetime.datetime.now().timestamp()
    
    # Refresh cache every 60 seconds
    if _general_config_cache is None or (current_time - _general_config_last_updated) > 60:
        _general_config_cache = get_general_config()
        _general_config_last_updated = current_time
    
    return _general_config_cache

def get_general_setting(setting_name, default_value=None):
    """Get a specific general configuration setting with fallback to default."""
    config = get_cached_general_config()
    setting = config.get(setting_name, {})
    return setting.get('value', default_value)

# --- General Configuration Endpoints ---
@app.route('/config/general')
def general_config_ui():
    """Render general configuration page."""
    if not WEB_UI_ENABLED:
        return "Web UI is disabled", 404
    return render_template('general_config.html', page='general')

@app.route('/api/general/config')
def api_general_config():
    """Get general configuration settings."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI is disabled"}), 404
    
    config = get_general_config()
    return jsonify(config)

@app.route('/api/general/config', methods=['POST'])
def api_update_general_config():
    """Update general configuration settings."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI is disabled"}), 404
    
    data = request.json
    if not data:
        return jsonify({"error": "No configuration data provided"}), 400
    
    # Update multiple settings at once
    for setting_name, setting_value in data.items():
        update_general_config(setting_name, setting_value)
    
    return jsonify({"message": "General configuration updated successfully"})

@app.route('/api/general/test', methods=['POST'])
def api_test_general_config():
    """Test general configuration settings."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI is disabled"}), 404
    
    data = request.json
    if not data:
        return jsonify({"error": "No configuration data provided"}), 400
    
    # Test log level setting
    log_level = data.get('log_level', 'INFO')
    valid_log_levels = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']
    
    if log_level not in valid_log_levels:
        return jsonify({
            "success": False, 
            "message": f"Invalid log level '{log_level}'. Valid levels: {', '.join(valid_log_levels)}"
        })
    
    # Test priority setting
    min_priority = data.get('min_priority', 'warning')
    valid_priorities = ["debug", "informational", "notice", "warning", "error", "critical", "alert", "emergency"]
    
    if min_priority not in valid_priorities:
        return jsonify({
            "success": False,
            "message": f"Invalid priority '{min_priority}'. Valid priorities: {', '.join(valid_priorities)}"
        })
    
    # Test numeric settings
    numeric_settings = {
        'ignore_older_minutes': 'Ignore Older Minutes',
        'web_ui_port': 'Web UI Port',
        'falco_ai_port': 'Falco AI Port',
        'deduplication_window_minutes': 'Deduplication Window',
        'max_alerts_storage': 'Max Alerts Storage',
        'alert_retention_days': 'Alert Retention Days',
        'max_alerts_per_minute': 'Max Alerts Per Minute',
        'batch_size': 'Batch Size',
        'correlation_window_minutes': 'Correlation Window Minutes'
    }
    
    for setting_key, setting_label in numeric_settings.items():
        if setting_key in data:
            try:
                value = int(data[setting_key])
                if value < 0:
                    return jsonify({
                        "success": False,
                        "message": f"{setting_label} must be a positive number"
                    })
            except ValueError:
                return jsonify({
                    "success": False,
                    "message": f"{setting_label} must be a valid number"
                })
    
    return jsonify({
        "success": True,
        "message": "General configuration validation successful"
    })

@app.route('/api/general/reset', methods=['POST'])
def api_reset_general_config():
    """Reset general configuration to defaults."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI is disabled"}), 404
    
    # Reset to default values
    defaults = {
        'min_priority': 'warning',
        'ignore_older_minutes': '1',
        'web_ui_enabled': 'true',
        'web_ui_port': '8081',
        'falco_ai_port': '8080',
        'log_level': 'INFO',
        'deduplication_enabled': 'true',
        'deduplication_window_minutes': '60',
        'max_alerts_storage': '10000',
        'alert_retention_days': '30',
        'rate_limit_enabled': 'false',
        'max_alerts_per_minute': '60',
        'batch_processing_enabled': 'false',
        'batch_size': '10',
        'alert_correlation_enabled': 'false',
        'correlation_window_minutes': '15'
    }
    
    for setting_name, setting_value in defaults.items():
        update_general_config(setting_name, setting_value)
    
    return jsonify({"message": "General configuration reset to defaults"})

@app.route('/config/features')
def feature_status_ui():
    """Render feature status page."""
    if not WEB_UI_ENABLED:
        return "Web UI is disabled", 404
    return render_template('feature_status.html', page='features')

@app.route('/api/falco/config')
def api_falco_config():
    """Get Falco webhook configuration."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI is disabled"}), 404
    
    try:
        # Get the actual port from configuration
        general_config = get_cached_general_config()
        webhook_port = general_config.get('falco_ai_port', {}).get('value', '8080')
        
        # Get request host and protocol
        host = request.host.split(':')[0]  # Remove port if present
        protocol = 'https' if request.is_secure else 'http'
        
        # Build webhook URL
        webhook_url = f"{protocol}://{host}:{webhook_port}/falco-webhook"
        
        # Generate Falco YAML configuration
        falco_yaml = f"""# Falco HTTP Output Configuration
# Add this to your falco.yaml file

http_output:
  enabled: true
  url: "{webhook_url}"
  user_agent: "Falco Webhook"
  # Optional: Add custom headers if needed
  # headers:
  #   X-Custom-Header: "value"

# Optional: JSON output formatting
json_output: true
json_include_output_property: true
json_include_tags_property: true

# Optional: Configure log level and priority
log_level: info
priority: warning

# Optional: Configure buffering for better performance
# buffered_outputs: true
# outputs:
#   rate: 1000
#   max_burst: 10000"""
        
        return jsonify({
            'success': True,
            'webhook_url': webhook_url,
            'webhook_port': webhook_port,
            'falco_yaml': falco_yaml,
            'host': host,
            'protocol': protocol
        })
        
    except Exception as e:
        logging.error(f"Error getting Falco config: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# --- Feature Detection and Auto-Configuration ---

# Feature detection cache for performance
_feature_cache = None
_feature_cache_last_updated = 0

def get_cached_features():
    """Get feature detection results with caching for performance."""
    global _feature_cache, _feature_cache_last_updated
    
    current_time = datetime.datetime.now().timestamp()
    
    # Refresh cache every 5 minutes (feature detection is expensive)
    if _feature_cache is None or (current_time - _feature_cache_last_updated) > 300:
        _feature_cache = detect_available_features()
        _feature_cache_last_updated = current_time
        logging.debug(f"üîÑ FEATURE_CACHE: Refreshed feature detection cache")
    
    return _feature_cache

def detect_available_features():
    """
    Intelligently detect available features based on multiple configuration sources.
    Kubernetes-aware detection that checks environment variables, mounted files, 
    service discovery, and runtime dependencies.
    """
    features = {
        'slack': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': []
        },
        'openai': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': []
        },
        'gemini': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': []
        },
        'ollama': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': []
        },
        'portkey': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': []
        },
        'weaviate': {
            'available': False,
            'configured': False,
            'implemented': False,
            'status': 'not_configured',
            'reason': '',
            'auto_configured': False,
            'implementation_status': 'not_checked',
            'config_sources': [],
            'dependencies_available': False
        },
        'multilingual': {
            'available': True,
            'configured': False,
            'implemented': True,
            'status': 'beta_disabled',
            'reason': '‚ö†Ô∏è Multilingual AI translation system (EXPERIMENTAL - May not work properly)',
            'auto_configured': False,
            'implementation_status': 'beta_experimental',
            'beta': True,
            'experimental': True,
            'version': '1.0.0-beta',
            'supported_languages': 24,
            'translation_providers': ['Local AI', 'Google Translate', 'DeepL', 'Azure Translator'],
            'config_sources': [],
            'warnings': [
                'This is an experimental feature that may not work reliably',
                'LLM-based UI translation can be slow and inconsistent',
                'Resource intensive - may impact system performance',
                'Not recommended for production use'
            ]
        },
        'recommended_provider': None,
        'auto_configuration_applied': False,
        'deployment_type': 'unknown',
        'kubernetes_detected': False,
        'config_summary': {
            'env_vars': 0,
            'mounted_files': 0,
            'services_detected': 0,
            'dependencies_verified': 0
        }
    }
    
    # Enhanced deployment environment detection
    features['deployment_type'], features['kubernetes_detected'] = _detect_deployment_environment()
    
    # Detect configuration from multiple sources
    config_resolver = KubernetesConfigResolver()
    
    # === WEAVIATE DETECTION ===
    weaviate_config = config_resolver.resolve_config('weaviate', {
        'host': ['WEAVIATE_HOST', 'WEAVIATE_SERVICE_HOST'],
        'port': ['WEAVIATE_PORT', 'WEAVIATE_SERVICE_PORT'], 
        'grpc_port': ['WEAVIATE_GRPC_PORT'],
        'enabled': ['WEAVIATE_ENABLED']
    })
    
    # Check Weaviate dependencies
    weaviate_deps = _check_python_dependencies(['weaviate', 'numpy', 'scikit-learn'])
    features['weaviate']['dependencies_available'] = all(weaviate_deps.values())
    
    if weaviate_config['enabled'] and features['weaviate']['dependencies_available']:
        # Test actual connectivity
        weaviate_connectivity = _test_weaviate_connectivity(
            weaviate_config.get('host', 'weaviate'), 
            weaviate_config.get('port', 8080)
        )
        
        if weaviate_connectivity['reachable']:
            features['weaviate']['available'] = True
            features['weaviate']['configured'] = True
            features['weaviate']['status'] = 'configured'
            features['weaviate']['reason'] = f"Weaviate service reachable at {weaviate_connectivity['endpoint']}"
            features['weaviate']['auto_configured'] = True
            features['weaviate']['config_sources'] = weaviate_config['sources']
            logging.debug("‚úÖ FEATURE_DETECTION: Weaviate analytics available")
        else:
            features['weaviate']['available'] = True
            features['weaviate']['configured'] = False
            features['weaviate']['status'] = 'unreachable'
            features['weaviate']['reason'] = f"Weaviate configured but unreachable: {weaviate_connectivity['error']}"
            features['weaviate']['config_sources'] = weaviate_config['sources']
    elif weaviate_config['enabled'] and not features['weaviate']['dependencies_available']:
        features['weaviate']['available'] = False
        features['weaviate']['configured'] = False
        features['weaviate']['status'] = 'missing_dependencies'
        missing_deps = [dep for dep, available in weaviate_deps.items() if not available]
        features['weaviate']['reason'] = f"Weaviate enabled but missing dependencies: {missing_deps}"
        features['weaviate']['config_sources'] = weaviate_config['sources']
    else:
        features['weaviate']['available'] = False
        features['weaviate']['configured'] = False
        features['weaviate']['status'] = 'not_configured'
        features['weaviate']['reason'] = 'Weaviate not enabled or not configured'
    
    # === SLACK DETECTION ===
    slack_config = config_resolver.resolve_config('slack', {
        'bot_token': ['SLACK_BOT_TOKEN'],
        'channel': ['SLACK_CHANNEL_NAME'],
        'enabled': ['SLACK_ENABLED']
    })
    
    slack_token = slack_config.get('bot_token', '')
    if slack_token and slack_token != "xoxb-your-token-here" and slack_token.startswith("xoxb-"):
        features['slack']['available'] = True
        features['slack']['configured'] = True
        features['slack']['status'] = 'configured'
        features['slack']['reason'] = 'Valid Slack bot token detected'
        features['slack']['auto_configured'] = True
        features['slack']['config_sources'] = slack_config['sources']
        logging.debug("‚úÖ FEATURE_DETECTION: Slack integration auto-configured")
    elif slack_token and slack_token != "xoxb-your-token-here":
        features['slack']['available'] = True
        features['slack']['configured'] = False
        features['slack']['status'] = 'invalid_token'
        features['slack']['reason'] = 'Invalid Slack bot token format'
        features['slack']['config_sources'] = slack_config['sources']
    else:
        features['slack']['available'] = False
        features['slack']['configured'] = False
        features['slack']['status'] = 'not_configured'
        features['slack']['reason'] = 'No Slack bot token provided'
    
    # === PORTKEY DETECTION ===
    portkey_config = config_resolver.resolve_config('portkey', {
        'api_key': ['PORTKEY_API_KEY'],
        'enabled': ['PORTKEY_ENABLED']
    })
    
    portkey_key = portkey_config.get('api_key', '')
    if portkey_key and portkey_key != "pk-your-portkey-api-key-here" and portkey_key.startswith("pk-"):
        features['portkey']['available'] = True
        features['portkey']['configured'] = True
        features['portkey']['status'] = 'configured'
        features['portkey']['reason'] = 'Valid Portkey API key detected'
        features['portkey']['auto_configured'] = True
        features['portkey']['config_sources'] = portkey_config['sources']
        logging.debug("‚úÖ FEATURE_DETECTION: Portkey security layer auto-configured")
    elif portkey_key and portkey_key != "pk-your-portkey-api-key-here":
        features['portkey']['available'] = True
        features['portkey']['configured'] = False
        features['portkey']['status'] = 'invalid_key'
        features['portkey']['reason'] = 'Invalid Portkey API key format'
        features['portkey']['config_sources'] = portkey_config['sources']
    else:
        features['portkey']['available'] = False
        features['portkey']['configured'] = False
        features['portkey']['status'] = 'not_configured'
        features['portkey']['reason'] = 'No Portkey API key provided'
    
    # === OPENAI DETECTION ===
    openai_config = config_resolver.resolve_config('openai', {
        'virtual_key': ['OPENAI_VIRTUAL_KEY'],
        'api_key': ['OPENAI_API_KEY'],  # Direct API key as fallback
        'enabled': ['OPENAI_ENABLED']
    })
    
    openai_vkey = openai_config.get('virtual_key', '')
    if features['portkey']['configured'] and openai_vkey and openai_vkey != "openai-your-virtual-key-here":
        features['openai']['available'] = True
        features['openai']['configured'] = True
        features['openai']['status'] = 'configured'
        features['openai']['reason'] = 'OpenAI virtual key detected with Portkey'
        features['openai']['auto_configured'] = True
        features['openai']['config_sources'] = openai_config['sources']
        logging.debug("‚úÖ FEATURE_DETECTION: OpenAI provider auto-configured")
    elif openai_vkey and openai_vkey != "openai-your-virtual-key-here":
        features['openai']['available'] = True
        features['openai']['configured'] = False
        features['openai']['status'] = 'missing_portkey'
        features['openai']['reason'] = 'OpenAI virtual key found but Portkey not configured'
        features['openai']['config_sources'] = openai_config['sources']
    elif features['portkey']['configured']:
        features['openai']['available'] = True
        features['openai']['configured'] = False
        features['openai']['status'] = 'missing_virtual_key'
        features['openai']['reason'] = 'Portkey configured but no OpenAI virtual key'
    else:
        features['openai']['available'] = False
        features['openai']['configured'] = False
        features['openai']['status'] = 'not_configured'
        features['openai']['reason'] = 'No OpenAI virtual key or Portkey configuration'
    
    # === GEMINI DETECTION ===
    gemini_config = config_resolver.resolve_config('gemini', {
        'virtual_key': ['GEMINI_VIRTUAL_KEY'], 
        'api_key': ['GEMINI_API_KEY'],  # Direct API key as fallback
        'enabled': ['GEMINI_ENABLED']
    })
    
    gemini_vkey = gemini_config.get('virtual_key', '')
    if features['portkey']['configured'] and gemini_vkey and gemini_vkey != "gemini-your-virtual-key-here":
        features['gemini']['available'] = True
        features['gemini']['configured'] = True
        features['gemini']['status'] = 'configured'
        features['gemini']['reason'] = 'Gemini virtual key detected with Portkey'
        features['gemini']['auto_configured'] = True
        features['gemini']['config_sources'] = gemini_config['sources']
        logging.debug("‚úÖ FEATURE_DETECTION: Gemini provider auto-configured")
    elif gemini_vkey and gemini_vkey != "gemini-your-virtual-key-here":
        features['gemini']['available'] = True
        features['gemini']['configured'] = False
        features['gemini']['status'] = 'missing_portkey'
        features['gemini']['reason'] = 'Gemini virtual key found but Portkey not configured'
        features['gemini']['config_sources'] = gemini_config['sources']
    elif features['portkey']['configured']:
        features['gemini']['available'] = True
        features['gemini']['configured'] = False
        features['gemini']['status'] = 'missing_virtual_key'
        features['gemini']['reason'] = 'Portkey configured but no Gemini virtual key'
    else:
        features['gemini']['available'] = False
        features['gemini']['configured'] = False
        features['gemini']['status'] = 'not_configured'
        features['gemini']['reason'] = 'No Gemini virtual key or Portkey configuration'
    
    # === OLLAMA DETECTION ===
    ollama_config = config_resolver.resolve_config('ollama', {
        'api_url': ['OLLAMA_API_URL'],
        'host': ['OLLAMA_HOST', 'OLLAMA_SERVICE_HOST'],
        'port': ['OLLAMA_PORT', 'OLLAMA_SERVICE_PORT'],
        'model': ['OLLAMA_MODEL', 'OLLAMA_MODEL_NAME'],
        'enabled': ['OLLAMA_ENABLED']
    })
    
    # Build Ollama URL from components if not directly specified
    ollama_url = ollama_config.get('api_url', '')
    if not ollama_url and ollama_config.get('host'):
        host = ollama_config['host']
        port = ollama_config.get('port', '11434')
        ollama_url = f"http://{host}:{port}/api/generate"
    
    if ollama_url and ollama_url != "http://your-ollama-url:11434/api/generate":
        connectivity = _test_ollama_connectivity(ollama_url)
        if connectivity['reachable']:
            features['ollama']['available'] = True
            features['ollama']['configured'] = True
            features['ollama']['status'] = 'configured'
            features['ollama']['reason'] = f"Ollama server detected and responding at {connectivity['endpoint']}"
            features['ollama']['auto_configured'] = True
            features['ollama']['config_sources'] = ollama_config['sources']
            logging.debug("‚úÖ FEATURE_DETECTION: Ollama provider auto-configured")
        else:
            features['ollama']['available'] = True
            features['ollama']['configured'] = False
            features['ollama']['status'] = 'unreachable'
            features['ollama']['reason'] = f"Ollama configured but unreachable: {connectivity['error']}"
            features['ollama']['config_sources'] = ollama_config['sources']
    else:
        features['ollama']['available'] = False
        features['ollama']['configured'] = False
        features['ollama']['status'] = 'not_configured'
        features['ollama']['reason'] = 'No Ollama configuration found'
    
    # === MULTILINGUAL DETECTION ===
    multilingual_config = config_resolver.resolve_config('multilingual', {
        'enabled': ['MULTILINGUAL_ENABLED'],
        'default_language': ['DEFAULT_LANGUAGE'],
        'translation_provider': ['TRANSLATION_PROVIDER']
    })
    
    try:
        translation_service = get_multilingual_service()
        multilingual_db_config = get_multilingual_config()
        
        # Default to disabled unless explicitly enabled
        master_enabled = multilingual_db_config.get('master_enabled', 'false') == 'true'
        
        if master_enabled and translation_service.is_available():
            features['multilingual']['configured'] = True
            features['multilingual']['status'] = 'beta_active'
            features['multilingual']['reason'] = f'‚ö†Ô∏è EXPERIMENTAL: Multilingual system active with {features["multilingual"]["supported_languages"]} languages (Beta - May not work properly)'
            features['multilingual']['config_sources'] = multilingual_config['sources']
            
            current_model = translation_service.model_name
            if current_model:
                features['multilingual']['current_model'] = current_model
                features['multilingual']['reason'] += f' using {current_model}'
                
            logging.warning("‚ö†Ô∏è FEATURE_DETECTION: Multilingual system (EXPERIMENTAL) - Active but may not work reliably")
        elif master_enabled:
            features['multilingual']['configured'] = False
            features['multilingual']['status'] = 'beta_partial'
            features['multilingual']['reason'] = '‚ö†Ô∏è EXPERIMENTAL: Multilingual enabled but AI translation service unavailable (Beta)'
        else:
            features['multilingual']['configured'] = False
            features['multilingual']['status'] = 'beta_disabled'
            features['multilingual']['reason'] = '‚ö†Ô∏è EXPERIMENTAL: Multilingual system disabled (Beta feature - not recommended for production)'
            
    except Exception as e:
        features['multilingual']['configured'] = False
        features['multilingual']['status'] = 'beta_error'
        features['multilingual']['reason'] = f'‚ö†Ô∏è EXPERIMENTAL: Multilingual system error: {str(e)} (Beta)'
        logging.warning(f"‚ùå FEATURE_DETECTION: Multilingual system detection failed: {e}")
    
    # Update configuration summary
    all_configs = [slack_config, portkey_config, openai_config, gemini_config, ollama_config, weaviate_config, multilingual_config]
    features['config_summary']['env_vars'] = sum(len([s for s in config['sources'] if s.startswith('env:')]) for config in all_configs)
    features['config_summary']['mounted_files'] = sum(len([s for s in config['sources'] if s.startswith('file:')]) for config in all_configs)
    features['config_summary']['services_detected'] = sum(len([s for s in config['sources'] if s.startswith('service:')]) for config in all_configs)
    
    # Determine recommended provider
    if features['openai']['configured']:
        features['recommended_provider'] = 'openai'
    elif features['gemini']['configured']:
        features['recommended_provider'] = 'gemini'
    elif features['ollama']['configured']:
        features['recommended_provider'] = 'ollama'
    elif features['ollama']['available']:
        features['recommended_provider'] = 'ollama'
    else:
        features['recommended_provider'] = 'ollama'
    
    # Check if any auto-configuration was applied
    features['auto_configuration_applied'] = any(
        feature['auto_configured'] for feature in features.values() if isinstance(feature, dict)
    )
    
    # Verify actual implementation in UI/backend
    _verify_feature_implementation(features)
    
    # Log deployment summary
    deployment_info = f"Deployment: {features['deployment_type']}"
    if features['kubernetes_detected']:
        deployment_info += " (Kubernetes detected)"
    deployment_info += f" | Config sources: {features['config_summary']['env_vars']} env vars, {features['config_summary']['mounted_files']} files, {features['config_summary']['services_detected']} services"
    logging.info(f"üîç FEATURE_DETECTION: {deployment_info}")
    
    return features


class KubernetesConfigResolver:
    """Enhanced configuration resolver that can detect config from multiple sources."""
    
    def __init__(self):
        self.secret_paths = ['/var/secrets/', '/etc/secrets/', '/run/secrets/']
        self.config_paths = ['/etc/config/', '/var/config/', '/etc/falco-config/']
        
    def resolve_config(self, service_name, config_keys):
        """
        Resolve configuration from multiple sources in priority order:
        1. Environment variables
        2. Mounted secrets/config files
        3. Service discovery
        4. Default values
        """
        resolved = {'sources': []}
        
        for config_key, env_vars in config_keys.items():
            value = None
            source = None
            
            # 1. Check environment variables
            for env_var in env_vars:
                env_value = os.environ.get(env_var)
                if env_value:
                    value = env_value
                    source = f"env:{env_var}"
                    break
            
            # 2. Check mounted files (Kubernetes secrets/configmaps)
            if not value:
                value, source = self._check_mounted_files(service_name, config_key)
            
            # 3. Check service discovery
            if not value and config_key in ['host', 'url']:
                value, source = self._check_service_discovery(service_name)
            
            # 4. Apply default values for boolean configs
            if not value and config_key in ['enabled']:
                # Default to true if service is detected via other means
                if any(resolved.get(k) for k in ['host', 'url', 'api_key', 'token']):
                    value = 'true'
                    source = 'default:auto-detected'
                else:
                    value = 'false'
                    source = 'default:disabled'
            
            if value:
                resolved[config_key] = value
                if source not in resolved['sources']:
                    resolved['sources'].append(source)
        
        return resolved
    
    def _check_mounted_files(self, service_name, config_key):
        """Check for configuration in mounted files (K8s secrets/configmaps)."""
        possible_filenames = [
            f"{service_name}-{config_key}",
            f"{service_name}_{config_key}",
            f"{config_key}",
            f"{service_name.upper()}_{config_key.upper()}",
            f"{service_name}-credentials",
            f"{service_name}-config"
        ]
        
        for base_path in self.secret_paths + self.config_paths:
            if os.path.exists(base_path):
                for filename in possible_filenames:
                    file_path = os.path.join(base_path, filename)
                    if os.path.isfile(file_path):
                        try:
                            with open(file_path, 'r') as f:
                                content = f.read().strip()
                                if content:
                                    return content, f"file:{file_path}"
                        except Exception as e:
                            logging.debug(f"Error reading {file_path}: {e}")
                            continue
        
        return None, None
    
    def _check_service_discovery(self, service_name):
        """Check for service via Kubernetes service discovery."""
        # Common Kubernetes service naming patterns
        service_names = [
            service_name,
            f"{service_name}-service", 
            f"{service_name}-svc",
            f"svc-{service_name}",
            f"{service_name.replace('_', '-')}"
        ]
        
        for svc_name in service_names:
            # Check if service is resolvable via DNS
            try:
                import socket
                socket.gethostbyname(svc_name)
                return svc_name, f"service:{svc_name}"
            except socket.gaierror:
                continue
        
        return None, None


def _detect_deployment_environment():
    """Enhanced deployment environment detection."""
    deployment_type = 'local'
    kubernetes_detected = False
    
    # Check for Kubernetes indicators
    k8s_indicators = [
        os.path.exists('/var/run/secrets/kubernetes.io'),
        os.environ.get('KUBERNETES_SERVICE_HOST'),
        os.environ.get('KUBERNETES_PORT'),
        os.path.exists('/etc/kubernetes'),
        'k8s' in os.environ.get('HOSTNAME', '').lower(),
        'kubernetes' in os.environ.get('HOSTNAME', '').lower()
    ]
    
    if any(k8s_indicators):
        kubernetes_detected = True
        deployment_type = 'kubernetes'
        
        # Determine if it's dev/staging/prod based on namespace or labels
        namespace = os.environ.get('POD_NAMESPACE', os.environ.get('NAMESPACE', ''))
        hostname = os.environ.get('HOSTNAME', '')
        
        if any(env in namespace.lower() for env in ['dev', 'develop', 'staging', 'test']):
            deployment_type = 'kubernetes-dev'
        elif any(env in namespace.lower() for env in ['prod', 'production']):
            deployment_type = 'kubernetes-prod'
        elif any(env in hostname.lower() for env in ['dev', 'test']):
            deployment_type = 'kubernetes-dev'
        elif any(env in hostname.lower() for env in ['prod']):
            deployment_type = 'kubernetes-prod'
    else:
        # Docker/local detection
        hostname = os.environ.get('HOSTNAME', '')
        if 'docker' in hostname.lower():
            deployment_type = 'docker'
        elif any(env in hostname.lower() for env in ['dev', 'localhost']):
            deployment_type = 'development'
        elif any(env in hostname.lower() for env in ['prod']):
            deployment_type = 'production'
    
    return deployment_type, kubernetes_detected


def _check_python_dependencies(modules):
    """Check if Python modules are available for import."""
    results = {}
    for module in modules:
        try:
            __import__(module)
            results[module] = True
        except ImportError:
            results[module] = False
    return results


def _test_weaviate_connectivity(host, port):
    """Test if Weaviate service is reachable."""
    try:
        import requests
        endpoint = f"http://{host}:{port}"
        response = requests.get(f"{endpoint}/v1/meta", timeout=5)
        if response.status_code == 200:
            return {
                'reachable': True,
                'endpoint': endpoint,
                'version': response.json().get('version', 'unknown')
            }
        else:
            return {
                'reachable': False,
                'endpoint': endpoint,
                'error': f"HTTP {response.status_code}"
            }
    except Exception as e:
        return {
            'reachable': False,
            'endpoint': f"http://{host}:{port}",
            'error': str(e)
        }


def _test_ollama_connectivity(api_url):
    """Test if Ollama service is reachable."""
    try:
        import requests
        # Convert generate URL to tags URL for health check
        health_url = api_url.replace('/api/generate', '/api/tags')
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            return {
                'reachable': True,
                'endpoint': health_url,
                'models': response.json().get('models', [])
            }
        else:
            return {
                'reachable': False,
                'endpoint': health_url,
                'error': f"HTTP {response.status_code}"
            }
    except Exception as e:
        return {
            'reachable': False,
            'endpoint': api_url,
            'error': str(e)
        }

def _verify_feature_implementation(features):
    """
    Verify that detected features are actually implemented and working in the current UI/backend.
    Updates the features dict with implementation status.
    """
    
    # Check Slack implementation
    try:
        # Check if Slack configuration UI exists and is accessible
        slack_config = get_slack_config()
        if slack_config and len(slack_config) > 0:
            features['slack']['implemented'] = True
            features['slack']['implementation_status'] = 'ui_accessible'
            
            # Check if Slack client is actually working
            if slack_client is not None:
                features['slack']['implementation_status'] = 'fully_functional'
                if features['slack']['configured']:
                    features['slack']['reason'] += ' (UI and backend integrated)'
        else:
            features['slack']['implemented'] = False
            features['slack']['implementation_status'] = 'ui_missing'
    except Exception as e:
        features['slack']['implemented'] = False
        features['slack']['implementation_status'] = f'error: {str(e)}'
    
    # Check AI provider implementation
    try:
        # Check if AI configuration UI exists and is accessible
        ai_config = get_ai_config()
        if ai_config and len(ai_config) > 0:
            # Check each AI provider
            provider_implementations = {
                'openai': 'openai_virtual_key' in ai_config,
                'gemini': 'gemini_virtual_key' in ai_config,
                'ollama': 'ollama_api_url' in ai_config
            }
            
            for provider, has_config in provider_implementations.items():
                if has_config:
                    features[provider]['implemented'] = True
                    features[provider]['implementation_status'] = 'ui_accessible'
                    
                    # Check if the provider has actual backend support
                    if provider == 'openai' and 'openai_parser' in globals():
                        features[provider]['implementation_status'] = 'fully_functional'
                    elif provider == 'gemini' and 'gemini_parser' in globals():
                        features[provider]['implementation_status'] = 'fully_functional'
                    elif provider == 'ollama':
                        features[provider]['implementation_status'] = 'fully_functional'
                        
                    if features[provider]['configured']:
                        features[provider]['reason'] += ' (UI and backend integrated)'
                else:
                    features[provider]['implemented'] = False
                    features[provider]['implementation_status'] = 'config_missing'
        else:
            for provider in ['openai', 'gemini', 'ollama']:
                features[provider]['implemented'] = False
                features[provider]['implementation_status'] = 'ui_missing'
    except Exception as e:
        for provider in ['openai', 'gemini', 'ollama']:
            features[provider]['implemented'] = False
            features[provider]['implementation_status'] = f'error: {str(e)}'
    
    # Check Portkey implementation
    try:
        # Check if Portkey is integrated in the AI configuration
        ai_config = get_ai_config()
        if ai_config and 'portkey_api_key' in ai_config:
            features['portkey']['implemented'] = True
            features['portkey']['implementation_status'] = 'ui_accessible'
            
            # Check if portkey_config module is available
            if 'portkey_config' in globals():
                features['portkey']['implementation_status'] = 'fully_functional'
                if features['portkey']['configured']:
                    features['portkey']['reason'] += ' (UI and backend integrated)'
        else:
            features['portkey']['implemented'] = False
            features['portkey']['implementation_status'] = 'ui_missing'
    except Exception as e:
        features['portkey']['implemented'] = False
        features['portkey']['implementation_status'] = f'error: {str(e)}'
    
    # Check Multilingual implementation (Beta Feature)
    try:
        # Check if multilingual configuration UI exists and is accessible
        multilingual_config = get_multilingual_config()
        if multilingual_config and len(multilingual_config) > 0:
            features['multilingual']['implemented'] = True
            features['multilingual']['implementation_status'] = 'beta_ui_accessible'
            
            # Check if multilingual service is actually working
            try:
                translation_service = get_multilingual_service()
                if translation_service and translation_service.is_available():
                    features['multilingual']['implementation_status'] = 'beta_fully_functional'
                    # Check translation capabilities
                    test_translation = translation_service.translate_ui_string("Hello", "es")
                    if test_translation and test_translation != "Hello":
                        features['multilingual']['test_translation'] = f'"Hello" ‚Üí "{test_translation}"'
                        features['multilingual']['implementation_status'] = 'beta_verified_working'
                        if features['multilingual']['configured']:
                            features['multilingual']['reason'] += ' (Verified working with live translation test)'
                else:
                    features['multilingual']['implementation_status'] = 'beta_service_unavailable'
            except Exception as e:
                features['multilingual']['implementation_status'] = f'beta_service_error: {str(e)}'
        else:
            features['multilingual']['implemented'] = False
            features['multilingual']['implementation_status'] = 'beta_config_missing'
    except Exception as e:
        features['multilingual']['implemented'] = False
        features['multilingual']['implementation_status'] = f'beta_error: {str(e)}'
    
    # Additional checks for endpoints and routes
    try:
        # Verify key API endpoints exist
        from flask import current_app
        with current_app.app_context():
            # Check if configuration routes exist
            rule_names = [rule.rule for rule in current_app.url_map.iter_rules()]
            
            required_routes = {
                'slack': ['/config/slack', '/api/slack/config'],
                'ai_providers': ['/config/ai', '/api/ai/config'],
                'features': ['/config/features', '/api/features/status'],
                'multilingual': ['/config/multilingual', '/api/multilingual/config', '/api/translation/status', '/api/translate/ui']
            }
            
            # Update implementation status based on route availability
            if '/config/slack' in rule_names and '/api/slack/config' in rule_names:
                if features['slack']['implementation_status'] not in ['fully_functional']:
                    features['slack']['implementation_status'] = 'routes_available'
            
            if '/config/ai' in rule_names and '/api/ai/config' in rule_names:
                for provider in ['openai', 'gemini', 'ollama', 'portkey']:
                    if features[provider]['implementation_status'] not in ['fully_functional']:
                        features[provider]['implementation_status'] = 'routes_available'
            
            if '/config/features' in rule_names:
                # Feature detection itself is implemented
                features['_feature_detection_implemented'] = True
            
            # Check multilingual routes
            if '/config/multilingual' in rule_names and '/api/multilingual/config' in rule_names:
                if features['multilingual']['implementation_status'] not in ['beta_fully_functional', 'beta_verified_working']:
                    features['multilingual']['implementation_status'] = 'beta_routes_available'
                
    except Exception as e:
        logging.warning(f"Could not verify route implementation: {e}")
    
    # Log implementation summary (only at debug level to reduce noise)
    implemented_features = [k for k, v in features.items() 
                          if isinstance(v, dict) and v.get('implemented', False)]
    logging.debug(f"‚úÖ IMPLEMENTATION_CHECK: {len(implemented_features)} features verified as implemented: {implemented_features}")

def apply_auto_configuration():
    """
    Apply intelligent auto-configuration based on detected features.
    Updates database configuration with detected optimal settings.
    """
    features = detect_available_features()
    
    if not features['auto_configuration_applied']:
        logging.info("‚ö†Ô∏è AUTO_CONFIG: No auto-configuration needed")
        return features
    
    logging.info("üîß AUTO_CONFIG: Applying intelligent auto-configuration...")
    
    # Auto-configure AI provider based on detection
    if features['recommended_provider']:
        try:
            current_provider = get_ai_config().get('provider_name', {}).get('value', 'openai')
            if current_provider != features['recommended_provider']:
                update_ai_config('provider_name', features['recommended_provider'])
                
                # Sync main model_name with provider-specific model (fix startup logic issue)
                ai_config = get_ai_config()
                if features['recommended_provider'] == 'openai':
                    model_name = ai_config.get('openai_model_name', {}).get('value', 'gpt-3.5-turbo')
                elif features['recommended_provider'] == 'gemini':
                    model_name = ai_config.get('gemini_model_name', {}).get('value', 'gemini-pro')
                elif features['recommended_provider'] == 'ollama':
                    model_name = ai_config.get('ollama_model_name', {}).get('value', 'phi3:mini')
                else:
                    model_name = 'gpt-3.5-turbo'  # Safe default
                
                update_ai_config('model_name', model_name)
                logging.info(f"‚úÖ AUTO_CONFIG: AI provider set to {features['recommended_provider']} with model {model_name}")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update AI provider: {e}")
    
    # Auto-configure Slack if detected
    if features['slack']['configured']:
        try:
            slack_token = os.environ.get("SLACK_BOT_TOKEN", "")
            current_token = get_slack_config().get('bot_token', {}).get('value', '')
            if current_token != slack_token:
                update_slack_config('bot_token', slack_token)
                update_slack_config('enabled', 'true')
                logging.info("‚úÖ AUTO_CONFIG: Slack integration enabled")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update Slack config: {e}")
    
    # Auto-configure Portkey and cloud providers
    if features['portkey']['configured']:
        try:
            portkey_key = os.environ.get("PORTKEY_API_KEY", "")
            current_key = get_ai_config().get('portkey_api_key', {}).get('value', '')
            if current_key != portkey_key:
                update_ai_config('portkey_api_key', portkey_key)
                logging.info("‚úÖ AUTO_CONFIG: Portkey security layer configured")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update Portkey config: {e}")
    
    if features['openai']['configured']:
        try:
            openai_vkey = os.environ.get("OPENAI_VIRTUAL_KEY", "")
            current_vkey = get_ai_config().get('openai_virtual_key', {}).get('value', '')
            if current_vkey != openai_vkey:
                update_ai_config('openai_virtual_key', openai_vkey)
                logging.info("‚úÖ AUTO_CONFIG: OpenAI virtual key configured")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update OpenAI config: {e}")
    
    if features['gemini']['configured']:
        try:
            gemini_vkey = os.environ.get("GEMINI_VIRTUAL_KEY", "")
            current_vkey = get_ai_config().get('gemini_virtual_key', {}).get('value', '')
            if current_vkey != gemini_vkey:
                update_ai_config('gemini_virtual_key', gemini_vkey)
                logging.info("‚úÖ AUTO_CONFIG: Gemini virtual key configured")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update Gemini config: {e}")
    
    # Auto-configure Ollama if detected
    if features['ollama']['configured']:
        try:
            ollama_url = os.environ.get("OLLAMA_API_URL", "")
            current_url = get_ai_config().get('ollama_api_url', {}).get('value', '')
            if current_url != ollama_url:
                update_ai_config('ollama_api_url', ollama_url)
                logging.info("‚úÖ AUTO_CONFIG: Ollama API URL configured")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è AUTO_CONFIG: Failed to update Ollama config: {e}")
    
    logging.info("‚úÖ AUTO_CONFIG: Auto-configuration completed successfully")
    return features

@app.route('/api/features/detect', methods=['GET'])
def api_detect_features():
    """API endpoint to detect available features and auto-configure if requested."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    apply_auto_config = request.args.get('apply_auto_config', 'false').lower() == 'true'
    
    try:
        if apply_auto_config:
            features = apply_auto_configuration()
        else:
            features = detect_available_features()
        
        return jsonify({
            'success': True,
            'features': features,
            'auto_configuration_applied': apply_auto_config and features.get('auto_configuration_applied', False)
        })
    except Exception as e:
        logging.error(f"Error detecting features: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/features/status', methods=['GET'])
def api_feature_status():
    """Get current feature status with recommendations."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    try:
        features = get_cached_features()
        
        # Generate recommendations
        recommendations = []
        
        if not features['slack']['configured']:
            recommendations.append({
                'type': 'slack',
                'priority': 'medium',
                'title': 'Enable Slack Notifications',
                'description': 'Configure Slack bot token to receive security alerts',
                'action': 'Add SLACK_BOT_TOKEN to your Kubernetes secrets'
            })
        
        if not any(features[p]['configured'] for p in ['openai', 'gemini', 'ollama']):
            recommendations.append({
                'type': 'ai',
                'priority': 'high',
                'title': 'Configure AI Provider',
                'description': 'No AI provider is configured for security analysis',
                'action': 'Configure at least one AI provider (OpenAI, Gemini, or Ollama)'
            })
        
        if features['portkey']['configured'] and not features['openai']['configured'] and not features['gemini']['configured']:
            recommendations.append({
                'type': 'cloud_ai',
                'priority': 'low',
                'title': 'Add Cloud AI Provider',
                'description': 'Portkey is configured but no cloud AI providers are enabled',
                'action': 'Add OpenAI or Gemini virtual keys to use cloud AI'
            })
        
        # Multilingual recommendations
        if features['multilingual']['status'] == 'beta_disabled':
            recommendations.append({
                'type': 'multilingual',
                'priority': 'low',
                'title': 'Try Multilingual AI Analysis (Beta)',
                'description': 'Enable multilingual security analysis and UI translation',
                'action': 'Visit /config/multilingual to enable 24-language support',
                'beta': True
            })
        elif features['multilingual']['status'] == 'beta_partial':
            recommendations.append({
                'type': 'multilingual',
                'priority': 'medium',
                'title': 'Fix Multilingual AI Service (Beta)',
                'description': 'Multilingual enabled but AI translation service unavailable',
                'action': 'Check Ollama service and download translation models',
                'beta': True
            })
        elif features['multilingual']['status'] == 'beta_active' and not features['multilingual'].get('ui_translation_enabled', True):
            recommendations.append({
                'type': 'multilingual',
                'priority': 'low',
                'title': 'Enable UI Translation (Beta)',
                'description': 'Multilingual AI is active but UI translation is disabled',
                'action': 'Enable UI translation in multilingual configuration',
                'beta': True
            })
        
        return jsonify({
            'success': True,
            'features': features,
            'recommendations': recommendations,
            'summary': {
                'total_features': len([f for f in features.values() if isinstance(f, dict)]),
                'configured_features': len([f for f in features.values() if isinstance(f, dict) and f.get('configured', False)]),
                'recommended_provider': features.get('recommended_provider'),
                'deployment_type': features.get('deployment_type')
            }
        })
    except Exception as e:
        logging.error(f"Error getting feature status: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# --- Internationalization Routes ---
@app.route('/api/lang', methods=['GET'])
def api_get_languages():
    """Get available languages."""
    current_language = get_locale()
    
    return jsonify({
        'languages': LANGUAGES,
        'current': current_language
    })

@app.route('/api/lang/<lang_code>', methods=['POST'])
def api_set_language(lang_code):
    """Set user language preference."""
    if lang_code not in LANGUAGES:
        return jsonify({'error': 'Language not supported'}), 400
    
    session['language'] = lang_code
    session.permanent = True  # Make session permanent
    
    # For global language switching, also store as system default
    try:
        # Store the global language setting in the multilingual config
        update_multilingual_config('general_default_language', lang_code)
        
        logging.info(f"üåç Global language changed to: {lang_code} ({LANGUAGES[lang_code]['name']})")
    except Exception as e:
        logging.warning(f"Failed to store global language preference: {e}")
        
        return jsonify({
            'success': True,
        'language': lang_code,
        'language_name': LANGUAGES[lang_code]['name']
    })

# --- Multilingual AI Analysis Routes ---
@app.route('/api/ai/analyze-multilingual', methods=['POST'])
def api_analyze_multilingual():
    """Analyze security alert in multiple languages using AI translation models."""
    try:
        data = request.json
        alert_payload = data.get('alert_payload')
        language = data.get('language', 'en')
        
        if not alert_payload:
            return jsonify({'error': 'Alert payload is required'}), 400
        
        # Generate multilingual analysis
        analysis = generate_explanation_multilingual(alert_payload, language)
        
        return jsonify({
            'success': True,
            'analysis': analysis,
            'language': language
        })
        
    except Exception as e:
        logging.error(f"‚ùå Error in multilingual analysis API: {e}")
        return jsonify({'error': str(e)}), 500



@app.route('/api/translation/pull-model', methods=['POST'])
def api_translation_pull_model():
    """Pull AI translation model via Ollama."""
    try:
        data = request.json
        model_name = data.get('model_name')
        
        translation_service = get_multilingual_service()
        success = translation_service.pull_model(model_name)
        
        if success:
            return jsonify({
                'success': True,
                'message': f'Successfully pulled model: {model_name or translation_service.model_name}'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to pull model'
            }), 500
            
    except Exception as e:
        logging.error(f"‚ùå Error pulling AI translation model: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/translate', methods=['POST'])
def api_translate():
    """Translate UI strings using available translation services."""
    try:
        data = request.json
        text = data.get('text')
        target_language = data.get('language', 'en')
        
        if not text:
            return jsonify({'error': 'Text is required'}), 400
        
        translation_service = get_multilingual_service()
        translated_text = translation_service.translate_ui_string(text, target_language)
        
        return jsonify({
            'success': True,
            'original': text,
            'translated': translated_text,
            'language': target_language
        })
        
    except Exception as e:
        logging.error(f"‚ùå Error in translation API: {e}")
        return jsonify({'error': str(e)}), 500

# --- Multilingual Configuration Routes ---
@app.route('/config/multilingual')
def multilingual_config_ui():
    """Multilingual configuration page."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('multilingual_config.html')

@app.route('/test/translation')
def translation_test_ui():
    """Translation system test page."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    return render_template('translation_test.html')

@app.route('/api/multilingual/config')
def api_multilingual_config():
    """Get multilingual configuration."""
    try:
        config = get_multilingual_config()
        return jsonify(config)
    except Exception as e:
        logging.error(f"‚ùå Error getting multilingual config: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/translation/status')
def api_translation_status():
    """Get multilingual translation system status."""
    try:
        translation_service = get_multilingual_service()
        
        # Check if multilingual AI is available
        available = translation_service.is_available()
        
        # Get available models
        models = []
        try:
            response = requests.get(f"{translation_service.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models_data = response.json().get("models", [])
                models = [model.get("name", "") for model in models_data]
        except Exception as e:
            logging.warning(f"Failed to get model list: {e}")
        
        # Get translation providers status
        translation_providers = translation_service.get_available_translation_providers()
        
        return jsonify({
            'available': available,
            'models': models,
            'enabled': translation_service.enabled,
            'endpoint': translation_service.ollama_url,
            'default_model': translation_service.model_name,
            'current_model': translation_service.model_name,
            'translation_providers': translation_providers,
            'ui_provider': translation_service.ui_translation_provider,
            'ai_provider': translation_service.ai_analysis_provider
        })
    except Exception as e:
        logging.error(f"‚ùå Error getting multilingual system status: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/translation/providers')
def api_translation_providers():
    """Get available translation providers."""
    try:
        translation_service = get_multilingual_service()
        providers = translation_service.get_available_translation_providers()
        
        return jsonify({
            'success': True,
            'providers': providers
        })
    except Exception as e:
        logging.error(f"‚ùå Error getting translation providers: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/translation/test', methods=['POST'])
def api_test_translation():
    """Test translation with a specific provider."""
    try:
        data = request.json
        text = data.get('text', 'Hello, this is a test.')
        target_language = data.get('language', 'es')
        provider = data.get('provider', 'auto')
        
        translation_service = get_multilingual_service()
        
        if provider == 'auto':
            translated = translation_service.translate_ui_string(text, target_language)
        else:
            translated = translation_service.translate_ui_string(text, target_language, provider)
        
        return jsonify({
            'success': True,
            'original': text,
            'translated': translated,
            'language': target_language,
            'provider_used': provider
        })
    except Exception as e:
        logging.error(f"‚ùå Error testing translation: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/multilingual/config/general', methods=['POST'])
def api_update_multilingual_general_config():
    """Update general multilingual settings."""
    try:
        data = request.json
        
        # Update each setting
        for key, value in data.items():
            update_multilingual_config(f'general_{key}', value)
        
        return jsonify({'success': True, 'message': 'General settings updated successfully'})
    except Exception as e:
        logging.error(f"‚ùå Error updating general multilingual config: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/multilingual/config/ai', methods=['POST'])
def api_update_multilingual_ai_config():
    """Update AI translation model settings."""
    try:
        data = request.json
        
        # Update each AI translation setting
        for key, value in data.items():
            update_multilingual_config(f'ai_{key}', value)
        
        return jsonify({'success': True, 'message': 'AI translation model settings updated successfully'})
    except Exception as e:
        logging.error(f"‚ùå Error updating AI translation model config: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/multilingual/config/languages', methods=['POST'])
def api_update_multilingual_language_config():
    """Update enabled languages settings."""
    try:
        data = request.json
        enabled_languages = data.get('enabled_languages', [])
        
        # Store as JSON string
        update_multilingual_config('enabled_languages', json.dumps(enabled_languages))
        
        return jsonify({'success': True, 'message': 'Language settings updated successfully'})
    except Exception as e:
        logging.error(f"‚ùå Error updating language multilingual config: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/multilingual/config/master', methods=['POST'])
def api_update_multilingual_master_config():
    """Update master multilingual enable/disable setting."""
    try:
        data = request.json
        master_enabled = data.get('master_enabled', 'true')
        
        # Update the master_enabled setting directly (not with general_ prefix)
        update_multilingual_config('master_enabled', master_enabled)
        
        logging.info(f"üîß Master multilingual setting updated: {master_enabled}")
        
        return jsonify({'success': True, 'message': 'Master multilingual setting updated successfully'})
    except Exception as e:
        logging.error(f"‚ùå Error updating master multilingual config: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/multilingual/test', methods=['POST'])
def api_test_multilingual():
    """Test multilingual functionality."""
    try:
        data = request.json
        test_type = data.get('type', 'ai_connection')
        
        if test_type == 'ai_connection':
            # Test AI translation service connection
            translation_service = get_multilingual_service()
            if translation_service.is_available():
                return jsonify({
                    'success': True,
                    'message': 'AI translation service connection successful',
                    'models': translation_service.get_available_models()
                })
            else:
                return jsonify({
                    'success': False,
                    'message': 'AI translation service not available - models may need to be downloaded'
                }), 400
        
        elif test_type == 'translation':
            # Test translation
            text = data.get('text', 'Hello, this is a test.')
            language = data.get('language', 'es')
            
            translation_service = get_multilingual_service()
            translated = translation_service.translate_ui_string(text, language)
            
            return jsonify({
                'success': True,
                'original': text,
                'translated': translated,
                'language': language
            })
        
        else:
            return jsonify({'error': 'Unknown test type'}), 400
            
    except Exception as e:
        logging.error(f"‚ùå Error testing multilingual functionality: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/mcp/system-health')
def mcp_system_health():
    """Get comprehensive system health including MCP status"""
    if not MCP_AVAILABLE:
        return jsonify({"error": "MCP features not available"}), 503
    
    try:
        # Initialize MCP manager if not already done
        if not mcp_manager.is_available:
            mcp_manager.initialize()
        
        # Get system health using our tools
        if "analyze_system_state" in mcp_manager.server.tools:
            components = ["falco", "weaviate", "ollama", "mcp"]
            health_result = mcp_manager.server.tools["analyze_system_state"].handler(components)
            
            # Add MCP status
            mcp_status = mcp_manager.get_status()
            
            return jsonify({
                "success": True,
                "system_health": health_result,
                "mcp_status": mcp_status,
                "overall_status": "healthy" if health_result["status"] == "healthy" else "degraded"
            })
        else:
            return jsonify({"error": "System health tool not available"}), 500
            
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def broadcast_to_clients(event_type, data):
    """Broadcast event to all connected SSE clients."""
    with sse_client_lock:
        if not sse_clients:
            return
        
        event_data = {
            'type': event_type,
            'timestamp': datetime.datetime.now().isoformat(),
            **data
        }
        
        # Remove disconnected clients
        disconnected_clients = []
        for client in sse_clients[:]:  # Create a copy to iterate
            try:
                client.put(event_data)
            except:
                disconnected_clients.append(client)
        
        # Clean up disconnected clients
        for client in disconnected_clients:
            if client in sse_clients:
                sse_clients.remove(client)
        
        if len(sse_clients) > 0:
            logging.info(f"üì° Broadcasted {event_type} to {len(sse_clients)} clients")

def broadcast_status_change(alert_id, new_status, old_status):
    """Broadcast alert status change to all connected clients."""
    broadcast_to_clients('alert_status_change', {
        'alert_id': alert_id,
        'new_status': new_status,
        'old_status': old_status
    })

def broadcast_new_alert(alert_data):
    """Broadcast new alert to all connected clients."""
    broadcast_to_clients('new_alert', {
        'alert': alert_data
    })

def broadcast_counts_updated():
    """Broadcast that alert counts have been updated."""
    broadcast_to_clients('counts_updated', {})

@app.route('/api/events/stream')
def sse_stream():
    """Server-Sent Events endpoint for real-time updates."""
    if not WEB_UI_ENABLED:
        return jsonify({"error": "Web UI disabled"}), 404
    
    def event_stream():
        client = SSEClient()
        add_sse_client(client)
        
        try:
            # Send initial connection message
            yield f"data: {json.dumps({'type': 'connected', 'timestamp': datetime.datetime.now().isoformat()})}\n\n"
            
            while True:
                try:
                    # Wait for events with timeout
                    event_data = client.queue.get(timeout=30)
                    yield f"data: {json.dumps(event_data)}\n\n"
                except queue.Empty:
                    # Send heartbeat to keep connection alive
                    yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': datetime.datetime.now().isoformat()})}\n\n"
                except GeneratorExit:
                    break
                except Exception as e:
                    logging.error(f"‚ùå SSE stream error: {e}")
                    break
        finally:
            remove_sse_client(client)
    
    response = Response(event_stream(), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['Connection'] = 'keep-alive'
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Headers'] = 'Cache-Control'
    return response

# ENHANCED STORE ALERT WITH REAL-TIME BROADCASTING
def store_alert_enhanced(alert_data, ai_analysis=None):
    """Enhanced store_alert function with real-time broadcasting."""
    # Store in SQLite as before
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO alerts (rule, priority, output, source, fields, ai_analysis)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        alert_data.get('rule', ''),
        alert_data.get('priority', ''),
        alert_data.get('output', ''),
        alert_data.get('output_fields', {}).get('container.name', 'unknown'),
        json.dumps(alert_data.get('output_fields', {})),
        json.dumps(ai_analysis) if ai_analysis else None
    ))
    
    alert_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    # Create alert object for broadcasting
    alert_obj = {
        'id': alert_id,
        'timestamp': alert_data.get('time', datetime.datetime.now().isoformat()),
        'rule': alert_data.get('rule', ''),
        'priority': alert_data.get('priority', ''),
        'output': alert_data.get('output', ''),
        'source': alert_data.get('output_fields', {}).get('container.name', 'unknown'),
        'fields': alert_data.get('output_fields', {}),
        'ai_analysis': ai_analysis,
        'processed': bool(ai_analysis),
        'status': 'unread'
    }
    
    # Broadcast new alert to all connected clients
    broadcast_new_alert(alert_obj)
    
    logging.info(f"Stored alert in SQLite: {alert_data.get('rule', 'Unknown')}")
    
    # Store in Weaviate if enabled
    if WEAVIATE_ENABLED:
        try:
            weaviate_service = get_weaviate_service()
            if weaviate_service.client:
                weaviate_id = weaviate_service.store_alert(alert_data, ai_analysis)
                if weaviate_id:
                    logging.info(f"‚úÖ Stored alert in Weaviate: {weaviate_id}")
                else:
                    logging.warning("‚ö†Ô∏è Failed to store alert in Weaviate")
            else:
                logging.warning("‚ö†Ô∏è Weaviate client not connected")
        except Exception as e:
            logging.error(f"‚ùå Error storing alert in Weaviate: {e}")

# AUDIT TRAIL SYSTEM
import hashlib
import uuid

# User session management for audit trails
@app.before_request
def before_request():
    """Set up user context for audit tracking."""
    # Generate or get user session identifier
    g.user_id = session.get('user_id')
    g.session_id = session.get('session_id')
    g.client_ip = request.environ.get('HTTP_X_REAL_IP', request.remote_addr)
    g.user_agent = request.headers.get('User-Agent', 'Unknown')
    g.request_id = str(uuid.uuid4())[:8]  # Short request ID for tracking
    
    # Create session if it doesn't exist
    if not g.session_id:
        g.session_id = str(uuid.uuid4())
        session['session_id'] = g.session_id
        session.permanent = True
    
    # Set default user ID if not authenticated
    if not g.user_id:
        # Create anonymous user ID based on IP and User-Agent
        user_hash = hashlib.md5(f"{g.client_ip}:{g.user_agent}".encode()).hexdigest()[:12]
        g.user_id = f"anonymous_{user_hash}"
        session['user_id'] = g.user_id

def init_audit_database():
    """Initialize audit trail database tables."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Audit trail table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS audit_trail (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            user_id TEXT NOT NULL,
            session_id TEXT NOT NULL,
            client_ip TEXT NOT NULL,
            user_agent TEXT,
            request_id TEXT,
            action_type TEXT NOT NULL,
            resource_type TEXT NOT NULL,
            resource_id TEXT,
            action_details TEXT,
            old_values TEXT,
            new_values TEXT,
            success BOOLEAN DEFAULT TRUE,
            error_message TEXT,
            endpoint TEXT,
            method TEXT,
            duration_ms INTEGER
        )
    ''')
    
    # User sessions table for better tracking
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_sessions (
            session_id TEXT PRIMARY KEY,
            user_id TEXT NOT NULL,
            client_ip TEXT NOT NULL,
            user_agent TEXT,
            first_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
            last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
            page_views INTEGER DEFAULT 1,
            actions_count INTEGER DEFAULT 0,
            status TEXT DEFAULT 'active'
        )
    ''')
    
    # Create indexes for performance
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_audit_user_id ON audit_trail(user_id)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_trail(timestamp)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_audit_action_type ON audit_trail(action_type)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_audit_resource ON audit_trail(resource_type, resource_id)')
    
    conn.commit()
    conn.close()

def log_audit_event(action_type, resource_type, resource_id=None, action_details=None, 
                    old_values=None, new_values=None, success=True, error_message=None, 
                    duration_ms=None):
    """Log an audit event with full context."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get current user context
        user_id = getattr(g, 'user_id', 'system')
        session_id = getattr(g, 'session_id', 'no_session')
        client_ip = getattr(g, 'client_ip', 'unknown')
        user_agent = getattr(g, 'user_agent', 'unknown')
        request_id = getattr(g, 'request_id', 'no_request')
        endpoint = request.endpoint if request else 'unknown'
        method = request.method if request else 'unknown'
        
        # Insert audit record
        cursor.execute('''
            INSERT INTO audit_trail (
                user_id, session_id, client_ip, user_agent, request_id,
                action_type, resource_type, resource_id, action_details,
                old_values, new_values, success, error_message,
                endpoint, method, duration_ms
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            user_id, session_id, client_ip, user_agent, request_id,
            action_type, resource_type, resource_id,
            json.dumps(action_details) if action_details else None,
            json.dumps(old_values) if old_values else None,
            json.dumps(new_values) if new_values else None,
            success, error_message, endpoint, method, duration_ms
        ))
        
        # Update session tracking
        cursor.execute('''
            INSERT OR REPLACE INTO user_sessions (
                session_id, user_id, client_ip, user_agent, first_seen, last_seen, 
                page_views, actions_count, status
            ) VALUES (
                ?, ?, ?, ?, 
                COALESCE((SELECT first_seen FROM user_sessions WHERE session_id = ?), CURRENT_TIMESTAMP),
                CURRENT_TIMESTAMP,
                COALESCE((SELECT page_views FROM user_sessions WHERE session_id = ?), 0) + 
                    (CASE WHEN ? IN ('page_view', 'dashboard_access') THEN 1 ELSE 0 END),
                COALESCE((SELECT actions_count FROM user_sessions WHERE session_id = ?), 0) + 1,
                'active'
            )
        ''', (session_id, user_id, client_ip, user_agent, session_id, session_id, action_type, session_id))
        
        conn.commit()
        conn.close()
        
        # Enhanced logging with user context (only for non-system actions)
        if user_id != 'system':
            logging.info(f"üîç AUDIT: {user_id} ({client_ip}) performed {action_type} on {resource_type}" + 
                       (f":{resource_id}" if resource_id else "") + 
                       (f" | Request: {request_id}" if request_id != 'no_request' else ""))
        
    except Exception as e:
        logging.error(f"‚ùå Failed to log audit event: {e}")

if __name__ == '__main__':
    # Initialize database if Web UI is enabled
    if WEB_UI_ENABLED:
        init_database()
        init_audit_database()
        
        # Sync environment variables to database
        sync_env_to_database()
        
        # Initialize Weaviate if enabled
        init_weaviate()
        
        # Apply auto-configuration based on detected secrets
        logging.info("üîç STARTUP: Detecting available features and applying auto-configuration...")
        try:
            features = apply_auto_configuration()
            configured_count = len([f for f in features.values() if isinstance(f, dict) and f.get('configured', False)])
            total_count = len([f for f in features.values() if isinstance(f, dict)])
            
            logging.info(f"‚úÖ STARTUP: Feature detection completed - {configured_count}/{total_count} features configured")
            logging.info(f"ü§ñ STARTUP: Recommended AI provider: {features.get('recommended_provider', 'unknown')}")
            logging.info(f"üè¢ STARTUP: Deployment type: {features.get('deployment_type', 'unknown')}")
            
            if features.get('auto_configuration_applied'):
                logging.info("üîß STARTUP: Auto-configuration was applied based on detected secrets")
            else:
                logging.info("‚ö†Ô∏è STARTUP: No auto-configuration applied - manual configuration may be needed")
                
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è STARTUP: Feature detection failed: {e}")
        
        # Add some sample data for demonstration
        sample_alerts = [
            {
                'rule': 'Terminal shell in container',
                'priority': 'warning',
                'output': 'A shell was used as the entrypoint/exec point into a container (user=root container_id=abc123)',
                'output_fields': {'proc.cmdline': '/bin/bash', 'container.id': 'abc123', 'container.name': 'web-app-container'}
            },
            {
                'rule': 'Write below binary dir',
                'priority': 'critical',
                'output': 'File below a known binary directory opened for writing (user=root command=touch /bin/malicious)',
                'output_fields': {'proc.cmdline': 'touch /bin/malicious', 'fd.name': '/bin/malicious', 'container.name': 'database-container'}
            }
        ]
        
        # Only add sample data if no alerts exist
        existing_alerts = get_alerts()
        if not existing_alerts:
            for alert in sample_alerts:
                store_alert_enhanced(alert)
    
    logging.info(f"üöÄ Starting Falco AI Alert System on port {falco_ai_port}")
    logging.info(f"ü§ñ Provider: {os.environ.get('PROVIDER_NAME', 'openai')}")
    logging.info(f"‚ö†Ô∏è Min Priority: {MIN_FALCO_PRIORITY}")
    logging.info(f"üì¢ Slack: {'‚úÖ Configured' if slack_client else '‚ùå Not configured'}")
    logging.info(f"üñ•Ô∏è Web UI: {'‚úÖ Enabled at http://localhost:' + str(falco_ai_port) + '/dashboard' if WEB_UI_ENABLED else '‚ùå Disabled'}")
    
    # Initialize MCP integration if available
    if MCP_AVAILABLE:
        try:
            mcp_manager.initialize()
            logging.info("‚úÖ MCP integration initialized successfully")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Failed to initialize MCP integration: {e}")
    
    app.run(debug=True, host='0.0.0.0', port=falco_ai_port, threaded=True)