apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: falco-ai-alerts-production

resources:
  - ../../base
  - hpa.yaml
  - network-policy.yaml

namespace: falco-ai-alerts

namePrefix: prod-

commonLabels:
  environment: production
  app.kubernetes.io/version: "1.5.2"

patches:
  # Increase replicas for production
  - target:
      kind: Deployment
      name: falco-ai-alerts
    patch: |-
      - op: replace
        path: /spec/replicas
        value: 3
  
  # Increase resource limits for production
  - target:
      kind: Deployment
      name: falco-ai-alerts
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/memory
        value: "512Mi"
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/cpu
        value: "500m"
      - op: replace
        path: /spec/template/spec/containers/0/resources/limits/memory
        value: "1Gi"
      - op: replace
        path: /spec/template/spec/containers/0/resources/limits/cpu
        value: "1000m"



  # Override ConfigMap values for production
  - target:
      kind: ConfigMap
      name: falco-ai-alerts-config
    patch: |-
      - op: replace
        path: /data/LOG_LEVEL
        value: "INFO"
      - op: replace
        path: /data/MIN_PRIORITY
        value: "warning"
      - op: add
        path: /data/ALERT_RETENTION_DAYS
        value: "90"
      - op: add
        path: /data/MAX_ALERTS_STORAGE
        value: "100000"
      - op: replace
        path: /data/OLLAMA_API_URL
        value: "http://prod-ollama:11434/api/generate"
      - op: replace
        path: /data/OLLAMA_TIMEOUT
        value: "60"  # Production timeout for model upgrades (llama3.1:8b+)
      - op: replace
        path: /data/AI_REQUEST_TIMEOUT
        value: "60"  # Allow longer inference for complex models

  # Keep larger storage for production Ollama (30Gi vs 15Gi base)
  - target:
      kind: PersistentVolumeClaim
      name: ollama-data
    patch: |-
      - op: replace
        path: /spec/resources/requests/storage
        value: "30Gi"
  
  # Production Ollama timeout configuration (for larger models)
  - target:
      kind: Deployment
      name: ollama
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/env/1/value
        value: "60"  # Extended timeout for production models
      - op: replace
        path: /spec/template/spec/containers/0/env/2/value
        value: "10m"  # Keep larger models in memory longer

  # Fix Ollama service name in init job
  - target:
      kind: Job
      name: ollama-model-init
    patch: |-
      - op: replace
        path: /spec/template/spec/initContainers/0/command/2
        value: |
          echo "Waiting for Ollama service to be ready..."
          until wget -q --spider http://prod-ollama:11434/api/tags; do
            echo "Ollama not ready, waiting 10 seconds..."
            sleep 10
          done
          echo "Ollama is ready!"
      - op: replace
        path: /spec/template/spec/containers/0/command/2
        value: |
          echo "Pulling ultra-fast model: tinyllama"
          curl -X POST http://prod-ollama:11434/api/pull \
            -H "Content-Type: application/json" \
            -d '{"name": "tinyllama"}' \
            --max-time 1800
          
          echo "Verifying model was pulled..."
          curl -s http://prod-ollama:11434/api/tags | grep -q "tinyllama" || exit 1
          
          echo "Warming up model with test inference..."
          curl -X POST http://prod-ollama:11434/api/generate \
            -H "Content-Type: application/json" \
            -d '{"model": "tinyllama", "prompt": "Hello, test", "stream": false}' \
            --max-time 60
          
          echo "Model initialization and warm-up complete!"
          echo "NOTE: For better analysis, consider upgrading to phi3:mini or jimscard/whiterabbit-neo:latest"
          echo "      via the AI Configuration dashboard after deployment."

images:
  - name: maddigsys/falco-ai-alerts
    newName: maddigsys/falco-ai-alerts
    newTag: "v1.5.5" 